{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questo notebook implementa un Convolutional Neural Network che utilizza, per√≤, i vettori pretrainati. Questi sono comunque soggetti a fine-tuning nel layer \"Embeddings\" col parametro trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import gensim.downloader as api\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, make_scorer\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load(\"w2vPreTrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3150, 6)\n",
      "(3150, 6)\n",
      "(2998, 6)\n",
      "(2196, 6)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"amazon_alexa.tsv\", sep = \"\\t\", encoding = \"utf-8\")\n",
    "print(dataset.shape)\n",
    "dataset.dropna(inplace = True)\n",
    "print(dataset.shape)\n",
    "dataset.drop(dataset[dataset.rating == 3].index, inplace=True)\n",
    "print(dataset.shape)\n",
    "dataset.drop_duplicates(subset = \"verified_reviews\", inplace = True)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1990\n",
      "0     206\n",
      "Name: feedback, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"feedback\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(dataset[\"verified_reviews\"].values).reshape(-1, 1)\n",
    "y = list(dataset[\"feedback\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 412, 0: 206})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "undersampler = RandomUnderSampler(sampling_strategy=0.5, random_state = 0)\n",
    "\n",
    "X, y = undersampler.fit_resample(X, y)\n",
    "\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = []\n",
    "\n",
    "for rev in X:\n",
    "  X_temp.append(rev[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of types extracted is: 1788\n"
     ]
    }
   ],
   "source": [
    "new_text, new_sent_tok = tokenize_list_of_text(X_temp, custom_stopwords, False, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews = frequency_cleaning(new_sent_tok, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = Phrases(cleaned_reviews, scoring=\"npmi\", threshold=0.60) #estrae le collocazioni tramite PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(bigrams[cleaned_reviews], y, test_size=0.20, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joke']\n",
      "-\n",
      "['laugh']\n",
      "--------------------------\n",
      "['price', 'product', 'nice', 'quality', 'nice', 'feature', 'definitely', 'reason', 'give', 'think', 'may', 'buyer', 'error', 'first', 'ignore', 'product', 'plug', 'time', 'work', 'really', 'unlike', 'not_a', 'stand', 'device', 'also', 'speaker', 'not_very', 'loud', 'buy', 'bluetooth', 'speaker', 'sure', 'lot', 'figure', 'use', 'kind', 'seem', 'like', 'device', 'plus', 'set', 'awful', 'would', 'definitely', 'money', 'buy', 'one', 'actually']\n",
      "-\n",
      "['cost', 'product', 'decent', 'quality', 'decent', 'feature', 'definitely', 'reason', 'present', 'imagine', 'may', 'buyer', 'error', 'start', 'ignore', 'product', 'plug', 'sentence', 'run', 'truly', 'different', 'not_a', 'base', 'device', 'also', 'speaker', 'not_very', 'loudly', 'purchase', 'bluetooth', 'speaker', 'sure', 'plenty', 'figure', 'utilize', 'kind', 'seem', 'wish', 'device', 'plus', 'adjust', 'terrible', 'would', 'definitely', 'money', 'purchase', 'one', 'really']\n",
      "--------------------------\n",
      "['never', 'work']\n",
      "-\n",
      "['never', 'run']\n",
      "--------------------------\n",
      "['order', 'deal', 'day', 'idle', 'day']\n",
      "-\n",
      "['order', 'bargain', 'day', 'idle', 'day']\n",
      "--------------------------\n",
      "['great', 'product', 'useless', 'overall', 'many', 'feature', 'unless', 'smart', 'home', 'obviate']\n",
      "-\n",
      "['outstanding', 'product', 'useless', 'overall', 'many', 'feature', 'unless', 'smart', 'house', 'obviate']\n",
      "--------------------------\n",
      "['use', 'idle']\n",
      "-\n",
      "['utilize', 'idle']\n",
      "--------------------------\n",
      "['much', 'difficult', 'use']\n",
      "-\n",
      "['much', 'hard', 'utilize']\n",
      "--------------------------\n",
      "['two', 'week', 'set', 'unretentive', 'work', 'dark', 'guess', 'lack', 'purchase', 'refurbished']\n",
      "-\n",
      "['two', 'week', 'adjust', 'unretentive', 'run', 'blue', 'think', 'miss', 'buy', 'refurbish']\n",
      "--------------------------\n",
      "['use', 'hear', 'news', 'concern', 'wish', 'would', 'something', 'firmware', 'yet']\n",
      "-\n",
      "['utilize', 'listen', 'news', 'worry', 'like', 'would', 'something', 'firmware', 'still']\n",
      "--------------------------\n",
      "['really', 'happy', 'original', 'thought', 'get', 'use', 'bedroom', 'really', 'disappointed', 'audio', 'quality', 'connect', 'speaker', 'via', 'bluetooth', 'audio', 'much', 'good', 'start', 'problem', 'connection', 'wifi', 'bluetooth', 'connect', 'speaker', 'via', 'wifi', 'wake', 'middle', 'night', 'horrible', 'sound', 'hop', 'take', 'thing', 'back', 'give', 'good', 'deal', 'spot', 'hope', 'good', 'device']\n",
      "-\n",
      "['truly', 'glad', 'original', 'think', 'receive', 'utilize', 'bedroom', 'truly', 'disappoint', 'sound', 'quality', 'link', 'speaker', 'via', 'bluetooth', 'sound', 'much', 'well', 'begin', 'trouble', 'connection', 'wifi', 'bluetooth', 'link', 'speaker', 'via', 'wifi', 'awake', 'eye', 'dark', 'horrible', 'audio', 'hop', 'bring', 'thing', 'back', 'present', 'well', 'bargain', 'place', 'promise', 'well', 'device']\n",
      "--------------------------\n",
      "['bad', 'purchase', 'make', 'big', 'love', 'brand', 'digital', 'music', 'video', 'even', 'buy', 'game', 'music', 'movie', 'app', 'try', 'use', 'make', 'simple', 'purchase', 'anything', 'useless']\n",
      "-\n",
      "['badly', 'buy', 'ready', 'large', 'enjoy', 'brand', 'digital', 'music', 'picture', 'still', 'purchase', 'game', 'music', 'movie', 'app', 'attempt', 'utilize', 'ready', 'simple', 'buy', 'anything', 'useless']\n",
      "--------------------------\n",
      "['sound', 'terrible', 'like', 'love', 'item', 'awful']\n",
      "-\n",
      "['audio', 'awful', 'wish', 'enjoy', 'item', 'terrible']\n",
      "--------------------------\n",
      "['product', 'two', 'software', 'make', 'completely', 'card', 'homescreen', 'call', 'thing', 'try', 'service', 'try', 'turn', 'homescreen', 'card', 'not_this', 'one', 'homescreen', 'card', 'cycle', 'annoy', 'set', 'card', 'cycle', 'instead', 'cycle', 'continuously', 'setting', 'idle', 'unit', 'set', 'cycle', 'card', 'still', 'continue', 'cycle', 'time', 'reboot', 'device', 'set', 'etc', 'etc', 'two', 'software', 'issue', 'fix', 'product', 'useless']\n",
      "-\n",
      "['product', 'two', 'software', 'ready', 'totally', 'card', 'homescreen', 'phone', 'thing', 'attempt', 'service', 'attempt', 'play', 'homescreen', 'card', 'not_this', 'one', 'homescreen', 'card', 'cycle', 'irritate', 'adjust', 'card', 'cycle', 'instead', 'cycle', 'continuously', 'position', 'idle', 'unit', 'adjust', 'cycle', 'card', 'yet', 'proceed', 'cycle', 'sentence', 'reboot', 'device', 'adjust', 'etc', 'etc', 'two', 'software', 'issue', 'repair', 'product', 'useless']\n",
      "--------------------------\n",
      "['sound', 'home', 'mini', 'sound', 'bad', 'also', 'need', 'small', 'selection', 'music', 'need', 'music', 'play', 'everything', 'also', 'get', 'two', 'need', 'family', 'music', 'play_music', 'think', 'need', 'family', 'use', 'multiple', 'device']\n",
      "-\n",
      "['audio', 'house', 'mini', 'audio', 'badly', 'also', 'want', 'little', 'option', 'music', 'want', 'music', 'turn', 'everything', 'also', 'receive', 'two', 'want', 'household', 'music', 'play_music', 'imagine', 'want', 'household', 'utilize', 'multiple', 'device']\n",
      "--------------------------\n",
      "['work', 'fine', 'realize', 'obviate', 'not_use']\n",
      "-\n",
      "['run', 'okay', 'see', 'obviate', 'not_use']\n",
      "--------------------------\n",
      "['fine', 'spot', 'exact', 'one', 'order', 'turn', 'repeat', 'alarm', 'morning', 'pretty', 'much', 'talk', 'not_a', 'thing', 'want', 'first', 'wake', 'bed', 'definitely', 'unlike', 'yes', 'swipe', 'alarm', 'face', 'dismiss', 'swipe', 'rather', 'touch', 'screen', 'half', 'asleep', 'difficult', 'set', 'snooze', 'half', 'time', 'even', 'really', 'try', 'swipe', 'dismiss', 'swipe', 'dismiss', 'completely', 'alarm', 'especially', 'annoy', 'could', 'easily', 'fix', 'make', 'touch', 'screen', 'turn', 'alarm', 'record', 'least', 'make', 'set', 'decide', 'touch', 'screen', 'alarm', 'snooze', 'turn', 'clock', 'year', 'still', 'set', 'clearly', 'may', 'big', 'product', 'ever', 'make']\n",
      "-\n",
      "['okay', 'place', 'precise', 'one', 'order', 'play', 'repeat', 'alarm', 'morning', 'fairly', 'much', 'speak', 'not_a', 'thing', 'need', 'start', 'awake', 'bed', 'definitely', 'different', 'yes', 'swipe', 'alarm', 'face', 'dismiss', 'swipe', 'rather', 'disturb', 'screen', 'half', 'asleep', 'hard', 'adjust', 'snooze', 'half', 'sentence', 'still', 'truly', 'attempt', 'swipe', 'dismiss', 'swipe', 'dismiss', 'totally', 'alarm', 'particularly', 'irritate', 'could', 'easy', 'repair', 'ready', 'disturb', 'screen', 'play', 'alarm', 'book', 'least', 'ready', 'adjust', 'settle', 'disturb', 'screen', 'alarm', 'snooze', 'play', 'clock', 'year', 'yet', 'adjust', 'clear', 'may', 'large', 'product', 'ever', 'ready']\n",
      "--------------------------\n",
      "['would', 'not_recommend', 'anyone', 'idle', 'program', 'way', 'thru', 'tell', 'unable', 'process', 'time', 'try', 'not_the', 'stream', 'fine', 'computer', 'disappointing']\n",
      "-\n",
      "['would', 'not_recommend', 'anyone', 'idle', 'program', 'way', 'thru', 'say', 'unable', 'procedure', 'sentence', 'attempt', 'not_the', 'stream', 'okay', 'computer', 'disappointing']\n",
      "--------------------------\n",
      "['product', 'dark', 'never', 'reset', 'instruction', 'actually', 'differ', 'package', 'instruction', 'try', 'product', 'defective']\n",
      "-\n",
      "['product', 'blue', 'never', 'reset', 'direction', 'really', 'differ', 'box', 'direction', 'attempt', 'product', 'faulty']\n",
      "--------------------------\n",
      "['turn']\n",
      "-\n",
      "['play']\n",
      "--------------------------\n",
      "['device', 'want', 'sync', 'phone', 'number', 'would', 'forbid', 'say', 'number', 'already', 'use', 'customer', 'service', 'could', 'basically', 'tell', 'phone', 'set', 'kind', 'pointless', 'pay']\n",
      "-\n",
      "['device', 'need', 'sync', 'call', 'amount', 'would', 'forbid', 'tell', 'amount', 'already', 'utilize', 'customer', 'service', 'could', 'essentially', 'say', 'call', 'adjust', 'kind', 'pointless', 'give']\n",
      "--------------------------\n",
      "['still', 'unable', 'connect', 'device', 'say', 'build', 'buy', 'bridge', 'connect', 'device', 'think', 'everything', 'would', 'sync', 'device', 'still', 'via', 'plus', 'look_forward', 'feature', 'able', 'play_music', 'check', 'weather', 'etc', 'fine']\n",
      "-\n",
      "['yet', 'unable', 'link', 'device', 'tell', 'build', 'purchase', 'bridge', 'link', 'device', 'imagine', 'everything', 'would', 'sync', 'device', 'yet', 'via', 'plus', 'look_forward', 'feature', 'able', 'play_music', 'check', 'weather', 'etc', 'okay']\n",
      "--------------------------\n",
      "['need', 'buy', 'get', 'work', 'many', 'device', 'want', 'money', 'back', 'thing', 'odd', 'turn', 'unless', 'buy', 'another', 'point', 'half', 'device', 'sell', 'thing', 'unless', 'want', 'spend', 'another', 'another', 'idle', 'many', 'device', 'must', 'not_this', 'good', 'yet', 'get', 'device', 'actually', 'understand', 'talk']\n",
      "-\n",
      "['want', 'purchase', 'receive', 'run', 'many', 'device', 'need', 'money', 'back', 'thing', 'odd', 'play', 'unless', 'purchase', 'another', 'point', 'half', 'device', 'trade', 'thing', 'unless', 'need', 'spend', 'another', 'another', 'idle', 'many', 'device', 'must', 'not_this', 'well', 'still', 'receive', 'device', 'really', 'interpret', 'speak']\n",
      "--------------------------\n",
      "['replace', 'one', 'move', 'lack', 'range', 'refurbish', 'unit', 'would', 'able', 'find', 'could', 'disconnect', 'get', 'hear', 'trouble', 'connect', 'check', 'app', 'unplug', 'several', 'time', 'not_a']\n",
      "-\n",
      "['substitute', 'one', 'movement', 'miss', 'range', 'refurbish', 'unit', 'would', 'able', 'discover', 'could', 'unplug', 'receive', 'listen', 'problem', 'link', 'check', 'app', 'disconnect', 'various', 'sentence', 'not_a']\n",
      "--------------------------\n",
      "['purchase', 'use', 'idle', 'application']\n",
      "-\n",
      "['buy', 'utilize', 'idle', 'application']\n",
      "--------------------------\n",
      "['much', 'price', 'speaker']\n",
      "-\n",
      "['much', 'cost', 'speaker']\n",
      "--------------------------\n",
      "['suppose', 'come', 'free', 'hue', 'day', 'dark', 'bulb']\n",
      "-\n",
      "['think', 'arrive', 'free', 'hue', 'day', 'blue', 'lightbulb']\n",
      "--------------------------\n",
      "['idle', 'say', 'disconnect', 'network']\n",
      "-\n",
      "['idle', 'tell', 'unplug', 'mesh']\n",
      "--------------------------\n",
      "['buy', 'refurbish', 'stop', 'function', 'quite', 'often', 'sleep', 'every', 'time', 'randomly', 'turn', 'nothing', 'sell', 'refurbished']\n",
      "-\n",
      "['purchase', 'refurbish', 'quit', 'purpose', 'quite', 'frequently', 'sleep', 'every', 'sentence', 'randomly', 'play', 'nothing', 'trade', 'refurbish']\n",
      "--------------------------\n",
      "['product', 'complete', 'waste', 'money', 'ask', 'question', 'either', 'ignore', 'answer', 'give', 'wrong', 'answer', 'find', 'information']\n",
      "-\n",
      "['product', 'finish', 'waste', 'money', 'demand', 'inquiry', 'either', 'ignore', 'response', 'present', 'wrong', 'response', 'discover', 'info']\n",
      "--------------------------\n",
      "['thing', 'work', 'party', 'apps', 'stuff', 'think', 'could', 'box', 'send_back', 'waste', 'money']\n",
      "-\n",
      "['thing', 'run', 'party', 'apps', 'stuff', 'imagine', 'could', 'package', 'send_back', 'waste', 'money']\n",
      "--------------------------\n",
      "['second', 'one', 'refurbished', 'work', 'least', 'home']\n",
      "-\n",
      "['minute', 'one', 'refurbish', 'run', 'least', 'house']\n",
      "--------------------------\n",
      "['item', 'never', 'work', 'box', 'spent', 'several', 'day', 'try', 'get', 'work', 'run', 'fix', 'thing', 'never', 'order', 'another', 'refurbish', 'device']\n",
      "-\n",
      "['item', 'never', 'run', 'package', 'spend', 'various', 'day', 'attempt', 'receive', 'run', 'work', 'repair', 'thing', 'never', 'order', 'another', 'refurbish', 'device']\n",
      "--------------------------\n",
      "['even_though', 'say', 'would', 'spend', 'multiple', 'hour', 'make', 'phone', 'call', 'also', 'miss', 'free', 'bulb']\n",
      "-\n",
      "['even_though', 'tell', 'would', 'spend', 'multiple', 'minute', 'ready', 'call', 'phone', 'also', 'lack', 'free', 'lightbulb']\n",
      "--------------------------\n",
      "['ignore', 'answer', 'many', 'question', 'ask', 'example', 'ask', 'many', 'say', 'money']\n",
      "-\n",
      "['ignore', 'response', 'many', 'inquiry', 'demand', 'example', 'demand', 'many', 'tell', 'money']\n",
      "--------------------------\n",
      "['work', 'well', 'month', 'stop', 'connect', 'internet', 'wifi', 'trouble', 'work', 'customer', 'service', 'could', 'far', 'tell', 'month', 'disappointing', 'replace']\n",
      "-\n",
      "['run', 'good', 'month', 'quit', 'link', 'internet', 'wifi', 'problem', 'run', 'customer', 'service', 'could', 'far', 'say', 'month', 'disappointing', 'substitute']\n",
      "--------------------------\n",
      "['receive', 'wrong', 'product', 'install', 'excitement', 'thank']\n",
      "-\n",
      "['get', 'wrong', 'product', 'instal', 'excitement', 'thank']\n",
      "--------------------------\n",
      "['like', 'day', 'year', 'unretentive', 'work', 'would', 'inability', 'past', 'buy', 'second', 'one', 'sell', 'third', 'one', 'first', 'longer']\n",
      "-\n",
      "['wish', 'day', 'year', 'unretentive', 'run', 'would', 'inability', 'past', 'purchase', 'minute', 'one', 'trade', 'third', 'one', 'start', 'longer']\n",
      "--------------------------\n",
      "['waste', 'money', 'not_really', 'get', 'anything', 'video_chat', 'device', 'would', 'picture', 'put', 'mode', 'first', 'photo', 'even', 'look', 'research', 'lose', 'also', 'problem', 'device', 'lack', 'problem', 'device', 'price', 'difference', 'worthlessness']\n",
      "-\n",
      "['waste', 'money', 'not_really', 'receive', 'anything', 'video_chat', 'device', 'would', 'photo', 'place', 'mood', 'start', 'picture', 'still', 'see', 'research', 'lose', 'also', 'trouble', 'device', 'miss', 'trouble', 'device', 'cost', 'difference', 'worthlessness']\n",
      "--------------------------\n",
      "['disappointed', 'request']\n",
      "-\n",
      "['disappoint', 'request']\n",
      "--------------------------\n",
      "['item', 'return', 'repair', 'item', 'back', 'repair', 'part', 'miss', 'inability', 'cord', 'include', 'please']\n",
      "-\n",
      "['item', 'refund', 'fix', 'item', 'back', 'fix', 'portion', 'lack', 'inability', 'cord', 'include', 'please']\n",
      "--------------------------\n",
      "['send_back', 'turn', 'expect', 'refurbished', 'item']\n",
      "-\n",
      "['send_back', 'play', 'anticipate', 'refurbish', 'item']\n",
      "--------------------------\n",
      "['bad', 'device', 'ignore', 'refurbish', 'activate', 'talk', 'activate', 'start', 'talk', 'talk', 'super']\n",
      "-\n",
      "['badly', 'device', 'ignore', 'refurbish', 'trigger', 'speak', 'trigger', 'begin', 'speak', 'speak', 'extremely']\n",
      "--------------------------\n",
      "['get', 'month', 'idea', 'help', 'control', 'smart', 'bulb', 'useful', 'answer_question', 'get', 'daily', 'weather', 'update', 'far', 'useful', 'half', 'time', 'wake', 'device', 'ask', 'question', 'command', 'say', 'turn', 'basically', 'ignore', 'often', 'unable', 'answer_question', 'work', 'rather', 'make_life', 'easy', 'would', 'return', 'past', 'return']\n",
      "-\n",
      "['receive', 'month', 'idea', 'assistance', 'operate', 'smart', 'lightbulb', 'useful', 'answer_question', 'receive', 'everyday', 'weather', 'update', 'far', 'useful', 'half', 'sentence', 'awake', 'device', 'demand', 'inquiry', 'control', 'tell', 'play', 'essentially', 'ignore', 'frequently', 'unable', 'answer_question', 'run', 'rather', 'make_life', 'easily', 'would', 'refund', 'past', 'refund']\n",
      "--------------------------\n",
      "['slow']\n",
      "-\n",
      "['sluggish']\n",
      "--------------------------\n",
      "['differ', 'excite', 'try', 'new', 'unfortunately', 'even_though', 'foot', 'away', 'router', 'get', 'think', 'little', 'device', 'suppose', 'take', 'issue']\n",
      "-\n",
      "['differ', 'excite', 'attempt', 'new', 'unfortunately', 'even_though', 'foot', 'away', 'router', 'receive', 'imagine', 'small', 'device', 'think', 'bring', 'issue']\n",
      "--------------------------\n",
      "['get', 'excite', 'device', 'good', 'sound', 'control', 'hue', 'not_realize', 'also', 'communicate', 'not_use', 'hue', 'bulb', 'full', 'potential', 'device', 'turn', 'light', 'set', 'number', 'color', 'also', 'bulb', 'new', 'security', 'concern', 'sell', 'want', 'full', 'new', 'device', 'end', 'need', 'update', 'make', 'device', 'pointless', 'still', 'love', 'complaint', 'functionality', 'sound_quality', 'device', 'disappointed', 'functionality']\n",
      "-\n",
      "['receive', 'excite', 'device', 'well', 'audio', 'operate', 'hue', 'not_realize', 'also', 'pass', 'not_use', 'hue', 'lightbulb', 'wide', 'potential', 'device', 'play', 'lighting', 'adjust', 'amount', 'color', 'also', 'lightbulb', 'new', 'security', 'worry', 'trade', 'need', 'wide', 'new', 'device', 'end', 'want', 'update', 'ready', 'device', 'pointless', 'yet', 'enjoy', 'complaint', 'functionality', 'sound_quality', 'device', 'disappoint', 'functionality']\n",
      "--------------------------\n",
      "['get', 'try', 'screen']\n",
      "-\n",
      "['receive', 'attempt', 'screen']\n",
      "--------------------------\n",
      "['purchase', 'plus', 'build', 'come', 'free', 'hue', 'bulb', 'get', 'everything', 'set', 'realize', 'plus', 'forbid', 'full', 'functionality', 'bulb', 'turn', 'light', 'stay', 'color', 'still', 'hue', 'bridge', 'full', 'function', 'feature', 'bulb', 'wish', 'buy', 'bulb', 'bridge', 'use', 'already', 'since', 'build', 'useless', 'buy', 'hue', 'bridge', 'get', 'full', 'light']\n",
      "-\n",
      "['buy', 'plus', 'build', 'arrive', 'free', 'hue', 'lightbulb', 'receive', 'everything', 'adjust', 'see', 'plus', 'forbid', 'wide', 'functionality', 'lightbulb', 'play', 'lighting', 'stop', 'color', 'yet', 'hue', 'bridge', 'wide', 'purpose', 'feature', 'lightbulb', 'like', 'purchase', 'lightbulb', 'bridge', 'utilize', 'already', 'since', 'build', 'useless', 'purchase', 'hue', 'bridge', 'receive', 'wide', 'lighting']\n",
      "--------------------------\n",
      "['terrible', 'stop', 'work', 'one', 'day']\n",
      "-\n",
      "['awful', 'quit', 'run', 'one', 'day']\n",
      "--------------------------\n",
      "['old', 'keep', 'crash', 'use', 'buy', 'one', 'think', 'old', 'one', 'defective', 'one', 'thing', 'back', 'start', 'leave', 'program']\n",
      "-\n",
      "['previous', 'prevent', 'crash', 'utilize', 'purchase', 'one', 'imagine', 'previous', 'one', 'faulty', 'one', 'thing', 'back', 'begin', 'forget', 'program']\n",
      "--------------------------\n",
      "['unbend', 'thing', 'try', 'screen', 'scroll', 'big', 'device', 'send_back', 'really', 'want', 'get', 'enough', 'already']\n",
      "-\n",
      "['unbend', 'thing', 'attempt', 'screen', 'scroll', 'large', 'device', 'send_back', 'truly', 'need', 'receive', 'enough', 'already']\n",
      "--------------------------\n",
      "['never', 'respond', 'speak', 'word', 'think', 'would', 'connect', 'use', 'like', 'intercom', 'differ', 'able']\n",
      "-\n",
      "['never', 'answer', 'talk', 'word', 'imagine', 'would', 'link', 'utilize', 'wish', 'intercom', 'differ', 'able']\n",
      "--------------------------\n",
      "['poor', 'quality', 'give', 'away']\n",
      "-\n",
      "['poor', 'quality', 'present', 'away']\n",
      "--------------------------\n",
      "['return', 'piece', 'garbage', 'soon', 'sure', 'small', 'customer', 'rarely', 'disappointed', 'purchase', 'home', 'automation', 'buy', 'plus', 'build', 'along', 'zigbee', 'light', 'switch', 'voice', 'control', 'even', 'work', 'often', 'nothing', 'could', 'differ', 'disappointed', 'product', 'zigbee', 'value', 'money', 'expect', 'product', 'need', 'look']\n",
      "-\n",
      "['refund', 'piece', 'garbage', 'shortly', 'sure', 'little', 'customer', 'seldom', 'disappoint', 'buy', 'house', 'automation', 'purchase', 'plus', 'build', 'along', 'zigbee', 'lighting', 'change', 'voice', 'operate', 'still', 'run', 'frequently', 'nothing', 'could', 'differ', 'disappoint', 'product', 'zigbee', 'value', 'money', 'anticipate', 'product', 'want', 'see']\n",
      "--------------------------\n",
      "['sound_quality', 'not_that', 'good', 'especially', 'price', 'pay', 'would', 'recommend', 'get', 'buy', 'good', 'speaker', 'instead', 'maybe', 'sonos', 'use']\n",
      "-\n",
      "['sound_quality', 'not_that', 'well', 'particularly', 'cost', 'give', 'would', 'recommend', 'receive', 'purchase', 'well', 'speaker', 'instead', 'perhaps', 'sonos', 'utilize']\n",
      "--------------------------\n",
      "['think', 'get', 'long', 'time', 'excite', 'hue', 'bulb', 'excite', 'end', 'spend', 'hour', 'attempt', 'add', 'bulb', 'plus', 'everything', 'try', 'end', 'try', 'set', 'watch', 'video', 'read', 'set', 'thing', 'expect', 'different', 'next', 'day', 'get', 'tech', 'support', 'hop', 'something', 'would', 'make', 'thing', 'work', 'also', 'problem', 'differ', 'error', 'well', 'tech', 'support', 'phone', 'still', 'idle', 'product', 'test', 'far', 'experience', 'smart', 'home', 'old', 'school', 'reason', 'give', 'two', 'send', 'different', 'plus', 'light_bulb', 'problem', 'not_the', 'bulb', 'item', 'purchase', 'another', 'bulb', 'still', 'could', 'device', 'next', 'attempt', 'defective', 'support', 'thought', 'maybe', 'explore', 'device', 'end', 'look', 'look', 'like', 'disbelieve', 'lose', 'video', 'show', 'problem', 'everything', 'look', 'simple', 'not_the', 'experience', 'review', 'spend', 'enough', 'time', 'already']\n",
      "-\n",
      "['imagine', 'receive', 'long', 'sentence', 'excite', 'hue', 'lightbulb', 'excite', 'end', 'spend', 'minute', 'try', 'bring', 'lightbulb', 'plus', 'everything', 'attempt', 'end', 'attempt', 'adjust', 'see', 'picture', 'understand', 'adjust', 'thing', 'anticipate', 'unlike', 'future', 'day', 'receive', 'tech', 'support', 'hop', 'something', 'would', 'ready', 'thing', 'run', 'also', 'trouble', 'differ', 'error', 'good', 'tech', 'support', 'call', 'yet', 'idle', 'product', 'test', 'far', 'experience', 'smart', 'house', 'previous', 'train', 'reason', 'present', 'two', 'ship', 'unlike', 'plus', 'light_bulb', 'trouble', 'not_the', 'lightbulb', 'item', 'buy', 'another', 'lightbulb', 'yet', 'could', 'device', 'future', 'try', 'faulty', 'support', 'think', 'perhaps', 'explore', 'device', 'end', 'see', 'see', 'wish', 'disbelieve', 'lose', 'picture', 'picture', 'trouble', 'everything', 'see', 'simple', 'not_the', 'experience', 'review', 'spend', 'enough', 'sentence', 'already']\n",
      "--------------------------\n",
      "['horrible', 'volume', 'phone', 'loud', 'device', 'one', 'not_the', 'case']\n",
      "-\n",
      "['horrible', 'loudness', 'call', 'loudly', 'device', 'one', 'not_the', 'case']\n",
      "--------------------------\n",
      "['come']\n",
      "-\n",
      "['arrive']\n",
      "--------------------------\n",
      "['sound', 'terrible', 'want', 'good', 'music', 'get']\n",
      "-\n",
      "['audio', 'awful', 'need', 'well', 'music', 'receive']\n",
      "--------------------------\n",
      "['speaker', 'pretty', 'terrible', 'home', 'good', 'product']\n",
      "-\n",
      "['speaker', 'fairly', 'awful', 'house', 'well', 'product']\n",
      "--------------------------\n",
      "['wish', 'battery', 'well', 'plug', 'item']\n",
      "-\n",
      "['like', 'battery', 'good', 'plug', 'item']\n",
      "--------------------------\n",
      "['idle', 'time']\n",
      "-\n",
      "['idle', 'sentence']\n",
      "--------------------------\n",
      "['smart', 'enough', 'make', 'work', 'send_back', 'cant', 'get', 'help', 'work', 'fine', 'want', 'big', 'speaker']\n",
      "-\n",
      "['smart', 'enough', 'ready', 'run', 'send_back', 'bank', 'receive', 'assistance', 'run', 'okay', 'need', 'large', 'speaker']\n",
      "--------------------------\n",
      "['ignore', 'customer', 'use', 'device', 'tool', 'screen', 'unbend', 'thing', 'try', 'people', 'turn', 'change', 'option', 'size', 'slightly', 'improve', 'audio', 'speaker', 'would', 'give', 'device', 'right', 'return', 'device', 'wife', 'say']\n",
      "-\n",
      "['ignore', 'customer', 'utilize', 'device', 'tool', 'screen', 'unbend', 'thing', 'attempt', 'people', 'play', 'switch', 'choice', 'size', 'slightly', 'improve', 'sound', 'speaker', 'would', 'present', 'device', 'right', 'refund', 'device', 'wife', 'tell']\n",
      "--------------------------\n",
      "['think', 'really', 'unmake', 'much', 'play_music', 'answer', 'stupid', 'question', 'finally', 'able', 'hook', 'thermostat', 'see', 'price', 'drop', 'like']\n",
      "-\n",
      "['imagine', 'truly', 'unmake', 'much', 'play_music', 'response', 'stupid', 'inquiry', 'eventually', 'able', 'addict', 'thermostat', 'visit', 'cost', 'drop', 'wish']\n",
      "--------------------------\n",
      "['buy', 'son', 'idle', 'return']\n",
      "-\n",
      "['purchase', 'son', 'idle', 'refund']\n",
      "--------------------------\n",
      "['first', 'one', 'work', 'get', 'next', 'one', 'voice', 'time', 'way', 'get', 'work', 'app', 'uncertain', 'way']\n",
      "-\n",
      "['start', 'one', 'run', 'receive', 'future', 'one', 'voice', 'sentence', 'way', 'receive', 'run', 'app', 'uncertain', 'way']\n",
      "--------------------------\n",
      "['make', 'receive', 'call', 'device', 'tell', 'need', 'ignore']\n",
      "-\n",
      "['ready', 'get', 'phone', 'device', 'say', 'want', 'ignore']\n",
      "--------------------------\n",
      "['quite', 'disappointed', 'product', 'clearly', 'half', 'time', 'ask', 'two', 'second', 'start', 'whole', 'thing', 'stop', 'couple', 'minute', 'ask', 'play_radio', 'also', 'many', 'time', 'get', 'ask', 'switch', 'light', 'item', 'also', 'name', 'clearly', 'still']\n",
      "-\n",
      "['quite', 'disappoint', 'product', 'clear', 'half', 'sentence', 'demand', 'two', 'minute', 'begin', 'totally', 'thing', 'quit', 'couple', 'second', 'demand', 'play_radio', 'also', 'many', 'sentence', 'receive', 'demand', 'change', 'lighting', 'item', 'also', 'call', 'clear', 'yet']\n",
      "--------------------------\n",
      "['unhappy', 'spot', 'reset', 'time', 'seem', 'slow', 'mode', 'top', 'hear', 'even', 'talk', 'support', 'still', 'lack', 'choose']\n",
      "-\n",
      "['unhappy', 'place', 'reset', 'sentence', 'seem', 'sluggish', 'mood', 'cover', 'listen', 'still', 'speak', 'support', 'yet', 'miss', 'select']\n",
      "--------------------------\n",
      "['load', 'keep', 'reboot', 'middle', 'show']\n",
      "-\n",
      "['load', 'prevent', 'reboot', 'eye', 'picture']\n",
      "--------------------------\n",
      "['device', 'show', 'seem', 'huge', 'potential', 'really', 'want', 'like', 'soon', 'find', 'quite', 'bit', 'disappointing', 'not_the', 'end', 'world', 'use', 'like', 'use', 'little', 'month', 'screen', 'start', 'screen', 'quick', 'look', 'make', 'understand', 'pointless', 'ask', 'replacement', 'people', 'device', 'replace', 'start', 'answer', 'quite', 'time', 'long', 'story', 'short', 'move', 'use', 'expensive', 'voice', 'activate', 'light', 'switch', 'hue', 'light', 'like']\n",
      "-\n",
      "['device', 'picture', 'seem', 'vast', 'potential', 'truly', 'need', 'wish', 'shortly', 'discover', 'quite', 'bit', 'disappointing', 'not_the', 'end', 'world', 'utilize', 'wish', 'utilize', 'small', 'month', 'screen', 'begin', 'screen', 'immediate', 'see', 'ready', 'interpret', 'pointless', 'demand', 'replacement', 'people', 'device', 'substitute', 'begin', 'response', 'quite', 'sentence', 'long', 'story', 'dead', 'movement', 'utilize', 'expensive', 'voice', 'trigger', 'lighting', 'change', 'hue', 'lighting', 'wish']\n",
      "--------------------------\n",
      "['not_it', 'end', 'help', 'replace']\n",
      "-\n",
      "['not_it', 'end', 'assistance', 'substitute']\n",
      "--------------------------\n",
      "['sound', 'terrible', 'play', 'must', 'upgrade', 'music', 'want', 'play', 'one', 'device', 'time']\n",
      "-\n",
      "['audio', 'awful', 'turn', 'must', 'upgrade', 'music', 'need', 'turn', 'one', 'device', 'sentence']\n",
      "--------------------------\n",
      "['need', 'able', 'connect', 'party', 'apps']\n",
      "-\n",
      "['want', 'able', 'link', 'party', 'apps']\n",
      "--------------------------\n",
      "['work', 'fine', 'get', 'thing', 'try', 'not_a', 'year', 'old', 'need', 'tell', 'thing', 'find', 'not_way', 'turn', 'except', 'turn', 'screen', 'lose', 'fix', 'back']\n",
      "-\n",
      "['run', 'okay', 'receive', 'thing', 'attempt', 'not_a', 'year', 'previous', 'want', 'say', 'thing', 'discover', 'not_way', 'play', 'except', 'play', 'screen', 'lose', 'repair', 'back']\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "negative_reviews = []\n",
    "for rev, label in zip(X_train, Y_train):\n",
    "    if label == 0:\n",
    "        negative_reviews.append(rev)\n",
    "    \n",
    "generated_reviews = generate_samples(negative_reviews, int(len(negative_reviews)/2), w2v_model)\n",
    "\n",
    "# run this only one time\n",
    "X_train.extend(generated_reviews)\n",
    "Y_train.extend([0 for x in generated_reviews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set is Counter({1: 329, 0: 241})\n",
      "Test set is Counter({1: 83, 0: 41})\n"
     ]
    }
   ],
   "source": [
    "print('Train set is %s' % Counter(Y_train))\n",
    "print('Test set is %s' % Counter(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer(lower = False)\n",
    "t.fit_on_texts(X_train)\n",
    "X_train_encoded = t.texts_to_sequences(X_train)\n",
    "max_length = len(max(bigrams[cleaned_reviews], key = len))\n",
    "Xtrain = pad_sequences(X_train_encoded, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_encoded = t.texts_to_sequences(X_test)\n",
    "Xtest = pad_sequences(X_test_encoded, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_matrix(embedding, vocab):\n",
    "    # total vocabulary size plus 0 for unknown words\n",
    "    vocab_size = len(vocab) + 1\n",
    "    # define weight matrix dimensions with all 0\n",
    "    weight_matrix = np.zeros((vocab_size, w2v_model.vector_size))\n",
    "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
    "    not_found = 0\n",
    "    not_found_list = []\n",
    "    for word, i in vocab.items():\n",
    "        try:\n",
    "            vector = embedding[word]\n",
    "            weight_matrix[i] = vector\n",
    "        except KeyError:\n",
    "            weight_matrix[i] = np.zeros((1, w2v_model.vector_size))\n",
    "            not_found+=1\n",
    "            not_found_list.append(word)\n",
    "            continue\n",
    "\n",
    "    print(not_found_list)\n",
    "    print(not_found)\n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['play_music', 'not_a', 'differ', 'sound_quality', 'not_the', 'send_back', 'still_learn', 'listen_music', 'light_bulb', \"'ve\", 'even_though', \"'re\", 'uncertain', 'answer_question', 'play_radio', 'homescreen', 'unmake', 'look_forward', 'not_very', 'unretentive', 'not_that', 'video_chat', 'alarm_clock', 'forbid', 'not_this', 'make_life', \"'ll\", 'not_i', 'unaware', 'trailer', 'certified', 'not_to', 'excitement', 'not_it']\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "embedding_weights = get_weight_matrix(w2v_model.wv, t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "Y_train_hot = to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [0. 1.]\n",
      "0 [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train[0], Y_train_hot[0])\n",
    "print(Y_train[1], Y_train_hot[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hot = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          70100     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 100)          0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 91, 16)            16016     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 45, 16)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 720)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 720)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               72100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 198,718\n",
      "Trainable params: 198,718\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D\n",
    "\n",
    "# Define the early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='binary_accuracy', patience=25)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, w2v_model.vector_size, input_length=max_length, trainable = True, weights = [embedding_weights]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=16, kernel_size=10, activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile network\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "# fit network\n",
    "# # better to fit multiple times\n",
    "# model.fit(Xtrain, Y_train_hot, epochs=50, verbose=2, validation_split=0.2, callbacks=[early_stopping], batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 - 2s - loss: 0.6848 - binary_accuracy: 0.6305 - val_loss: 0.9191 - val_binary_accuracy: 0.2609 - 2s/epoch - 85ms/step\n",
      "Epoch 2/100\n",
      "23/23 - 0s - loss: 0.5734 - binary_accuracy: 0.7184 - val_loss: 0.8517 - val_binary_accuracy: 0.4348 - 330ms/epoch - 14ms/step\n",
      "Epoch 3/100\n",
      "23/23 - 0s - loss: 0.4284 - binary_accuracy: 0.7953 - val_loss: 0.6570 - val_binary_accuracy: 0.6359 - 328ms/epoch - 14ms/step\n",
      "Epoch 4/100\n",
      "23/23 - 0s - loss: 0.2526 - binary_accuracy: 0.8956 - val_loss: 0.5417 - val_binary_accuracy: 0.7935 - 331ms/epoch - 14ms/step\n",
      "Epoch 5/100\n",
      "23/23 - 0s - loss: 0.1548 - binary_accuracy: 0.9327 - val_loss: 0.7569 - val_binary_accuracy: 0.7554 - 331ms/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "23/23 - 0s - loss: 0.1467 - binary_accuracy: 0.9451 - val_loss: 0.4716 - val_binary_accuracy: 0.8152 - 336ms/epoch - 15ms/step\n",
      "Epoch 7/100\n",
      "23/23 - 0s - loss: 0.1173 - binary_accuracy: 0.9629 - val_loss: 1.2701 - val_binary_accuracy: 0.7011 - 331ms/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "23/23 - 0s - loss: 0.1094 - binary_accuracy: 0.9602 - val_loss: 0.6753 - val_binary_accuracy: 0.7935 - 327ms/epoch - 14ms/step\n",
      "Epoch 9/100\n",
      "23/23 - 0s - loss: 0.0656 - binary_accuracy: 0.9643 - val_loss: 0.4857 - val_binary_accuracy: 0.8478 - 322ms/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "23/23 - 0s - loss: 0.0608 - binary_accuracy: 0.9794 - val_loss: 0.5093 - val_binary_accuracy: 0.8424 - 330ms/epoch - 14ms/step\n",
      "Epoch 11/100\n",
      "23/23 - 0s - loss: 0.0829 - binary_accuracy: 0.9766 - val_loss: 0.7158 - val_binary_accuracy: 0.8152 - 331ms/epoch - 14ms/step\n",
      "Epoch 12/100\n",
      "23/23 - 0s - loss: 0.0520 - binary_accuracy: 0.9753 - val_loss: 0.7455 - val_binary_accuracy: 0.7880 - 332ms/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "23/23 - 0s - loss: 0.0554 - binary_accuracy: 0.9766 - val_loss: 0.7203 - val_binary_accuracy: 0.8315 - 331ms/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "23/23 - 0s - loss: 0.0574 - binary_accuracy: 0.9766 - val_loss: 1.5054 - val_binary_accuracy: 0.7065 - 325ms/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "23/23 - 0s - loss: 0.0446 - binary_accuracy: 0.9808 - val_loss: 0.4616 - val_binary_accuracy: 0.8696 - 322ms/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "23/23 - 0s - loss: 0.0289 - binary_accuracy: 0.9918 - val_loss: 0.7157 - val_binary_accuracy: 0.8370 - 332ms/epoch - 14ms/step\n",
      "Epoch 17/100\n",
      "23/23 - 0s - loss: 0.0713 - binary_accuracy: 0.9739 - val_loss: 0.5621 - val_binary_accuracy: 0.8587 - 333ms/epoch - 14ms/step\n",
      "Epoch 18/100\n",
      "23/23 - 0s - loss: 0.0525 - binary_accuracy: 0.9821 - val_loss: 0.7139 - val_binary_accuracy: 0.8370 - 332ms/epoch - 14ms/step\n",
      "Epoch 19/100\n",
      "23/23 - 0s - loss: 0.0333 - binary_accuracy: 0.9835 - val_loss: 0.6595 - val_binary_accuracy: 0.8478 - 333ms/epoch - 14ms/step\n",
      "Epoch 20/100\n",
      "23/23 - 0s - loss: 0.0754 - binary_accuracy: 0.9712 - val_loss: 0.7758 - val_binary_accuracy: 0.8261 - 326ms/epoch - 14ms/step\n",
      "Epoch 21/100\n",
      "23/23 - 0s - loss: 0.0485 - binary_accuracy: 0.9739 - val_loss: 0.7255 - val_binary_accuracy: 0.8478 - 323ms/epoch - 14ms/step\n",
      "Epoch 22/100\n",
      "23/23 - 0s - loss: 0.0568 - binary_accuracy: 0.9821 - val_loss: 0.6984 - val_binary_accuracy: 0.8424 - 327ms/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "23/23 - 0s - loss: 0.0402 - binary_accuracy: 0.9863 - val_loss: 1.1202 - val_binary_accuracy: 0.7772 - 334ms/epoch - 15ms/step\n",
      "Epoch 24/100\n",
      "23/23 - 0s - loss: 0.0452 - binary_accuracy: 0.9739 - val_loss: 0.7741 - val_binary_accuracy: 0.8370 - 337ms/epoch - 15ms/step\n",
      "Epoch 25/100\n",
      "23/23 - 0s - loss: 0.0236 - binary_accuracy: 0.9904 - val_loss: 1.0953 - val_binary_accuracy: 0.8207 - 333ms/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "23/23 - 0s - loss: 0.0329 - binary_accuracy: 0.9890 - val_loss: 0.9747 - val_binary_accuracy: 0.8587 - 332ms/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "23/23 - 0s - loss: 0.0184 - binary_accuracy: 0.9918 - val_loss: 0.8473 - val_binary_accuracy: 0.8533 - 319ms/epoch - 14ms/step\n",
      "Epoch 28/100\n",
      "23/23 - 0s - loss: 0.0321 - binary_accuracy: 0.9821 - val_loss: 0.8712 - val_binary_accuracy: 0.8478 - 323ms/epoch - 14ms/step\n",
      "Epoch 29/100\n",
      "23/23 - 0s - loss: 0.0429 - binary_accuracy: 0.9821 - val_loss: 0.6924 - val_binary_accuracy: 0.8804 - 320ms/epoch - 14ms/step\n",
      "Epoch 30/100\n",
      "23/23 - 0s - loss: 0.0373 - binary_accuracy: 0.9808 - val_loss: 0.7574 - val_binary_accuracy: 0.8804 - 347ms/epoch - 15ms/step\n",
      "Epoch 31/100\n",
      "23/23 - 0s - loss: 0.0219 - binary_accuracy: 0.9918 - val_loss: 0.9006 - val_binary_accuracy: 0.8641 - 326ms/epoch - 14ms/step\n",
      "Epoch 32/100\n",
      "23/23 - 0s - loss: 0.0487 - binary_accuracy: 0.9794 - val_loss: 1.2379 - val_binary_accuracy: 0.8207 - 314ms/epoch - 14ms/step\n",
      "Epoch 33/100\n",
      "23/23 - 0s - loss: 0.0308 - binary_accuracy: 0.9863 - val_loss: 0.9928 - val_binary_accuracy: 0.8424 - 317ms/epoch - 14ms/step\n",
      "Epoch 34/100\n",
      "23/23 - 0s - loss: 0.0218 - binary_accuracy: 0.9863 - val_loss: 0.8922 - val_binary_accuracy: 0.8587 - 318ms/epoch - 14ms/step\n",
      "Epoch 35/100\n",
      "23/23 - 0s - loss: 0.0196 - binary_accuracy: 0.9890 - val_loss: 0.9134 - val_binary_accuracy: 0.8587 - 320ms/epoch - 14ms/step\n",
      "Epoch 36/100\n",
      "23/23 - 0s - loss: 0.0313 - binary_accuracy: 0.9890 - val_loss: 1.1481 - val_binary_accuracy: 0.8261 - 326ms/epoch - 14ms/step\n",
      "Epoch 37/100\n",
      "23/23 - 0s - loss: 0.0214 - binary_accuracy: 0.9890 - val_loss: 1.1664 - val_binary_accuracy: 0.8207 - 320ms/epoch - 14ms/step\n",
      "Epoch 38/100\n",
      "23/23 - 0s - loss: 0.0221 - binary_accuracy: 0.9863 - val_loss: 0.9086 - val_binary_accuracy: 0.8750 - 312ms/epoch - 14ms/step\n",
      "Epoch 39/100\n",
      "23/23 - 0s - loss: 0.0465 - binary_accuracy: 0.9849 - val_loss: 1.0286 - val_binary_accuracy: 0.8587 - 323ms/epoch - 14ms/step\n",
      "Epoch 40/100\n",
      "23/23 - 0s - loss: 0.0200 - binary_accuracy: 0.9890 - val_loss: 1.0597 - val_binary_accuracy: 0.8696 - 330ms/epoch - 14ms/step\n",
      "Epoch 41/100\n",
      "23/23 - 0s - loss: 0.0308 - binary_accuracy: 0.9766 - val_loss: 1.1910 - val_binary_accuracy: 0.8587 - 332ms/epoch - 14ms/step\n",
      "Epoch 1/100\n",
      "23/23 - 0s - loss: 0.4188 - binary_accuracy: 0.9299 - val_loss: 0.4349 - val_binary_accuracy: 0.8533 - 364ms/epoch - 16ms/step\n",
      "Epoch 2/100\n",
      "23/23 - 0s - loss: 0.0797 - binary_accuracy: 0.9794 - val_loss: 0.4254 - val_binary_accuracy: 0.8641 - 331ms/epoch - 14ms/step\n",
      "Epoch 3/100\n",
      "23/23 - 0s - loss: 0.0539 - binary_accuracy: 0.9821 - val_loss: 0.4589 - val_binary_accuracy: 0.8859 - 328ms/epoch - 14ms/step\n",
      "Epoch 4/100\n",
      "23/23 - 0s - loss: 0.0515 - binary_accuracy: 0.9890 - val_loss: 0.4937 - val_binary_accuracy: 0.8750 - 328ms/epoch - 14ms/step\n",
      "Epoch 5/100\n",
      "23/23 - 0s - loss: 0.0291 - binary_accuracy: 0.9904 - val_loss: 0.5952 - val_binary_accuracy: 0.8696 - 332ms/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "23/23 - 0s - loss: 0.0515 - binary_accuracy: 0.9808 - val_loss: 0.4291 - val_binary_accuracy: 0.8696 - 352ms/epoch - 15ms/step\n",
      "Epoch 7/100\n",
      "23/23 - 0s - loss: 0.0481 - binary_accuracy: 0.9808 - val_loss: 0.5439 - val_binary_accuracy: 0.8967 - 333ms/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "23/23 - 0s - loss: 0.0260 - binary_accuracy: 0.9890 - val_loss: 0.7657 - val_binary_accuracy: 0.8696 - 332ms/epoch - 14ms/step\n",
      "Epoch 9/100\n",
      "23/23 - 0s - loss: 0.0332 - binary_accuracy: 0.9808 - val_loss: 0.5767 - val_binary_accuracy: 0.8913 - 326ms/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "23/23 - 0s - loss: 0.0222 - binary_accuracy: 0.9918 - val_loss: 0.6190 - val_binary_accuracy: 0.8913 - 328ms/epoch - 14ms/step\n",
      "Epoch 11/100\n",
      "23/23 - 0s - loss: 0.0188 - binary_accuracy: 0.9904 - val_loss: 0.5333 - val_binary_accuracy: 0.9130 - 333ms/epoch - 14ms/step\n",
      "Epoch 12/100\n",
      "23/23 - 0s - loss: 0.0148 - binary_accuracy: 0.9945 - val_loss: 0.6468 - val_binary_accuracy: 0.9022 - 332ms/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "23/23 - 0s - loss: 0.0218 - binary_accuracy: 0.9918 - val_loss: 0.6811 - val_binary_accuracy: 0.8913 - 326ms/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "23/23 - 0s - loss: 0.0116 - binary_accuracy: 0.9945 - val_loss: 0.6892 - val_binary_accuracy: 0.8859 - 318ms/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "23/23 - 0s - loss: 0.0132 - binary_accuracy: 0.9945 - val_loss: 0.7033 - val_binary_accuracy: 0.8804 - 318ms/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "23/23 - 0s - loss: 0.0359 - binary_accuracy: 0.9863 - val_loss: 0.5219 - val_binary_accuracy: 0.9022 - 346ms/epoch - 15ms/step\n",
      "Epoch 17/100\n",
      "23/23 - 0s - loss: 0.0241 - binary_accuracy: 0.9890 - val_loss: 0.6485 - val_binary_accuracy: 0.8750 - 334ms/epoch - 15ms/step\n",
      "Epoch 18/100\n",
      "23/23 - 0s - loss: 0.0356 - binary_accuracy: 0.9863 - val_loss: 0.5926 - val_binary_accuracy: 0.8696 - 317ms/epoch - 14ms/step\n",
      "Epoch 19/100\n",
      "23/23 - 0s - loss: 0.0221 - binary_accuracy: 0.9918 - val_loss: 0.5126 - val_binary_accuracy: 0.8804 - 329ms/epoch - 14ms/step\n",
      "Epoch 20/100\n",
      "23/23 - 0s - loss: 0.0180 - binary_accuracy: 0.9918 - val_loss: 0.4860 - val_binary_accuracy: 0.8804 - 329ms/epoch - 14ms/step\n",
      "Epoch 21/100\n",
      "23/23 - 0s - loss: 0.0165 - binary_accuracy: 0.9918 - val_loss: 0.5826 - val_binary_accuracy: 0.8587 - 316ms/epoch - 14ms/step\n",
      "Epoch 22/100\n",
      "23/23 - 0s - loss: 0.0166 - binary_accuracy: 0.9918 - val_loss: 0.6363 - val_binary_accuracy: 0.8696 - 386ms/epoch - 17ms/step\n",
      "Epoch 23/100\n",
      "23/23 - 0s - loss: 0.0158 - binary_accuracy: 0.9945 - val_loss: 0.6460 - val_binary_accuracy: 0.8696 - 324ms/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "23/23 - 0s - loss: 0.0126 - binary_accuracy: 0.9945 - val_loss: 0.6618 - val_binary_accuracy: 0.8696 - 320ms/epoch - 14ms/step\n",
      "Epoch 25/100\n",
      "23/23 - 0s - loss: 0.0189 - binary_accuracy: 0.9918 - val_loss: 0.6785 - val_binary_accuracy: 0.8913 - 330ms/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "23/23 - 0s - loss: 0.0358 - binary_accuracy: 0.9890 - val_loss: 0.6874 - val_binary_accuracy: 0.8804 - 317ms/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "23/23 - 0s - loss: 0.0120 - binary_accuracy: 0.9945 - val_loss: 0.7361 - val_binary_accuracy: 0.8804 - 317ms/epoch - 14ms/step\n",
      "Epoch 28/100\n",
      "23/23 - 0s - loss: 0.0126 - binary_accuracy: 0.9945 - val_loss: 0.7475 - val_binary_accuracy: 0.8804 - 316ms/epoch - 14ms/step\n",
      "Epoch 29/100\n",
      "23/23 - 0s - loss: 0.0251 - binary_accuracy: 0.9876 - val_loss: 0.7498 - val_binary_accuracy: 0.8913 - 326ms/epoch - 14ms/step\n",
      "Epoch 30/100\n",
      "23/23 - 0s - loss: 0.0135 - binary_accuracy: 0.9945 - val_loss: 0.8484 - val_binary_accuracy: 0.8913 - 334ms/epoch - 15ms/step\n",
      "Epoch 31/100\n",
      "23/23 - 0s - loss: 0.0115 - binary_accuracy: 0.9945 - val_loss: 0.8625 - val_binary_accuracy: 0.8913 - 332ms/epoch - 14ms/step\n",
      "Epoch 32/100\n",
      "23/23 - 0s - loss: 0.0166 - binary_accuracy: 0.9918 - val_loss: 0.8280 - val_binary_accuracy: 0.8913 - 332ms/epoch - 14ms/step\n",
      "Epoch 33/100\n",
      "23/23 - 0s - loss: 0.0333 - binary_accuracy: 0.9863 - val_loss: 0.7701 - val_binary_accuracy: 0.8804 - 327ms/epoch - 14ms/step\n",
      "Epoch 34/100\n",
      "23/23 - 0s - loss: 0.0155 - binary_accuracy: 0.9931 - val_loss: 0.6268 - val_binary_accuracy: 0.9022 - 322ms/epoch - 14ms/step\n",
      "Epoch 35/100\n",
      "23/23 - 0s - loss: 0.0137 - binary_accuracy: 0.9945 - val_loss: 0.6024 - val_binary_accuracy: 0.8804 - 329ms/epoch - 14ms/step\n",
      "Epoch 36/100\n",
      "23/23 - 0s - loss: 0.0115 - binary_accuracy: 0.9945 - val_loss: 0.6416 - val_binary_accuracy: 0.8804 - 326ms/epoch - 14ms/step\n",
      "Epoch 37/100\n",
      "23/23 - 0s - loss: 0.0114 - binary_accuracy: 0.9945 - val_loss: 0.6892 - val_binary_accuracy: 0.8804 - 349ms/epoch - 15ms/step\n",
      "Epoch 1/100\n",
      "23/23 - 0s - loss: 0.0237 - binary_accuracy: 0.9890 - val_loss: 0.6434 - val_binary_accuracy: 0.8913 - 361ms/epoch - 16ms/step\n",
      "Epoch 2/100\n",
      "23/23 - 0s - loss: 0.0182 - binary_accuracy: 0.9876 - val_loss: 1.1383 - val_binary_accuracy: 0.8370 - 323ms/epoch - 14ms/step\n",
      "Epoch 3/100\n",
      "23/23 - 0s - loss: 0.0183 - binary_accuracy: 0.9904 - val_loss: 1.1032 - val_binary_accuracy: 0.8533 - 320ms/epoch - 14ms/step\n",
      "Epoch 4/100\n",
      "23/23 - 0s - loss: 0.0134 - binary_accuracy: 0.9904 - val_loss: 0.9199 - val_binary_accuracy: 0.8913 - 328ms/epoch - 14ms/step\n",
      "Epoch 5/100\n",
      "23/23 - 0s - loss: 0.0129 - binary_accuracy: 0.9931 - val_loss: 0.9276 - val_binary_accuracy: 0.8913 - 330ms/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "23/23 - 0s - loss: 0.0203 - binary_accuracy: 0.9904 - val_loss: 0.8929 - val_binary_accuracy: 0.9022 - 329ms/epoch - 14ms/step\n",
      "Epoch 7/100\n",
      "23/23 - 0s - loss: 0.0173 - binary_accuracy: 0.9876 - val_loss: 0.7924 - val_binary_accuracy: 0.8913 - 333ms/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "23/23 - 0s - loss: 0.0311 - binary_accuracy: 0.9821 - val_loss: 0.9649 - val_binary_accuracy: 0.8913 - 322ms/epoch - 14ms/step\n",
      "Epoch 9/100\n",
      "23/23 - 0s - loss: 0.0270 - binary_accuracy: 0.9918 - val_loss: 0.6417 - val_binary_accuracy: 0.9130 - 323ms/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "23/23 - 0s - loss: 0.0193 - binary_accuracy: 0.9904 - val_loss: 1.0262 - val_binary_accuracy: 0.8587 - 323ms/epoch - 14ms/step\n",
      "Epoch 11/100\n",
      "23/23 - 0s - loss: 0.0132 - binary_accuracy: 0.9890 - val_loss: 1.3551 - val_binary_accuracy: 0.8370 - 321ms/epoch - 14ms/step\n",
      "Epoch 12/100\n",
      "23/23 - 0s - loss: 0.0214 - binary_accuracy: 0.9808 - val_loss: 0.9649 - val_binary_accuracy: 0.8587 - 327ms/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "23/23 - 0s - loss: 0.0168 - binary_accuracy: 0.9890 - val_loss: 0.6872 - val_binary_accuracy: 0.9022 - 322ms/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "23/23 - 0s - loss: 0.0333 - binary_accuracy: 0.9808 - val_loss: 1.1349 - val_binary_accuracy: 0.8424 - 317ms/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "23/23 - 0s - loss: 0.0208 - binary_accuracy: 0.9904 - val_loss: 1.3574 - val_binary_accuracy: 0.8261 - 321ms/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "23/23 - 0s - loss: 0.0260 - binary_accuracy: 0.9821 - val_loss: 0.7691 - val_binary_accuracy: 0.8804 - 319ms/epoch - 14ms/step\n",
      "Epoch 17/100\n",
      "23/23 - 0s - loss: 0.0150 - binary_accuracy: 0.9904 - val_loss: 0.8575 - val_binary_accuracy: 0.8750 - 320ms/epoch - 14ms/step\n",
      "Epoch 18/100\n",
      "23/23 - 0s - loss: 0.0157 - binary_accuracy: 0.9876 - val_loss: 0.7201 - val_binary_accuracy: 0.8913 - 324ms/epoch - 14ms/step\n",
      "Epoch 19/100\n",
      "23/23 - 0s - loss: 0.0165 - binary_accuracy: 0.9918 - val_loss: 1.1259 - val_binary_accuracy: 0.8478 - 320ms/epoch - 14ms/step\n",
      "Epoch 20/100\n",
      "23/23 - 0s - loss: 0.0209 - binary_accuracy: 0.9863 - val_loss: 1.2161 - val_binary_accuracy: 0.8478 - 324ms/epoch - 14ms/step\n",
      "Epoch 21/100\n",
      "23/23 - 0s - loss: 0.0136 - binary_accuracy: 0.9890 - val_loss: 1.1060 - val_binary_accuracy: 0.8478 - 318ms/epoch - 14ms/step\n",
      "Epoch 22/100\n",
      "23/23 - 0s - loss: 0.0132 - binary_accuracy: 0.9904 - val_loss: 1.0409 - val_binary_accuracy: 0.8478 - 320ms/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "23/23 - 0s - loss: 0.0129 - binary_accuracy: 0.9904 - val_loss: 1.0190 - val_binary_accuracy: 0.8587 - 319ms/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "23/23 - 0s - loss: 0.0145 - binary_accuracy: 0.9890 - val_loss: 0.8701 - val_binary_accuracy: 0.8804 - 325ms/epoch - 14ms/step\n",
      "Epoch 25/100\n",
      "23/23 - 0s - loss: 0.0124 - binary_accuracy: 0.9890 - val_loss: 0.8189 - val_binary_accuracy: 0.8804 - 326ms/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "23/23 - 0s - loss: 0.0139 - binary_accuracy: 0.9945 - val_loss: 1.4083 - val_binary_accuracy: 0.8370 - 317ms/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "23/23 - 0s - loss: 0.0412 - binary_accuracy: 0.9821 - val_loss: 0.5916 - val_binary_accuracy: 0.8913 - 313ms/epoch - 14ms/step\n",
      "Epoch 28/100\n",
      "23/23 - 0s - loss: 0.0173 - binary_accuracy: 0.9808 - val_loss: 0.8128 - val_binary_accuracy: 0.9076 - 320ms/epoch - 14ms/step\n",
      "Epoch 29/100\n",
      "23/23 - 0s - loss: 0.0454 - binary_accuracy: 0.9835 - val_loss: 1.0379 - val_binary_accuracy: 0.8424 - 320ms/epoch - 14ms/step\n",
      "Epoch 30/100\n",
      "23/23 - 0s - loss: 0.0325 - binary_accuracy: 0.9835 - val_loss: 1.0977 - val_binary_accuracy: 0.8478 - 322ms/epoch - 14ms/step\n",
      "Epoch 31/100\n",
      "23/23 - 0s - loss: 0.0142 - binary_accuracy: 0.9945 - val_loss: 0.8926 - val_binary_accuracy: 0.8696 - 326ms/epoch - 14ms/step\n",
      "Epoch 32/100\n",
      "23/23 - 0s - loss: 0.0193 - binary_accuracy: 0.9890 - val_loss: 1.1514 - val_binary_accuracy: 0.8315 - 314ms/epoch - 14ms/step\n",
      "Epoch 33/100\n",
      "23/23 - 0s - loss: 0.0148 - binary_accuracy: 0.9918 - val_loss: 0.9300 - val_binary_accuracy: 0.8804 - 381ms/epoch - 17ms/step\n",
      "Epoch 34/100\n",
      "23/23 - 0s - loss: 0.0159 - binary_accuracy: 0.9890 - val_loss: 0.8375 - val_binary_accuracy: 0.8913 - 315ms/epoch - 14ms/step\n",
      "Epoch 35/100\n",
      "23/23 - 0s - loss: 0.0219 - binary_accuracy: 0.9931 - val_loss: 0.8314 - val_binary_accuracy: 0.8913 - 345ms/epoch - 15ms/step\n",
      "Epoch 36/100\n",
      "23/23 - 0s - loss: 0.0132 - binary_accuracy: 0.9890 - val_loss: 0.6484 - val_binary_accuracy: 0.8913 - 331ms/epoch - 14ms/step\n",
      "Epoch 37/100\n",
      "23/23 - 0s - loss: 0.0239 - binary_accuracy: 0.9876 - val_loss: 0.6172 - val_binary_accuracy: 0.9239 - 322ms/epoch - 14ms/step\n",
      "Epoch 38/100\n",
      "23/23 - 0s - loss: 0.0157 - binary_accuracy: 0.9849 - val_loss: 0.7059 - val_binary_accuracy: 0.9130 - 316ms/epoch - 14ms/step\n",
      "Epoch 39/100\n",
      "23/23 - 0s - loss: 0.0171 - binary_accuracy: 0.9931 - val_loss: 0.7459 - val_binary_accuracy: 0.9239 - 318ms/epoch - 14ms/step\n",
      "Epoch 40/100\n",
      "23/23 - 0s - loss: 0.0148 - binary_accuracy: 0.9876 - val_loss: 0.9473 - val_binary_accuracy: 0.8913 - 321ms/epoch - 14ms/step\n",
      "Epoch 41/100\n",
      "23/23 - 0s - loss: 0.0128 - binary_accuracy: 0.9890 - val_loss: 1.0543 - val_binary_accuracy: 0.8804 - 325ms/epoch - 14ms/step\n",
      "Epoch 42/100\n",
      "23/23 - 0s - loss: 0.0351 - binary_accuracy: 0.9890 - val_loss: 0.5737 - val_binary_accuracy: 0.8967 - 333ms/epoch - 14ms/step\n",
      "Epoch 43/100\n",
      "23/23 - 0s - loss: 0.0252 - binary_accuracy: 0.9863 - val_loss: 0.7803 - val_binary_accuracy: 0.8804 - 339ms/epoch - 15ms/step\n",
      "Epoch 44/100\n",
      "23/23 - 0s - loss: 0.0120 - binary_accuracy: 0.9931 - val_loss: 0.8798 - val_binary_accuracy: 0.8696 - 326ms/epoch - 14ms/step\n",
      "Epoch 45/100\n",
      "23/23 - 0s - loss: 0.0179 - binary_accuracy: 0.9863 - val_loss: 0.9743 - val_binary_accuracy: 0.8696 - 327ms/epoch - 14ms/step\n",
      "Epoch 46/100\n",
      "23/23 - 0s - loss: 0.0117 - binary_accuracy: 0.9945 - val_loss: 1.0010 - val_binary_accuracy: 0.8696 - 347ms/epoch - 15ms/step\n",
      "Epoch 47/100\n",
      "23/23 - 0s - loss: 0.0128 - binary_accuracy: 0.9931 - val_loss: 0.9754 - val_binary_accuracy: 0.8641 - 342ms/epoch - 15ms/step\n",
      "Epoch 48/100\n",
      "23/23 - 0s - loss: 0.0174 - binary_accuracy: 0.9835 - val_loss: 0.7986 - val_binary_accuracy: 0.8750 - 342ms/epoch - 15ms/step\n",
      "Epoch 49/100\n",
      "23/23 - 0s - loss: 0.0248 - binary_accuracy: 0.9876 - val_loss: 0.6733 - val_binary_accuracy: 0.8804 - 340ms/epoch - 15ms/step\n",
      "Epoch 50/100\n",
      "23/23 - 0s - loss: 0.0119 - binary_accuracy: 0.9959 - val_loss: 0.7248 - val_binary_accuracy: 0.8804 - 325ms/epoch - 14ms/step\n",
      "Epoch 51/100\n",
      "23/23 - 0s - loss: 0.0140 - binary_accuracy: 0.9890 - val_loss: 0.7890 - val_binary_accuracy: 0.8804 - 327ms/epoch - 14ms/step\n",
      "Epoch 52/100\n",
      "23/23 - 0s - loss: 0.0287 - binary_accuracy: 0.9794 - val_loss: 0.6332 - val_binary_accuracy: 0.8641 - 327ms/epoch - 14ms/step\n",
      "Epoch 53/100\n",
      "23/23 - 0s - loss: 0.0133 - binary_accuracy: 0.9904 - val_loss: 0.6118 - val_binary_accuracy: 0.8696 - 335ms/epoch - 15ms/step\n",
      "Epoch 54/100\n",
      "23/23 - 0s - loss: 0.0132 - binary_accuracy: 0.9931 - val_loss: 0.7103 - val_binary_accuracy: 0.8804 - 334ms/epoch - 15ms/step\n",
      "Epoch 55/100\n",
      "23/23 - 0s - loss: 0.0457 - binary_accuracy: 0.9863 - val_loss: 0.6785 - val_binary_accuracy: 0.8804 - 339ms/epoch - 15ms/step\n",
      "Epoch 56/100\n",
      "23/23 - 0s - loss: 0.0212 - binary_accuracy: 0.9918 - val_loss: 0.4410 - val_binary_accuracy: 0.9022 - 327ms/epoch - 14ms/step\n",
      "Epoch 57/100\n",
      "23/23 - 0s - loss: 0.0136 - binary_accuracy: 0.9918 - val_loss: 0.6341 - val_binary_accuracy: 0.8913 - 325ms/epoch - 14ms/step\n",
      "Epoch 58/100\n",
      "23/23 - 0s - loss: 0.0129 - binary_accuracy: 0.9931 - val_loss: 0.7253 - val_binary_accuracy: 0.8913 - 328ms/epoch - 14ms/step\n",
      "Epoch 59/100\n",
      "23/23 - 0s - loss: 0.0160 - binary_accuracy: 0.9904 - val_loss: 0.7988 - val_binary_accuracy: 0.8913 - 324ms/epoch - 14ms/step\n",
      "Epoch 60/100\n",
      "23/23 - 0s - loss: 0.0135 - binary_accuracy: 0.9876 - val_loss: 0.8483 - val_binary_accuracy: 0.8913 - 320ms/epoch - 14ms/step\n",
      "Epoch 61/100\n",
      "23/23 - 0s - loss: 0.0206 - binary_accuracy: 0.9863 - val_loss: 0.7502 - val_binary_accuracy: 0.8913 - 320ms/epoch - 14ms/step\n",
      "Epoch 62/100\n",
      "23/23 - 0s - loss: 0.0158 - binary_accuracy: 0.9945 - val_loss: 0.7507 - val_binary_accuracy: 0.8913 - 316ms/epoch - 14ms/step\n",
      "Epoch 63/100\n",
      "23/23 - 0s - loss: 0.0158 - binary_accuracy: 0.9863 - val_loss: 0.7010 - val_binary_accuracy: 0.8859 - 325ms/epoch - 14ms/step\n",
      "Epoch 64/100\n",
      "23/23 - 0s - loss: 0.0127 - binary_accuracy: 0.9945 - val_loss: 0.8089 - val_binary_accuracy: 0.8804 - 317ms/epoch - 14ms/step\n",
      "Epoch 65/100\n",
      "23/23 - 0s - loss: 0.0131 - binary_accuracy: 0.9904 - val_loss: 0.8958 - val_binary_accuracy: 0.8804 - 326ms/epoch - 14ms/step\n",
      "Epoch 66/100\n",
      "23/23 - 0s - loss: 0.0123 - binary_accuracy: 0.9876 - val_loss: 1.0268 - val_binary_accuracy: 0.8804 - 321ms/epoch - 14ms/step\n",
      "Epoch 67/100\n",
      "23/23 - 0s - loss: 0.0125 - binary_accuracy: 0.9918 - val_loss: 1.2742 - val_binary_accuracy: 0.8696 - 330ms/epoch - 14ms/step\n",
      "Epoch 68/100\n",
      "23/23 - 0s - loss: 0.0125 - binary_accuracy: 0.9918 - val_loss: 1.3162 - val_binary_accuracy: 0.8696 - 323ms/epoch - 14ms/step\n",
      "Epoch 69/100\n",
      "23/23 - 0s - loss: 0.0116 - binary_accuracy: 0.9890 - val_loss: 1.3023 - val_binary_accuracy: 0.8696 - 316ms/epoch - 14ms/step\n",
      "Epoch 70/100\n",
      "23/23 - 0s - loss: 0.0138 - binary_accuracy: 0.9918 - val_loss: 0.9735 - val_binary_accuracy: 0.8696 - 392ms/epoch - 17ms/step\n",
      "Epoch 71/100\n",
      "23/23 - 0s - loss: 0.0162 - binary_accuracy: 0.9863 - val_loss: 1.0044 - val_binary_accuracy: 0.8696 - 330ms/epoch - 14ms/step\n",
      "Epoch 72/100\n",
      "23/23 - 0s - loss: 0.0114 - binary_accuracy: 0.9904 - val_loss: 1.0875 - val_binary_accuracy: 0.8587 - 321ms/epoch - 14ms/step\n",
      "Epoch 73/100\n",
      "23/23 - 0s - loss: 0.0128 - binary_accuracy: 0.9945 - val_loss: 1.1823 - val_binary_accuracy: 0.8587 - 325ms/epoch - 14ms/step\n",
      "Epoch 74/100\n",
      "23/23 - 0s - loss: 0.0153 - binary_accuracy: 0.9849 - val_loss: 1.0830 - val_binary_accuracy: 0.8804 - 342ms/epoch - 15ms/step\n",
      "Epoch 75/100\n",
      "23/23 - 0s - loss: 0.0243 - binary_accuracy: 0.9863 - val_loss: 1.2336 - val_binary_accuracy: 0.8696 - 329ms/epoch - 14ms/step\n",
      "Epoch 1/100\n",
      "23/23 - 0s - loss: 0.0266 - binary_accuracy: 0.9863 - val_loss: 0.5565 - val_binary_accuracy: 0.9239 - 366ms/epoch - 16ms/step\n",
      "Epoch 2/100\n",
      "23/23 - 0s - loss: 0.0101 - binary_accuracy: 0.9973 - val_loss: 0.4506 - val_binary_accuracy: 0.9130 - 339ms/epoch - 15ms/step\n",
      "Epoch 3/100\n",
      "23/23 - 0s - loss: 0.0123 - binary_accuracy: 0.9918 - val_loss: 0.4825 - val_binary_accuracy: 0.9239 - 335ms/epoch - 15ms/step\n",
      "Epoch 4/100\n",
      "23/23 - 0s - loss: 0.0103 - binary_accuracy: 0.9890 - val_loss: 0.5108 - val_binary_accuracy: 0.9239 - 336ms/epoch - 15ms/step\n",
      "Epoch 5/100\n",
      "23/23 - 0s - loss: 0.0115 - binary_accuracy: 0.9918 - val_loss: 0.5695 - val_binary_accuracy: 0.9239 - 330ms/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "23/23 - 0s - loss: 0.0099 - binary_accuracy: 0.9945 - val_loss: 0.5738 - val_binary_accuracy: 0.9239 - 329ms/epoch - 14ms/step\n",
      "Epoch 7/100\n",
      "23/23 - 0s - loss: 0.0099 - binary_accuracy: 0.9945 - val_loss: 0.5899 - val_binary_accuracy: 0.9239 - 337ms/epoch - 15ms/step\n",
      "Epoch 8/100\n",
      "23/23 - 0s - loss: 0.0127 - binary_accuracy: 0.9918 - val_loss: 0.5830 - val_binary_accuracy: 0.9239 - 334ms/epoch - 15ms/step\n",
      "Epoch 9/100\n",
      "23/23 - 0s - loss: 0.0096 - binary_accuracy: 0.9945 - val_loss: 0.4991 - val_binary_accuracy: 0.9348 - 336ms/epoch - 15ms/step\n",
      "Epoch 10/100\n",
      "23/23 - 0s - loss: 0.0202 - binary_accuracy: 0.9918 - val_loss: 0.5449 - val_binary_accuracy: 0.9348 - 332ms/epoch - 14ms/step\n",
      "Epoch 11/100\n",
      "23/23 - 0s - loss: 0.0110 - binary_accuracy: 0.9931 - val_loss: 0.5248 - val_binary_accuracy: 0.9402 - 329ms/epoch - 14ms/step\n",
      "Epoch 12/100\n",
      "23/23 - 0s - loss: 0.0120 - binary_accuracy: 0.9918 - val_loss: 0.5314 - val_binary_accuracy: 0.9457 - 328ms/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "23/23 - 0s - loss: 0.0098 - binary_accuracy: 0.9945 - val_loss: 0.5363 - val_binary_accuracy: 0.9457 - 335ms/epoch - 15ms/step\n",
      "Epoch 14/100\n",
      "23/23 - 0s - loss: 0.0178 - binary_accuracy: 0.9918 - val_loss: 0.4160 - val_binary_accuracy: 0.9457 - 335ms/epoch - 15ms/step\n",
      "Epoch 15/100\n",
      "23/23 - 0s - loss: 0.0117 - binary_accuracy: 0.9945 - val_loss: 0.4410 - val_binary_accuracy: 0.9457 - 327ms/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "23/23 - 0s - loss: 0.0100 - binary_accuracy: 0.9945 - val_loss: 0.5097 - val_binary_accuracy: 0.9348 - 325ms/epoch - 14ms/step\n",
      "Epoch 17/100\n",
      "23/23 - 0s - loss: 0.0292 - binary_accuracy: 0.9890 - val_loss: 0.9128 - val_binary_accuracy: 0.9239 - 322ms/epoch - 14ms/step\n",
      "Epoch 18/100\n",
      "23/23 - 0s - loss: 0.0113 - binary_accuracy: 0.9945 - val_loss: 0.4686 - val_binary_accuracy: 0.9565 - 319ms/epoch - 14ms/step\n",
      "Epoch 19/100\n",
      "23/23 - 0s - loss: 0.0140 - binary_accuracy: 0.9918 - val_loss: 0.6787 - val_binary_accuracy: 0.9348 - 318ms/epoch - 14ms/step\n",
      "Epoch 20/100\n",
      "23/23 - 0s - loss: 0.0109 - binary_accuracy: 0.9945 - val_loss: 0.8693 - val_binary_accuracy: 0.9239 - 323ms/epoch - 14ms/step\n",
      "Epoch 21/100\n",
      "23/23 - 0s - loss: 0.0098 - binary_accuracy: 0.9945 - val_loss: 0.8542 - val_binary_accuracy: 0.9239 - 327ms/epoch - 14ms/step\n",
      "Epoch 22/100\n",
      "23/23 - 0s - loss: 0.0108 - binary_accuracy: 0.9931 - val_loss: 0.6602 - val_binary_accuracy: 0.9457 - 330ms/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "23/23 - 0s - loss: 0.0199 - binary_accuracy: 0.9890 - val_loss: 0.9429 - val_binary_accuracy: 0.9130 - 320ms/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "23/23 - 0s - loss: 0.0123 - binary_accuracy: 0.9931 - val_loss: 0.9460 - val_binary_accuracy: 0.9130 - 328ms/epoch - 14ms/step\n",
      "Epoch 25/100\n",
      "23/23 - 0s - loss: 0.0087 - binary_accuracy: 0.9945 - val_loss: 0.9146 - val_binary_accuracy: 0.9130 - 326ms/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "23/23 - 0s - loss: 0.0221 - binary_accuracy: 0.9918 - val_loss: 0.6118 - val_binary_accuracy: 0.9348 - 330ms/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "23/23 - 0s - loss: 0.0095 - binary_accuracy: 0.9945 - val_loss: 0.5781 - val_binary_accuracy: 0.9402 - 325ms/epoch - 14ms/step\n",
      "Epoch 1/100\n",
      "23/23 - 0s - loss: 0.0164 - binary_accuracy: 0.9904 - val_loss: 0.7739 - val_binary_accuracy: 0.9022 - 430ms/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "23/23 - 0s - loss: 0.0092 - binary_accuracy: 0.9945 - val_loss: 0.7375 - val_binary_accuracy: 0.9076 - 324ms/epoch - 14ms/step\n",
      "Epoch 3/100\n",
      "23/23 - 0s - loss: 0.0087 - binary_accuracy: 0.9931 - val_loss: 0.7415 - val_binary_accuracy: 0.9239 - 319ms/epoch - 14ms/step\n",
      "Epoch 4/100\n",
      "23/23 - 0s - loss: 0.1052 - binary_accuracy: 0.9890 - val_loss: 0.9772 - val_binary_accuracy: 0.8478 - 331ms/epoch - 14ms/step\n",
      "Epoch 5/100\n",
      "23/23 - 0s - loss: 0.0136 - binary_accuracy: 0.9918 - val_loss: 0.5901 - val_binary_accuracy: 0.8913 - 325ms/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "23/23 - 0s - loss: 0.0110 - binary_accuracy: 0.9945 - val_loss: 0.7227 - val_binary_accuracy: 0.9076 - 323ms/epoch - 14ms/step\n",
      "Epoch 7/100\n",
      "23/23 - 0s - loss: 0.0127 - binary_accuracy: 0.9931 - val_loss: 0.7557 - val_binary_accuracy: 0.9022 - 320ms/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "23/23 - 0s - loss: 0.0339 - binary_accuracy: 0.9876 - val_loss: 1.3716 - val_binary_accuracy: 0.8478 - 317ms/epoch - 14ms/step\n",
      "Epoch 9/100\n",
      "23/23 - 0s - loss: 0.0194 - binary_accuracy: 0.9890 - val_loss: 0.5388 - val_binary_accuracy: 0.9022 - 320ms/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "23/23 - 0s - loss: 0.0096 - binary_accuracy: 0.9945 - val_loss: 0.5413 - val_binary_accuracy: 0.9022 - 322ms/epoch - 14ms/step\n",
      "Epoch 11/100\n",
      "23/23 - 0s - loss: 0.0136 - binary_accuracy: 0.9904 - val_loss: 0.5603 - val_binary_accuracy: 0.8967 - 325ms/epoch - 14ms/step\n",
      "Epoch 12/100\n",
      "23/23 - 0s - loss: 0.0098 - binary_accuracy: 0.9945 - val_loss: 0.6166 - val_binary_accuracy: 0.8967 - 319ms/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "23/23 - 0s - loss: 0.0104 - binary_accuracy: 0.9945 - val_loss: 0.7976 - val_binary_accuracy: 0.9022 - 321ms/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "23/23 - 0s - loss: 0.0117 - binary_accuracy: 0.9918 - val_loss: 1.0252 - val_binary_accuracy: 0.8913 - 316ms/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "23/23 - 0s - loss: 0.0565 - binary_accuracy: 0.9918 - val_loss: 0.4716 - val_binary_accuracy: 0.9022 - 320ms/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "23/23 - 0s - loss: 0.0128 - binary_accuracy: 0.9931 - val_loss: 0.5356 - val_binary_accuracy: 0.8804 - 328ms/epoch - 14ms/step\n",
      "Epoch 17/100\n",
      "23/23 - 0s - loss: 0.0102 - binary_accuracy: 0.9945 - val_loss: 0.7145 - val_binary_accuracy: 0.8750 - 323ms/epoch - 14ms/step\n",
      "Epoch 18/100\n",
      "23/23 - 0s - loss: 0.0103 - binary_accuracy: 0.9959 - val_loss: 0.6661 - val_binary_accuracy: 0.8804 - 321ms/epoch - 14ms/step\n",
      "Epoch 19/100\n",
      "23/23 - 0s - loss: 0.0085 - binary_accuracy: 0.9918 - val_loss: 0.6612 - val_binary_accuracy: 0.8804 - 322ms/epoch - 14ms/step\n",
      "Epoch 20/100\n",
      "23/23 - 0s - loss: 0.0158 - binary_accuracy: 0.9918 - val_loss: 0.8388 - val_binary_accuracy: 0.8696 - 331ms/epoch - 14ms/step\n",
      "Epoch 21/100\n",
      "23/23 - 0s - loss: 0.0087 - binary_accuracy: 0.9931 - val_loss: 0.9314 - val_binary_accuracy: 0.8696 - 330ms/epoch - 14ms/step\n",
      "Epoch 22/100\n",
      "23/23 - 0s - loss: 0.0291 - binary_accuracy: 0.9849 - val_loss: 1.1882 - val_binary_accuracy: 0.8804 - 337ms/epoch - 15ms/step\n",
      "Epoch 23/100\n",
      "23/23 - 0s - loss: 0.0200 - binary_accuracy: 0.9890 - val_loss: 0.7854 - val_binary_accuracy: 0.8696 - 337ms/epoch - 15ms/step\n",
      "Epoch 24/100\n",
      "23/23 - 0s - loss: 0.0093 - binary_accuracy: 0.9931 - val_loss: 0.6534 - val_binary_accuracy: 0.8804 - 336ms/epoch - 15ms/step\n",
      "Epoch 25/100\n",
      "23/23 - 0s - loss: 0.0114 - binary_accuracy: 0.9931 - val_loss: 0.6206 - val_binary_accuracy: 0.8859 - 344ms/epoch - 15ms/step\n",
      "Epoch 26/100\n",
      "23/23 - 0s - loss: 0.0185 - binary_accuracy: 0.9890 - val_loss: 0.7788 - val_binary_accuracy: 0.8696 - 334ms/epoch - 15ms/step\n",
      "Epoch 27/100\n",
      "23/23 - 0s - loss: 0.0120 - binary_accuracy: 0.9890 - val_loss: 0.8746 - val_binary_accuracy: 0.8750 - 334ms/epoch - 15ms/step\n",
      "Epoch 28/100\n",
      "23/23 - 0s - loss: 0.0109 - binary_accuracy: 0.9918 - val_loss: 0.8345 - val_binary_accuracy: 0.8804 - 338ms/epoch - 15ms/step\n",
      "Epoch 29/100\n",
      "23/23 - 0s - loss: 0.0126 - binary_accuracy: 0.9918 - val_loss: 0.6983 - val_binary_accuracy: 0.8804 - 338ms/epoch - 15ms/step\n",
      "Epoch 30/100\n",
      "23/23 - 0s - loss: 0.0108 - binary_accuracy: 0.9945 - val_loss: 0.6866 - val_binary_accuracy: 0.8913 - 336ms/epoch - 15ms/step\n",
      "Epoch 31/100\n",
      "23/23 - 0s - loss: 0.0317 - binary_accuracy: 0.9931 - val_loss: 0.8773 - val_binary_accuracy: 0.8804 - 335ms/epoch - 15ms/step\n",
      "Epoch 32/100\n",
      "23/23 - 0s - loss: 0.0367 - binary_accuracy: 0.9890 - val_loss: 0.4401 - val_binary_accuracy: 0.8859 - 330ms/epoch - 14ms/step\n",
      "Epoch 33/100\n",
      "23/23 - 0s - loss: 0.0199 - binary_accuracy: 0.9904 - val_loss: 0.5674 - val_binary_accuracy: 0.8804 - 329ms/epoch - 14ms/step\n",
      "Epoch 34/100\n",
      "23/23 - 0s - loss: 0.0097 - binary_accuracy: 0.9931 - val_loss: 0.5858 - val_binary_accuracy: 0.8804 - 330ms/epoch - 14ms/step\n",
      "Epoch 35/100\n",
      "23/23 - 0s - loss: 0.0092 - binary_accuracy: 0.9945 - val_loss: 0.6265 - val_binary_accuracy: 0.8804 - 334ms/epoch - 15ms/step\n",
      "Epoch 36/100\n",
      "23/23 - 0s - loss: 0.0177 - binary_accuracy: 0.9904 - val_loss: 0.5873 - val_binary_accuracy: 0.8804 - 326ms/epoch - 14ms/step\n",
      "Epoch 37/100\n",
      "23/23 - 0s - loss: 0.0083 - binary_accuracy: 0.9959 - val_loss: 0.5943 - val_binary_accuracy: 0.8804 - 328ms/epoch - 14ms/step\n",
      "Epoch 38/100\n",
      "23/23 - 0s - loss: 0.0124 - binary_accuracy: 0.9931 - val_loss: 0.6757 - val_binary_accuracy: 0.8804 - 320ms/epoch - 14ms/step\n",
      "Epoch 39/100\n",
      "23/23 - 0s - loss: 0.0078 - binary_accuracy: 0.9959 - val_loss: 0.5727 - val_binary_accuracy: 0.9022 - 384ms/epoch - 17ms/step\n",
      "Epoch 40/100\n",
      "23/23 - 0s - loss: 0.0243 - binary_accuracy: 0.9835 - val_loss: 0.9667 - val_binary_accuracy: 0.8750 - 323ms/epoch - 14ms/step\n",
      "Epoch 41/100\n",
      "23/23 - 0s - loss: 0.0117 - binary_accuracy: 0.9931 - val_loss: 0.7855 - val_binary_accuracy: 0.8750 - 328ms/epoch - 14ms/step\n",
      "Epoch 42/100\n",
      "23/23 - 0s - loss: 0.0115 - binary_accuracy: 0.9918 - val_loss: 0.6752 - val_binary_accuracy: 0.8913 - 338ms/epoch - 15ms/step\n",
      "Epoch 43/100\n",
      "23/23 - 0s - loss: 0.0082 - binary_accuracy: 0.9959 - val_loss: 0.6795 - val_binary_accuracy: 0.8913 - 332ms/epoch - 14ms/step\n",
      "Mean accuracy: 0.9721491217613221\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def fit_and_evaluate(model, X, y, epochs=100):\n",
    "    model.fit(X, y,epochs=epochs, batch_size=16, verbose=2, validation_split=0.2, callbacks = [early_stopping])\n",
    "    _, accuracy = model.evaluate(X, y, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "# Initialize the KFold object\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Loop over the folds and fit/evaluate the model\n",
    "accuracies = []\n",
    "for train_index, val_index in kfold.split(Xtrain):\n",
    "    X_train, X_val = Xtrain[train_index], Xtrain[val_index]\n",
    "    y_train, y_val = Y_train_hot[train_index], Y_train_hot[val_index]\n",
    "    accuracy = fit_and_evaluate(model, X_train, y_train)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Calculate the mean accuracy across all folds\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print('Mean accuracy:', mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81        41\n",
      "           1       0.90      0.92      0.91        83\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       124\n",
      "   macro avg       0.86      0.86      0.86       124\n",
      "weighted avg       0.88      0.88      0.88       124\n",
      " samples avg       0.88      0.88      0.88       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test_hot, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &  precision &  recall &  f1-score &  support \\\\\n",
      "\\midrule\n",
      "\\textbf{0           } &       0.82 &    0.80 &      0.81 &    41.00 \\\\\n",
      "\\textbf{1           } &       0.90 &    0.92 &      0.91 &    83.00 \\\\\n",
      "\\textbf{micro avg   } &       0.88 &    0.88 &      0.88 &   124.00 \\\\\n",
      "\\textbf{macro avg   } &       0.86 &    0.86 &      0.86 &   124.00 \\\\\n",
      "\\textbf{weighted avg} &       0.88 &    0.88 &      0.88 &   124.00 \\\\\n",
      "\\textbf{samples avg } &       0.88 &    0.88 &      0.88 &   124.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_3452\\4095485670.py:3: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(pd.DataFrame(rep_dict).T.to_latex(bold_rows = True, float_format=\"%.2f\" ))\n"
     ]
    }
   ],
   "source": [
    "rep_dict = classification_report(Y_test_hot, predictions, output_dict=True)\n",
    "\n",
    "print(pd.DataFrame(rep_dict).T.to_latex(bold_rows = True, float_format=\"%.2f\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_test.png', show_shapes=True, rankdir=\"LR\", layer_range=[\"embedding\", \"dropout_1\"], show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, to_file='model_test.png', show_shapes=True, rankdir=\"LR\", layer_range=[\"dense\", \"dense_3\"], show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of types extracted is: 4\n",
      "[['awful', 'sound', 'terrible', 'not_understand']]\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [\"Awful, the sound is terrible and it doesn't understand me\"]\n",
    "review, temp = tokenize_list_of_text(x, custom_stopwords, False, 2)\n",
    "print(temp)\n",
    "seq_review = t.texts_to_sequences(temp)\n",
    "padded_review = pad_sequences(seq_review, maxlen=max_length, padding='post')\n",
    "preds = np.round(model.predict(padded_review))\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9984378 , 0.00148084]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1, 0] is equal to negative label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43973268aa23c7cf4b4cafe0e819fac9b2412fcc991a21988492c3271a4e3f9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
