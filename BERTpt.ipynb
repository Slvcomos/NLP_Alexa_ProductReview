{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KyDjHbJXE-v",
        "outputId": "8a64d0f2-1c4d-4589-eb02-90cc85fed9dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install transformers\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "from transformers import BertForSequenceClassification\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SufvA3i6Ylxm",
        "outputId": "882a3f0a-0d94-4e21-e8f8-26db870d9b62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using PyTorch version: 1.13.1+cu116 Device: cuda [Tesla T4]\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    devicename = '['+torch.cuda.get_device_name(0)+']'\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    devicename = \"\"\n",
        "    \n",
        "print('Using PyTorch version:', torch.__version__,\n",
        "      'Device:', device, devicename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "8lbiJDUPYuTm"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"amazon_alexa.tsv\", sep = \"\\t\", encoding = \"utf-8\")\n",
        "dataset.dropna(inplace = True)\n",
        "dataset.drop(dataset[dataset.rating == 3].index, inplace=True)\n",
        "dataset.drop_duplicates(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi9kcXGsG5lU",
        "outputId": "7b5cece0-6705-44c3-fa9d-c6c5e47e57d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2322, 5)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "U160V_vx9wMT"
      },
      "outputs": [],
      "source": [
        "X = np.array(dataset[\"verified_reviews\"].values).reshape(-1, 1)\n",
        "y = list(dataset[\"feedback\"].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bmgxg4I2Gs4S",
        "outputId": "0f8ce90c-38a1-4422-d125-41fcb0e42090"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2322"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHk4bBD08-x3",
        "outputId": "ff7daada-07ca-40ee-bf11-18377fc1751a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({1: 442, 0: 221})\n"
          ]
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "\n",
        "undersampler = RandomUnderSampler(sampling_strategy=0.5, random_state = 0)\n",
        "\n",
        "X, y = undersampler.fit_resample(X, y)\n",
        "\n",
        "\n",
        "print('Resampled dataset shape %s' % Counter(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "0GFlQ_Lr_Pgy"
      },
      "outputs": [],
      "source": [
        "X_temp = []\n",
        "\n",
        "for rev in X:\n",
        "  X_temp.append(rev[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "hNd47_lAYwEs"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X_temp, y, test_size=0.20, random_state=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "UEwGpQlSYzvh"
      },
      "outputs": [],
      "source": [
        "sentences_train = [\"[CLS] \" + s for s in X_train]\n",
        "sentences_test = [\"[CLS] \" + s for s in X_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7qud3-OY1uC",
        "outputId": "3b36c6ef-5c1b-4255-aff0-905e4c6a0c9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BERTMODEL = \"bert-base-uncased\"\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(BERTMODEL,\n",
        "                                          do_lower_case=True)\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZOKTDWlY2x8",
        "outputId": "b535a604-3377-4e13-c4a4-4cde3db10c2d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 530/530 [00:00<00:00, 1524.46it/s]\n",
            "100%|██████████| 133/133 [00:00<00:00, 1559.17it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "tokenized_train = [tokenizer.tokenize(s) for s in tqdm(sentences_train)]\n",
        "tokenized_test  = [tokenizer.tokenize(s) for s in tqdm(sentences_test)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXO3y22KY5BQ",
        "outputId": "79a97f54-0bc2-4e33-d4f7-503893976890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The full tokenized first training sentence:\n",
            "['[CLS]', 'received', 'the', 'wrong', 'product', '.', '.', '.', 'was', 'so', 'excited', 'to', 'install', 'it', '.', '.', '.', 'all', 'excitement', 'gone', '.', 'thank', 'you', 'amazon', '.']\n"
          ]
        }
      ],
      "source": [
        "print (\"The full tokenized first training sentence:\")\n",
        "print (tokenized_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNUtvYudY71J",
        "outputId": "34bcb0c2-f699-4da8-d110-6abfe3879bda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The truncated tokenized first training sentence:\n",
            "['[CLS]', 'received', 'the', 'wrong', 'product', '.', '.', '.', 'was', 'so', 'excited', 'to', 'install', 'it', '.', '.', '.', 'all', 'excitement', 'gone', '.', 'thank', 'you', 'amazon', '.', 'SEP']\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN_TRAIN, MAX_LEN_TEST = 512, 512\n",
        "\n",
        "tokenized_train = [t[:(MAX_LEN_TRAIN-1)]+['SEP'] for t in tokenized_train]\n",
        "tokenized_test  = [t[:(MAX_LEN_TEST-1)]+['SEP'] for t in tokenized_test]\n",
        "\n",
        "print (\"The truncated tokenized first training sentence:\")\n",
        "print (tokenized_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR8nVt6SY8sE",
        "outputId": "2a1c5d83-116c-46f3-dbba-9751ad3880e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The indices of the first training sentence:\n",
            "[  101  2363  1996  3308  4031  1012  1012  1012  2001  2061  7568  2000\n",
            " 16500  2009  1012  1012  1012  2035  8277  2908  1012  4067  2017  9733\n",
            "  1012   100     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n"
          ]
        }
      ],
      "source": [
        "ids_train = [tokenizer.convert_tokens_to_ids(t) for t in tokenized_train]\n",
        "ids_train = np.array([np.pad(i, (0, MAX_LEN_TRAIN-len(i)),\n",
        "                             mode='constant') for i in ids_train])\n",
        "\n",
        "ids_test = [tokenizer.convert_tokens_to_ids(t) for t in tokenized_test]\n",
        "ids_test = np.array([np.pad(i, (0, MAX_LEN_TEST-len(i)),\n",
        "                            mode='constant') for i in ids_test])\n",
        "\n",
        "print (\"The indices of the first training sentence:\")\n",
        "print (ids_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "zNb-UNnyY-lD"
      },
      "outputs": [],
      "source": [
        "amasks_train, amasks_test = [], []\n",
        "\n",
        "for seq in ids_train:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  amasks_train.append(seq_mask)\n",
        "\n",
        "for seq in ids_test:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  amasks_test.append(seq_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "oMQj1fVyZBJk"
      },
      "outputs": [],
      "source": [
        "(train_inputs, validation_inputs,\n",
        " train_labels, validation_labels) = train_test_split(ids_train, Y_train,\n",
        "                                                     random_state=42,\n",
        "                                                     test_size=0.1)\n",
        "(train_masks, validation_masks,\n",
        " _, _) = train_test_split(amasks_train, ids_train,\n",
        "                          random_state=42, test_size=0.1)\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks  = torch.tensor(train_masks)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks  = torch.tensor(validation_masks)\n",
        "test_inputs = torch.tensor(ids_test)\n",
        "test_labels = torch.tensor(Y_test)\n",
        "test_masks  = torch.tensor(amasks_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "NKCqVWajZB9n"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import (TensorDataset, DataLoader,\n",
        "                              RandomSampler, SequentialSampler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT1dwWYpZDef",
        "outputId": "dfb5b975-817c-47f2-83b2-267606897fa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets:\n",
            "Train: 477 documents\n",
            "Validation: 53 documents\n",
            "Test: 133 documents\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "print('Datasets:')\n",
        "print('Train: ', end=\"\")\n",
        "train_data = TensorDataset(train_inputs, train_masks,\n",
        "                           train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler,\n",
        "                              batch_size=BATCH_SIZE)\n",
        "print(len(train_data), 'documents')\n",
        "\n",
        "print('Validation: ', end=\"\")\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks,\n",
        "                                validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data,\n",
        "                                   sampler=validation_sampler,\n",
        "                                   batch_size=BATCH_SIZE)\n",
        "print(len(validation_data), 'documents')\n",
        "\n",
        "print('Test: ', end=\"\")\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler,\n",
        "                             batch_size=BATCH_SIZE)\n",
        "print(len(test_data), 'documents')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qarW0glFZF6h",
        "outputId": "00b4f790-c03d-4214-9c7d-6210b9fa20fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pretrained BERT model \"bert-base-uncased\" loaded\n"
          ]
        }
      ],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(BERTMODEL,\n",
        "                                                      num_labels=2)\n",
        "model.cuda()\n",
        "print('Pretrained BERT model \"{}\" loaded'.format(BERTMODEL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHOZC_BbZGpZ",
        "outputId": "ebd8757b-90f4-4779-b463-2f33d82de337"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 4\n",
        "WEIGHT_DECAY = 0.01\n",
        "LR = 2e-5\n",
        "WARMUP_STEPS =int(0.2*len(train_dataloader))\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters()\n",
        "                if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay': WEIGHT_DECAY},\n",
        "    {'params': [p for n, p in model.named_parameters()\n",
        "                if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=LR, eps=1e-8)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS,\n",
        "                                 num_training_steps =len(train_dataloader)*EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "SauJFv6KZKm3"
      },
      "outputs": [],
      "source": [
        "def train(epoch, loss_vector=None, log_interval=200):\n",
        "      # Set model to training mode\n",
        "  model.train()\n",
        "\n",
        "  # Loop over each batch from the training set\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "    # Copy data to GPU if needed\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # Zero gradient buffers\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(b_input_ids, token_type_ids=None,\n",
        "                    attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "    loss = outputs[0]\n",
        "    if loss_vector is not None:\n",
        "        loss_vector.append(loss.item())\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update weights\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    if step % log_interval == 0:\n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, step * len(b_input_ids),\n",
        "                len(train_dataloader.dataset),\n",
        "                100. * step / len(train_dataloader), loss))\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "\n",
        "    n_correct, n_all = 0, 0\n",
        "    predicted_labels = []\n",
        "\n",
        "    for batch in loader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "            logits = outputs[0]\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        predictions = np.argmax(logits, axis=1)\n",
        "        predicted_labels.append(predictions)\n",
        "\n",
        "        labels = b_labels.to('cpu').numpy()\n",
        "        n_correct += np.sum(predictions == labels)\n",
        "        n_all += len(labels)\n",
        "\n",
        "    print('Accuracy: [{}/{}] {:.4f}'.format(n_correct, n_all, n_correct/n_all))\n",
        "    return np.concatenate(predicted_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH6o-NgpZO9K",
        "outputId": "711df058-c387-4b48-a9e9-009d89d2bde6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Epoch: 1 [0/477 (0%)]\tLoss: 0.766362\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [43/53] 0.8113\n",
            "\n",
            "Train Epoch: 2 [0/477 (0%)]\tLoss: 0.346527\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [47/53] 0.8868\n",
            "\n",
            "Train Epoch: 3 [0/477 (0%)]\tLoss: 0.093722\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [47/53] 0.8868\n",
            "\n",
            "Train Epoch: 4 [0/477 (0%)]\tLoss: 0.274144\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [48/53] 0.9057\n"
          ]
        }
      ],
      "source": [
        "train_lossv = []\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    print()\n",
        "    train(epoch, train_lossv)\n",
        "    print('\\nValidation set:')\n",
        "    evaluate(validation_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwuRPa69ZkT3",
        "outputId": "9258ac50-e55e-4616-c48b-c3b7165ade75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set:\n",
            "Accuracy: [125/133] 0.9398\n"
          ]
        }
      ],
      "source": [
        "print('Test set:')\n",
        "predictions = evaluate(test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWXRPTZodi6v",
        "outputId": "c99da75f-66f7-468d-9be3-b00cda8f3154"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90        42\n",
            "           1       0.96      0.96      0.96        91\n",
            "\n",
            "    accuracy                           0.94       133\n",
            "   macro avg       0.93      0.93      0.93       133\n",
            "weighted avg       0.94      0.94      0.94       133\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1mxoDIlOq7B6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "43973268aa23c7cf4b4cafe0e819fac9b2412fcc991a21988492c3271a4e3f9b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
