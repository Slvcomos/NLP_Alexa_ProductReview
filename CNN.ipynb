{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, Conv1D, MaxPooling1D, Flatten\n",
    "import pandas as pd\n",
    "from preprocessing import *\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.phrases import Phrases\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_twitter_25 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pre trained embeddings, this can take some minutes...\n",
      "loading complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"loading pre trained embeddings, this can take some minutes...\")\n",
    "glove_twitter_25 = KeyedVectors.load_word2vec_format('glove-twitter-25.txt', binary=False)\n",
    "print(\"loading complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3150, 5)\n",
      "(3150, 5)\n",
      "(2998, 5)\n",
      "(2322, 5)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"amazon_alexa.tsv\", sep = \"\\t\", encoding = \"utf-8\")\n",
    "print(dataset.shape)\n",
    "dataset.dropna(inplace = True)\n",
    "print(dataset.shape)\n",
    "dataset.drop(dataset[dataset.rating == 3].index, inplace=True)\n",
    "print(dataset.shape)\n",
    "dataset.drop_duplicates(inplace = True)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(dataset[\"verified_reviews\"].values).reshape(-1, 1)\n",
    "y = list(dataset[\"feedback\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 442, 0: 221})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "undersampler = RandomUnderSampler(sampling_strategy=0.5, random_state = 0)\n",
    "\n",
    "X, y = undersampler.fit_resample(X, y)\n",
    "\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = []\n",
    "\n",
    "for rev in X:\n",
    "  X_temp.append(rev[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of types extracted is: 1810\n"
     ]
    }
   ],
   "source": [
    "new_text, new_sent_tok = tokenize_list_of_text(X_temp, custom_stopwords, False, pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_cleaning(new_sent_tok, n):\n",
    "    \n",
    "    tot_tokens = []\n",
    "\n",
    "    for sent in new_sent_tok:\n",
    "        for tok in sent:\n",
    "            tot_tokens.append(tok)\n",
    "\n",
    "    freqs = nltk.FreqDist(tot_tokens)\n",
    "    cleaned_reviews = []\n",
    "\n",
    "    for sent in new_sent_tok:\n",
    "        clean_sent = []\n",
    "        for tok in sent:\n",
    "            if freqs[tok] > n:\n",
    "                clean_sent.append(tok)\n",
    "        cleaned_reviews.append(clean_sent)\n",
    "\n",
    "    return cleaned_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews = frequency_cleaning(new_sent_tok, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['little', 'feature']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = Phrases(cleaned_reviews, scoring=\"npmi\", threshold=0.60) #estrae le collocazioni tramite PMI\n",
    "bigrams[cleaned_reviews][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(bigrams[cleaned_reviews], y, test_size=0.20, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(X_train)\n",
    "X_train_encoded = t.texts_to_sequences(X_train)\n",
    "max_length = len(max(bigrams[cleaned_reviews], key = len))\n",
    "Xtrain = pad_sequences(X_train_encoded, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_encoded = t.texts_to_sequences(X_test)\n",
    "Xtest = pad_sequences(X_test_encoded, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 325, 0: 153})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "undersampler_nn = TomekLinks(sampling_strategy=\"all\") # use tomeLinks to remove ambiguous data through nearest neighbours\n",
    "\n",
    "\n",
    "# Fit and transform the X and y data\n",
    "X_train_resampled, y_train_resampled = undersampler_nn.fit_resample(Xtrain, Y_train)\n",
    "\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_train_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "Y_train_hot = to_categorical(y_train_resampled)\n",
    "Y_test_hot = to_categorical(Y_test)\n",
    "Y_train_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 98, 300)           185700    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 98, 300)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 89, 16)            48016     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 44, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 704)               0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 704)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 300)               211500    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 150)               45150     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               15100     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 505,668\n",
      "Trainable params: 505,668\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='binary_accuracy', patience=25)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length, trainable = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=16, kernel_size=10, activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 3s - loss: 0.6574 - binary_accuracy: 0.6674 - val_loss: 0.6714 - val_binary_accuracy: 0.6979 - 3s/epoch - 182ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 1s - loss: 0.6406 - binary_accuracy: 0.6802 - val_loss: 0.6004 - val_binary_accuracy: 0.6875 - 756ms/epoch - 54ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 1s - loss: 0.6008 - binary_accuracy: 0.6837 - val_loss: 0.5958 - val_binary_accuracy: 0.7396 - 782ms/epoch - 56ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 1s - loss: 0.5495 - binary_accuracy: 0.7605 - val_loss: 0.6360 - val_binary_accuracy: 0.7292 - 715ms/epoch - 51ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 1s - loss: 0.4586 - binary_accuracy: 0.8326 - val_loss: 0.6518 - val_binary_accuracy: 0.7083 - 636ms/epoch - 45ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 1s - loss: 0.3188 - binary_accuracy: 0.8837 - val_loss: 0.7454 - val_binary_accuracy: 0.7500 - 642ms/epoch - 46ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 1s - loss: 0.2263 - binary_accuracy: 0.9163 - val_loss: 0.7030 - val_binary_accuracy: 0.7708 - 624ms/epoch - 45ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 1s - loss: 0.1436 - binary_accuracy: 0.9395 - val_loss: 0.7821 - val_binary_accuracy: 0.7708 - 649ms/epoch - 46ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 1s - loss: 0.1095 - binary_accuracy: 0.9349 - val_loss: 0.8243 - val_binary_accuracy: 0.7708 - 741ms/epoch - 53ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 1s - loss: 0.0816 - binary_accuracy: 0.9616 - val_loss: 1.0048 - val_binary_accuracy: 0.7708 - 740ms/epoch - 53ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 1s - loss: 0.0899 - binary_accuracy: 0.9535 - val_loss: 0.9331 - val_binary_accuracy: 0.7917 - 801ms/epoch - 57ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 1s - loss: 0.0693 - binary_accuracy: 0.9733 - val_loss: 0.8692 - val_binary_accuracy: 0.7500 - 636ms/epoch - 45ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 1s - loss: 0.0548 - binary_accuracy: 0.9767 - val_loss: 1.0253 - val_binary_accuracy: 0.7708 - 660ms/epoch - 47ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 1s - loss: 0.0573 - binary_accuracy: 0.9616 - val_loss: 1.0345 - val_binary_accuracy: 0.7708 - 764ms/epoch - 55ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 1s - loss: 0.0533 - binary_accuracy: 0.9581 - val_loss: 1.1362 - val_binary_accuracy: 0.7708 - 732ms/epoch - 52ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 1s - loss: 0.0515 - binary_accuracy: 0.9686 - val_loss: 1.1538 - val_binary_accuracy: 0.7917 - 642ms/epoch - 46ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 1s - loss: 0.0484 - binary_accuracy: 0.9709 - val_loss: 1.2881 - val_binary_accuracy: 0.7917 - 719ms/epoch - 51ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 1s - loss: 0.0530 - binary_accuracy: 0.9605 - val_loss: 1.4668 - val_binary_accuracy: 0.7917 - 626ms/epoch - 45ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 1s - loss: 0.0504 - binary_accuracy: 0.9709 - val_loss: 2.4755 - val_binary_accuracy: 0.7292 - 671ms/epoch - 48ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 1s - loss: 0.0476 - binary_accuracy: 0.9581 - val_loss: 2.3850 - val_binary_accuracy: 0.7500 - 649ms/epoch - 46ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 1s - loss: 0.0457 - binary_accuracy: 0.9651 - val_loss: 2.4421 - val_binary_accuracy: 0.7708 - 639ms/epoch - 46ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 1s - loss: 0.0468 - binary_accuracy: 0.9721 - val_loss: 2.2250 - val_binary_accuracy: 0.7292 - 692ms/epoch - 49ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 1s - loss: 0.0466 - binary_accuracy: 0.9698 - val_loss: 2.1533 - val_binary_accuracy: 0.7708 - 793ms/epoch - 57ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 1s - loss: 0.0497 - binary_accuracy: 0.9651 - val_loss: 1.9642 - val_binary_accuracy: 0.7708 - 748ms/epoch - 53ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 1s - loss: 0.0539 - binary_accuracy: 0.9709 - val_loss: 1.8927 - val_binary_accuracy: 0.7083 - 669ms/epoch - 48ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 1s - loss: 0.0448 - binary_accuracy: 0.9721 - val_loss: 2.0102 - val_binary_accuracy: 0.7708 - 632ms/epoch - 45ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 1s - loss: 0.0453 - binary_accuracy: 0.9605 - val_loss: 2.1219 - val_binary_accuracy: 0.7708 - 616ms/epoch - 44ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 1s - loss: 0.0429 - binary_accuracy: 0.9640 - val_loss: 2.2752 - val_binary_accuracy: 0.7708 - 617ms/epoch - 44ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 1s - loss: 0.0424 - binary_accuracy: 0.9674 - val_loss: 2.3106 - val_binary_accuracy: 0.7708 - 624ms/epoch - 45ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 1s - loss: 0.0424 - binary_accuracy: 0.9674 - val_loss: 2.3249 - val_binary_accuracy: 0.7708 - 642ms/epoch - 46ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 1s - loss: 0.0435 - binary_accuracy: 0.9663 - val_loss: 2.3186 - val_binary_accuracy: 0.7917 - 612ms/epoch - 44ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 1s - loss: 0.0432 - binary_accuracy: 0.9616 - val_loss: 2.5570 - val_binary_accuracy: 0.7708 - 619ms/epoch - 44ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 1s - loss: 0.0437 - binary_accuracy: 0.9628 - val_loss: 2.5558 - val_binary_accuracy: 0.7708 - 629ms/epoch - 45ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 1s - loss: 0.0421 - binary_accuracy: 0.9640 - val_loss: 2.6298 - val_binary_accuracy: 0.7708 - 600ms/epoch - 43ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 1s - loss: 0.0406 - binary_accuracy: 0.9721 - val_loss: 2.6828 - val_binary_accuracy: 0.7708 - 618ms/epoch - 44ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 1s - loss: 0.0417 - binary_accuracy: 0.9721 - val_loss: 2.8218 - val_binary_accuracy: 0.7708 - 612ms/epoch - 44ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 1s - loss: 0.0438 - binary_accuracy: 0.9698 - val_loss: 2.4798 - val_binary_accuracy: 0.7708 - 619ms/epoch - 44ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 1s - loss: 0.0475 - binary_accuracy: 0.9674 - val_loss: 2.7737 - val_binary_accuracy: 0.7917 - 603ms/epoch - 43ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5e52a32e0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile network\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "# fit network\n",
    "model.fit(X_train_resampled, Y_train_hot, epochs=100, verbose=2, validation_split=0.1, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79        42\n",
      "           1       0.93      0.87      0.90        91\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       133\n",
      "   macro avg       0.83      0.86      0.84       133\n",
      "weighted avg       0.87      0.86      0.86       133\n",
      " samples avg       0.86      0.86      0.86       133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test_hot, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "print(gensim.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43973268aa23c7cf4b4cafe0e819fac9b2412fcc991a21988492c3271a4e3f9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
