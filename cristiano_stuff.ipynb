{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import gensim.downloader as api\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = ['echo', 'alexa', \"alexia\", 'dot', \"star\", 'amazon', 'prime', '2nd', 'generation', \"fire\", \"stick\", \"firestick\", \"skype\", \"facetime\", '1st', '3rd', '4th', '5th', \"hub\", \"hulu\", 'google', 'netflix', \"sony\", 'youtube', 'philip', 'tp-link', 'fourth', 'roku', \"siri\", 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"...\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n",
    "\n",
    "def negation_handler(sentence):\t\n",
    "\n",
    "    \"\"\"Handle negations using WordNet. See https://github.com/UtkarshRedd/Negation_handling for a clear explenation.\"\"\"\n",
    "\n",
    "    temp = int(0)\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i-1] in ['not',\"n't\", \"no\", \"without\"]:\n",
    "            antonyms = []\n",
    "            for syn in wordnet.synsets(sentence[i]):\n",
    "                syns = wordnet.synsets(sentence[i])\n",
    "                w1 = syns[0].name()\n",
    "                temp = 0\n",
    "                for l in syn.lemmas():\n",
    "                    if l.antonyms():\n",
    "                        antonyms.append(l.antonyms()[0].name())\n",
    "                max_dissimilarity = 0\n",
    "                for ant in antonyms:\n",
    "                    syns = wordnet.synsets(ant)\n",
    "                    w2 = syns[0].name()\n",
    "                    syns = wordnet.synsets(sentence[i])\n",
    "                    w1 = syns[0].name()\n",
    "                    word1 = wordnet.synset(w1)\n",
    "                    word2 = wordnet.synset(w2)\n",
    "                    if isinstance(word1.wup_similarity(word2), float) or isinstance(word1.wup_similarity(word2), int):\n",
    "                        temp = 1 - word1.wup_similarity(word2)\n",
    "                    if temp>max_dissimilarity:\n",
    "                        max_dissimilarity = temp\n",
    "                        antonym_max = ant\n",
    "                        sentence[i] = antonym_max\n",
    "                        sentence[i-1] = ''\n",
    "    while '' in sentence:\n",
    "        sentence.remove('')\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Love my Echo!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Loved it!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Walnut Finish</td>\n",
       "      <td>Sometimes while playing a game, you can answer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>I have had a lot of fun with this thing. My 4 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Music</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating       date         variation  \\\n",
       "0       5  31-Jul-18  Charcoal Fabric    \n",
       "1       5  31-Jul-18  Charcoal Fabric    \n",
       "2       4  31-Jul-18    Walnut Finish    \n",
       "3       5  31-Jul-18  Charcoal Fabric    \n",
       "4       5  31-Jul-18  Charcoal Fabric    \n",
       "\n",
       "                                    verified_reviews  feedback  \n",
       "0                                      Love my Echo!         1  \n",
       "1                                          Loved it!         1  \n",
       "2  Sometimes while playing a game, you can answer...         1  \n",
       "3  I have had a lot of fun with this thing. My 4 ...         1  \n",
       "4                                              Music         1  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"amazon_alexa.tsv\", sep = \"\\t\")\n",
    "dataset.drop(dataset[dataset.rating == 3].index, inplace=True) #droppa recensioni con 3 stelle\n",
    "# dataset.drop(dataset[dataset.rating == 4].index, inplace=True) #droppa recensioni con 4 stelle\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_duplicates = dataset.drop_duplicates(subset=\"verified_reviews\")\n",
    "df_no_duplicates[df_no_duplicates[\"feedback\"] == 1]\n",
    "index_positive = list(dataset[dataset[\"feedback\"] == 1].index)\n",
    "dataset.drop(labels=index_positive, inplace = True)\n",
    "dataset = pd.concat([dataset, df_no_duplicates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1990\n",
      "0     463\n",
      "Name: feedback, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"feedback\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CREAZIONE DI UN SAMPLE DATASET BILANCIATO\n",
    "# prende le prime n recensioni positive di lunghezza maggiore, dove n Ã¨ il numero di recensioni negative\n",
    "def create_balanced_dataset(dataset):\n",
    "    \"\"\"Bilancia il dataset uniformando il numero di recensioni negative e positive. Prende in input il dataset\"\"\"\n",
    "    reviews_1 = list(dataset[dataset[\"feedback\"] == 1][\"verified_reviews\"])\n",
    "    reviews_0 = list(dataset[dataset[\"feedback\"] == 0][\"verified_reviews\"])\n",
    "    reviews_1.sort(key=len, reverse = True)\n",
    "    sample_1 = reviews_1[:len(reviews_0)]\n",
    "    verified_reviews_sample = []\n",
    "    feedback_sample = []\n",
    "    verified_reviews_sample.extend(sample_1)\n",
    "    verified_reviews_sample.extend(reviews_0)\n",
    "    feedback_sample.extend([1 for i in range(len(sample_1))])\n",
    "    feedback_sample.extend([0 for i in range(len(reviews_0))])\n",
    "    dataset = pd.DataFrame({\"verified_reviews\":verified_reviews_sample, \"feedback\": feedback_sample})\n",
    "    print(dataset[\"feedback\"].value_counts())\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# dataset = create_balanced_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"\n",
    "    return WORDNET POS compliance to WORDENT lemmatization (a,n,r,v).\n",
    "    This was done in order to have compatibility with the wordnet lemmatizer.\n",
    "    For example the pos \"JJ\" is transformed in \"a\".\n",
    "    \"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return \"a\"\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return \"v\"\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return \"n\"\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return \"r\"\n",
    "    else:\n",
    "        return \"n\"\n",
    "        \n",
    "pos_list = [\"JJ\", \"JJR\", \"JJS\", \"RB\", \"RBR\", \"RBS\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"]\n",
    "# pos_list = [\"JJ\", \"JJR\", \"JJS\", \"RB\", \"RBR\", \"RBS\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\", \"NN\", \"NNS\"]\n",
    "\n",
    "def tokenize_list_of_text(list_of_text, custom_stopwords = [], pos_filter = False, pos_list = []):\n",
    "    \"\"\"Tokenizza tutte le recensioni, pulisce da stopwords, elimina token <= 2 caratteri e lemmatizza.\n",
    "    Ritorna sia il la lista tokenizzata ma come stringa sia come lista di tokens, dunque ritorna due elementi\"\"\"\n",
    "\n",
    "    tokenizer = nltk.tokenize.TweetTokenizer()\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    detokenizer = TreebankWordDetokenizer()\n",
    "\n",
    "    tokenized_reviews = []\n",
    "    sent_tokenized_reviews = []\n",
    "    pos_reviews = []\n",
    "    for review in list_of_text: #pulisce le recensioni\n",
    "        review = re.sub(r'\\d+', '', review) # elimina i numeri\n",
    "        clean_text = \"\"\n",
    "        tokens = nltk.tokenize.word_tokenize(review, language='english', preserve_line=False)\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "        tokens_pos = pos_tag(tokens)\n",
    "        lemmatized_tokens = [(lemmatizer.lemmatize(w, get_wordnet_pos(pos)), pos) for w, pos in tokens_pos]\n",
    "        if pos_filter:\n",
    "            clean_tokens = [w for w, pos in lemmatized_tokens if w not in string.punctuation and len(w)>2 and w not in custom_stopwords and pos in pos_list]\n",
    "        else:\n",
    "            clean_tokens = [w for w, pos in lemmatized_tokens if w not in string.punctuation and len(w)>2 and w not in custom_stopwords]\n",
    "        clean_tokens = negation_handler(clean_tokens)\n",
    "        sent_tokenized_reviews.append(clean_tokens)\n",
    "        tokenized_reviews.append(detokenizer.detokenize(clean_tokens))\n",
    "    \n",
    "    n_tokens = []\n",
    "    for sent in sent_tokenized_reviews:\n",
    "        for w in sent:\n",
    "            n_tokens.append(w)\n",
    "    print(\"total number of tokens extracted are:\", len(set(n_tokens)))\n",
    "    return tokenized_reviews,  sent_tokenized_reviews # ritorna una tupla!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of tokens extracted are: 3174\n"
     ]
    }
   ],
   "source": [
    "new_text, new_sent_tok = tokenize_list_of_text(dataset[\"verified_reviews\"], custom_stopwords, False, pos_list)\n",
    "# contengono una lista di tutte le frasi pre processate, nella prima variabile in stringa, nella seconda in tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of tokens extracted are: 1240\n"
     ]
    }
   ],
   "source": [
    "negative_reviews = list(dataset[dataset[\"feedback\"] == 0][\"verified_reviews\"].values)\n",
    "negative_text, negative_tok = tokenize_list_of_text(negative_reviews, custom_stopwords, False, pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732937, 871200)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_neg = Word2Vec(negative_tok, vector_size=300, window = 5, min_count = 0, sg=1, hs = 1, alpha=0.03, min_alpha=0.0007, seed = 5)\n",
    "w2v_model_neg.train(negative_tok, total_examples=len(negative_tok), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(reviews = [], n = 100):\n",
    "    \n",
    "    import random\n",
    "    from nltk.corpus import wordnet as wn\n",
    "\n",
    "    random.seed(10)\n",
    "    reviews_to_sample = random.sample(reviews, n)\n",
    "    generated_reviews = []\n",
    "\n",
    "    for review in reviews_to_sample:\n",
    "        new_review = []\n",
    "        for w in review:\n",
    "            syns = wn.synsets(w, lang = \"eng\")\n",
    "            synonyms = []\n",
    "            for syn in syns:\n",
    "                synonyms.extend(syn.lemma_names())\n",
    "            sim_score = {}\n",
    "            for word_sim in synonyms:\n",
    "                if word_sim != w and word_sim != \"\" and \"_\" not in word_sim:\n",
    "                    try:\n",
    "                        score = w2v_model_neg.wv.similarity(w, word_sim)\n",
    "                        sim_score[word_sim] = score\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "            \n",
    "            if sim_score:\n",
    "                new_review.append(max(sim_score, key=sim_score.get))\n",
    "            else:\n",
    "                new_review.append(w)\n",
    "\n",
    "        if new_review:\n",
    "            # print(\"-------------------------\")\n",
    "            # print(review)\n",
    "            # print(\"-\")\n",
    "            # print(new_review)\n",
    "            generated_reviews.append(new_review)\n",
    "\n",
    "    return generated_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_artifical = generate_samples(negative_tok, 150)\n",
    "new_sent_tok.extend(negative_artifical)\n",
    "len(negative_artifical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['disconnection',\n",
       "  'speaker',\n",
       "  'clock',\n",
       "  'day',\n",
       "  'deal',\n",
       "  'refurbish',\n",
       "  'product',\n",
       "  'attempt'],\n",
       " ['never',\n",
       "  'reply',\n",
       "  'talk',\n",
       "  'promp',\n",
       "  'news',\n",
       "  'suppose',\n",
       "  'would',\n",
       "  'link',\n",
       "  'upstairs',\n",
       "  'function',\n",
       "  'care',\n",
       "  'intercom',\n",
       "  'unable'],\n",
       " ['unhappy',\n",
       "  'speaker',\n",
       "  'heavy',\n",
       "  'ground',\n",
       "  'deal',\n",
       "  'clock',\n",
       "  'fun',\n",
       "  'music',\n",
       "  'depart',\n",
       "  'brand',\n",
       "  'weird',\n",
       "  'interference',\n",
       "  'contain',\n",
       "  'son',\n",
       "  'family',\n",
       "  'practically',\n",
       "  'sound'],\n",
       " ['contain',\n",
       "  'run',\n",
       "  'month',\n",
       "  'guarantee',\n",
       "  'sound',\n",
       "  'month',\n",
       "  'would',\n",
       "  'take',\n",
       "  'product',\n",
       "  'deal',\n",
       "  'would',\n",
       "  'high',\n",
       "  'standard',\n",
       "  'warranty',\n",
       "  'would',\n",
       "  'run',\n",
       "  'unit',\n",
       "  'month',\n",
       "  'think',\n",
       "  'product',\n",
       "  'think',\n",
       "  'bit',\n",
       "  'dust',\n",
       "  'crack',\n",
       "  'dismiss',\n",
       "  'lack',\n",
       "  'purchase',\n",
       "  'another',\n",
       "  'one',\n",
       "  'would',\n",
       "  'lack',\n",
       "  'purchase',\n",
       "  'another',\n",
       "  'one'],\n",
       " ['non',\n",
       "  'crack',\n",
       "  'move',\n",
       "  'sink',\n",
       "  'would',\n",
       "  'tightness',\n",
       "  'anything',\n",
       "  'stupid',\n",
       "  'plenty',\n",
       "  'mark',\n",
       "  'among',\n",
       "  'spotify',\n",
       "  'history',\n",
       "  \"n't\",\n",
       "  'function',\n",
       "  'either',\n",
       "  'randomly',\n",
       "  'talk',\n",
       "  'nobody',\n",
       "  'speak',\n",
       "  'today',\n",
       "  'disconnect',\n",
       "  'unsure',\n",
       "  \"'ll\",\n",
       "  'always',\n",
       "  'function'],\n",
       " ['run',\n",
       "  'fine',\n",
       "  'become',\n",
       "  'indundated',\n",
       "  'matter',\n",
       "  'prove',\n",
       "  'non',\n",
       "  'year',\n",
       "  'previous',\n",
       "  'take',\n",
       "  'stimulus',\n",
       "  'differentiate',\n",
       "  'matter',\n",
       "  'determine',\n",
       "  'room',\n",
       "  'number',\n",
       "  'except',\n",
       "  '....',\n",
       "  'number',\n",
       "  'cover',\n",
       "  'miss',\n",
       "  'suitable',\n",
       "  'ready',\n",
       "  'second'],\n",
       " ['dislike',\n",
       "  'virtually',\n",
       "  'everytime',\n",
       "  'expect',\n",
       "  'head',\n",
       "  'would',\n",
       "  'state',\n",
       "  'dont',\n",
       "  'bed',\n",
       "  'havent',\n",
       "  'determine'],\n",
       " ['practically', 'hard', 'function', 'chromecast'],\n",
       " ['light',\n",
       "  'good',\n",
       "  'compare',\n",
       "  'family',\n",
       "  'mini',\n",
       "  'good',\n",
       "  'big',\n",
       "  'also',\n",
       "  'take',\n",
       "  'little',\n",
       "  'option',\n",
       "  'music',\n",
       "  'take',\n",
       "  'music',\n",
       "  'fun',\n",
       "  'everything',\n",
       "  'also',\n",
       "  'become',\n",
       "  'two',\n",
       "  'take',\n",
       "  'household',\n",
       "  'music',\n",
       "  'fun',\n",
       "  'music',\n",
       "  'suppose',\n",
       "  'game',\n",
       "  'take',\n",
       "  'household',\n",
       "  'design',\n",
       "  'function',\n",
       "  'multiple',\n",
       "  'device'],\n",
       " ['yet',\n",
       "  'run',\n",
       "  'play',\n",
       "  'phone',\n",
       "  'allow',\n",
       "  'bed',\n",
       "  'direction',\n",
       "  'clock',\n",
       "  'ridiculous'],\n",
       " ['tech', 'see', 'common', 'news', 'essentially', 'laud', 'wireless'],\n",
       " ['heavy',\n",
       "  'product',\n",
       "  'except',\n",
       "  'potential',\n",
       "  'room',\n",
       "  'bit',\n",
       "  'time',\n",
       "  'show',\n",
       "  'clock',\n",
       "  'permanently',\n",
       "  \"'clock\",\n",
       "  'way',\n",
       "  'cover',\n",
       "  'rotate',\n",
       "  'time',\n",
       "  'font',\n",
       "  \"'things\",\n",
       "  'prove',\n",
       "  'cover',\n",
       "  'mean',\n",
       "  'purchase',\n",
       "  'several',\n",
       "  'whole',\n",
       "  'home',\n",
       "  'obviate',\n",
       "  'cover',\n",
       "  'home',\n",
       "  'permanently',\n",
       "  'prove',\n",
       "  'confused',\n",
       "  'bit',\n",
       "  'time',\n",
       "  'basic',\n",
       "  'characteristic',\n",
       "  'position',\n",
       "  'could',\n",
       "  'become',\n",
       "  'damage',\n",
       "  'die'],\n",
       " ['become',\n",
       "  'month',\n",
       "  'ago',\n",
       "  'theme',\n",
       "  'assist',\n",
       "  'contain',\n",
       "  'smart',\n",
       "  'lightbulb',\n",
       "  'useful',\n",
       "  'serve',\n",
       "  'head',\n",
       "  'become',\n",
       "  'daily',\n",
       "  'weather',\n",
       "  'updates.it',\n",
       "  'far',\n",
       "  'useful.half',\n",
       "  'clock',\n",
       "  'wake',\n",
       "  'device',\n",
       "  'expect',\n",
       "  'head',\n",
       "  'start',\n",
       "  'instruction',\n",
       "  'listen',\n",
       "  'state',\n",
       "  'number',\n",
       "  'essentially',\n",
       "  'discount',\n",
       "  'much',\n",
       "  'unable',\n",
       "  'serve',\n",
       "  'basic',\n",
       "  'questions.it',\n",
       "  'baffle',\n",
       "  'run',\n",
       "  'quite',\n",
       "  'brand',\n",
       "  'lifetime',\n",
       "  'easier.i',\n",
       "  'would',\n",
       "  'refund',\n",
       "  'past',\n",
       "  'refund',\n",
       "  'point',\n",
       "  '......',\n",
       "  'zzzz'],\n",
       " ['lack',\n",
       "  'function',\n",
       "  'time',\n",
       "  'bedroom',\n",
       "  'face',\n",
       "  'little',\n",
       "  'date',\n",
       "  'distance',\n",
       "  'apparently',\n",
       "  'stop'],\n",
       " ['run',\n",
       "  'month',\n",
       "  'contain',\n",
       "  \"'ve\",\n",
       "  'prove',\n",
       "  'everything',\n",
       "  'prove',\n",
       "  'brand',\n",
       "  'run',\n",
       "  'zero',\n",
       "  'run',\n",
       "  'lack',\n",
       "  'return'],\n",
       " ['barely', 'arrive'],\n",
       " ['real',\n",
       "  'glad',\n",
       "  'original',\n",
       "  'view',\n",
       "  'become',\n",
       "  'function',\n",
       "  'bedroom',\n",
       "  'real',\n",
       "  'disappoint',\n",
       "  'sound',\n",
       "  'choice',\n",
       "  'link',\n",
       "  'external',\n",
       "  'speaker',\n",
       "  'via',\n",
       "  'bluetooth',\n",
       "  'sound',\n",
       "  'practically',\n",
       "  'sound',\n",
       "  'depart',\n",
       "  'trouble',\n",
       "  'free',\n",
       "  'link',\n",
       "  'wifi',\n",
       "  'presumably',\n",
       "  'due',\n",
       "  'noise',\n",
       "  'bluetooth',\n",
       "  'link',\n",
       "  'speaker',\n",
       "  'via',\n",
       "  'auxiliary',\n",
       "  'jack',\n",
       "  'auxiliary',\n",
       "  'jack',\n",
       "  'clean',\n",
       "  'noise',\n",
       "  'wifi',\n",
       "  'wake',\n",
       "  'eye',\n",
       "  'dark',\n",
       "  'horrible',\n",
       "  'buzzing',\n",
       "  'good',\n",
       "  'hop',\n",
       "  'deal',\n",
       "  'matter',\n",
       "  'second',\n",
       "  'yield',\n",
       "  'sound',\n",
       "  'bargain',\n",
       "  'position',\n",
       "  'trust',\n",
       "  'sound',\n",
       "  'nightstand',\n",
       "  'device'],\n",
       " ['suppose',\n",
       "  'become',\n",
       "  'long',\n",
       "  'clock',\n",
       "  'charge',\n",
       "  'come',\n",
       "  'package',\n",
       "  'hue',\n",
       "  'lightbulb',\n",
       "  'excite',\n",
       "  'close',\n",
       "  'quick',\n",
       "  'drop',\n",
       "  'add',\n",
       "  'minute',\n",
       "  'effort',\n",
       "  'total',\n",
       "  'lightbulb',\n",
       "  'positive',\n",
       "  'everything',\n",
       "  'prove',\n",
       "  'close',\n",
       "  'find',\n",
       "  'die',\n",
       "  'content',\n",
       "  'prove',\n",
       "  'correct',\n",
       "  'follow',\n",
       "  'picture',\n",
       "  'record',\n",
       "  'correct',\n",
       "  'site',\n",
       "  'notice',\n",
       "  'baby',\n",
       "  'insanity',\n",
       "  'matter',\n",
       "  'look',\n",
       "  'different',\n",
       "  'solution',\n",
       "  '.the',\n",
       "  'future',\n",
       "  'day',\n",
       "  'onto',\n",
       "  'become',\n",
       "  'tech',\n",
       "  'living',\n",
       "  'hop',\n",
       "  'something',\n",
       "  'would',\n",
       "  'brand',\n",
       "  'matter',\n",
       "  'run',\n",
       "  'also',\n",
       "  'trouble',\n",
       "  'non',\n",
       "  'operator',\n",
       "  'fault',\n",
       "  'good',\n",
       "  'tech',\n",
       "  'living',\n",
       "  'staff',\n",
       "  'minute',\n",
       "  'call',\n",
       "  'yet',\n",
       "  'loose',\n",
       "  'product',\n",
       "  'prove',\n",
       "  'patience',\n",
       "  'far',\n",
       "  'know',\n",
       "  'break',\n",
       "  'mindset',\n",
       "  'smart',\n",
       "  'family',\n",
       "  'complain',\n",
       "  'previous',\n",
       "  'school.the',\n",
       "  'ground',\n",
       "  'yield',\n",
       "  'two',\n",
       "  'charge',\n",
       "  'different',\n",
       "  'positive',\n",
       "  'clean',\n",
       "  'lightbulb',\n",
       "  'trouble',\n",
       "  \"n't\",\n",
       "  'lightbulb',\n",
       "  'bundle',\n",
       "  'particular',\n",
       "  'buy',\n",
       "  'another',\n",
       "  'lightbulb',\n",
       "  'yet',\n",
       "  'could',\n",
       "  \"n't\",\n",
       "  'site',\n",
       "  'device.i',\n",
       "  'pray',\n",
       "  'future',\n",
       "  'effort',\n",
       "  'successful',\n",
       "  'revise',\n",
       "  'range',\n",
       "  'odds',\n",
       "  'send',\n",
       "  'bad',\n",
       "  'living',\n",
       "  'somebody',\n",
       "  'view',\n",
       "  'perhaps',\n",
       "  'research',\n",
       "  'device',\n",
       "  'provide',\n",
       "  'expect',\n",
       "  'expect',\n",
       "  'care',\n",
       "  'defuser.i',\n",
       "  'disbelieve',\n",
       "  'miss',\n",
       "  'picture',\n",
       "  'point',\n",
       "  'trouble',\n",
       "  'everything',\n",
       "  'expect',\n",
       "  'bare',\n",
       "  'seamless',\n",
       "  'inexperience',\n",
       "  'review',\n",
       "  'drop',\n",
       "  'plenty',\n",
       "  'waste',\n",
       "  'clock',\n",
       "  'weekend',\n",
       "  'already'],\n",
       " ['disconnection',\n",
       "  'speaker',\n",
       "  'clock',\n",
       "  'day',\n",
       "  'deal',\n",
       "  'refurbish',\n",
       "  'product',\n",
       "  'attempt'],\n",
       " ['device',\n",
       "  'point',\n",
       "  'look',\n",
       "  'huge',\n",
       "  'possible',\n",
       "  'real',\n",
       "  'lack',\n",
       "  'care',\n",
       "  'shortly',\n",
       "  'determine',\n",
       "  'rather',\n",
       "  'set',\n",
       "  'piece',\n",
       "  'disappoint',\n",
       "  'get',\n",
       "  'world',\n",
       "  'function',\n",
       "  'care',\n",
       "  'function',\n",
       "  'screenless',\n",
       "  '....',\n",
       "  'short',\n",
       "  'month',\n",
       "  'cover',\n",
       "  'depart',\n",
       "  'flicker',\n",
       "  'mostly',\n",
       "  'bed',\n",
       "  'cover',\n",
       "  'non',\n",
       "  'fast',\n",
       "  'expect',\n",
       "  'forum',\n",
       "  'brand',\n",
       "  'see',\n",
       "  'wasted',\n",
       "  'expect',\n",
       "  'switch',\n",
       "  'people',\n",
       "  'device',\n",
       "  'exchange',\n",
       "  'depart',\n",
       "  'flicker',\n",
       "  'short',\n",
       "  'non',\n",
       "  'leave',\n",
       "  'good',\n",
       "  'serve',\n",
       "  'rather',\n",
       "  'clock',\n",
       "  'apparently.long',\n",
       "  'history',\n",
       "  'shortly',\n",
       "  'act',\n",
       "  'hallway',\n",
       "  'function',\n",
       "  'expensive',\n",
       "  'bulky',\n",
       "  'sound',\n",
       "  'trigger',\n",
       "  'clean',\n",
       "  'exchange',\n",
       "  'hue',\n",
       "  'clean',\n",
       "  'care',\n",
       "  'headline',\n",
       "  'advise',\n",
       "  'meh'],\n",
       " ['never',\n",
       "  'purchase',\n",
       "  'anything',\n",
       "  'brand',\n",
       "  'funny',\n",
       "  'year',\n",
       "  'previous',\n",
       "  'zero',\n",
       "  'restart',\n",
       "  'freeze',\n",
       "  'forever',\n",
       "  'guarantee',\n",
       "  'low',\n",
       "  'clue',\n",
       "  'horrible',\n",
       "  'device',\n",
       "  'never',\n",
       "  'purchase',\n",
       "  'anything',\n",
       "  'shape'],\n",
       " ['dont', 'hope', '....'],\n",
       " ['flash', 'flash', 'good'],\n",
       " ['barely', 'arrive'],\n",
       " ['run',\n",
       "  'half',\n",
       "  'clock',\n",
       "  'non',\n",
       "  'reply',\n",
       "  'state',\n",
       "  'wake',\n",
       "  'describe',\n",
       "  'run',\n",
       "  'fine'],\n",
       " ['practically', 'hard', 'function', 'chromecast'],\n",
       " ['dislike',\n",
       "  'non',\n",
       "  'charge',\n",
       "  'history',\n",
       "  'also',\n",
       "  'dumb',\n",
       "  'bed',\n",
       "  'non',\n",
       "  'internet',\n",
       "  'link',\n",
       "  'xbox',\n",
       "  'one',\n",
       "  'run',\n",
       "  'fine',\n",
       "  'deal',\n",
       "  'always',\n",
       "  'charge',\n",
       "  'anything'],\n",
       " ['would',\n",
       "  'screw',\n",
       "  'remote',\n",
       "  'wasnt',\n",
       "  'drop',\n",
       "  'practically',\n",
       "  'money',\n",
       "  'exchange',\n",
       "  'battery',\n",
       "  'trouble',\n",
       "  'drop',\n",
       "  'money',\n",
       "  'heavy',\n",
       "  'device',\n",
       "  'battery',\n",
       "  'low'],\n",
       " ['refund',\n",
       "  'loose',\n",
       "  'device',\n",
       "  'continue',\n",
       "  'arrive',\n",
       "  'fault',\n",
       "  'app',\n",
       "  'unable',\n",
       "  'clear',\n",
       "  'clock',\n",
       "  'shoot',\n",
       "  'drop',\n",
       "  'clock',\n",
       "  'contain',\n",
       "  'run',\n",
       "  'properly',\n",
       "  'eye',\n",
       "  'point',\n",
       "  'picture',\n",
       "  'positive',\n",
       "  'dumb',\n",
       "  'clear',\n",
       "  'apps'],\n",
       " ['run',\n",
       "  'fine',\n",
       "  'become',\n",
       "  'indundated',\n",
       "  'matter',\n",
       "  'prove',\n",
       "  'non',\n",
       "  'year',\n",
       "  'previous',\n",
       "  'take',\n",
       "  'stimulus',\n",
       "  'differentiate',\n",
       "  'matter',\n",
       "  'determine',\n",
       "  'room',\n",
       "  'number',\n",
       "  'except',\n",
       "  '....',\n",
       "  'number',\n",
       "  'cover',\n",
       "  'miss',\n",
       "  'suitable',\n",
       "  'ready',\n",
       "  'second'],\n",
       " ['disappoint',\n",
       "  'device',\n",
       "  'unable',\n",
       "  'approach',\n",
       "  'dec',\n",
       "  'aware',\n",
       "  'buy',\n",
       "  'trouble',\n",
       "  'device',\n",
       "  'sound',\n",
       "  'contain',\n",
       "  'run',\n",
       "  'throughout',\n",
       "  'day',\n",
       "  'date',\n",
       "  'prove',\n",
       "  'reply',\n",
       "  'window',\n",
       "  'clear',\n",
       "  'stop',\n",
       "  'information',\n",
       "  'expect',\n",
       "  'care',\n",
       "  'device',\n",
       "  'become',\n",
       "  'action',\n",
       "  'contain',\n",
       "  'run',\n",
       "  'dark',\n",
       "  'stop',\n",
       "  'newsflash',\n",
       "  'continue',\n",
       "  'disconnect',\n",
       "  'restart',\n",
       "  'device',\n",
       "  'depart',\n",
       "  'run',\n",
       "  'annoying',\n",
       "  'device',\n",
       "  'could',\n",
       "  'real',\n",
       "  'heavy',\n",
       "  'device',\n",
       "  'would',\n",
       "  'bit',\n",
       "  'care',\n",
       "  'big'],\n",
       " ['rather',\n",
       "  'disappoint',\n",
       "  'product.there',\n",
       "  'clear',\n",
       "  'glitch',\n",
       "  'half',\n",
       "  'clock',\n",
       "  'expect',\n",
       "  'flash',\n",
       "  'two',\n",
       "  'minute',\n",
       "  'depart',\n",
       "  'unit',\n",
       "  'matter',\n",
       "  'contain',\n",
       "  'reboot',\n",
       "  'pair',\n",
       "  'second',\n",
       "  'expect',\n",
       "  'fun',\n",
       "  'wireless',\n",
       "  'also',\n",
       "  'many',\n",
       "  'clock',\n",
       "  'become',\n",
       "  'confuse',\n",
       "  'expect',\n",
       "  'exchange',\n",
       "  'clean',\n",
       "  'particular',\n",
       "  'also',\n",
       "  'describe',\n",
       "  'false',\n",
       "  'clear',\n",
       "  'cancel',\n",
       "  'speech',\n",
       "  \"'beta\",\n",
       "  'degree',\n",
       "  'yet',\n",
       "  'non',\n",
       "  'impress'],\n",
       " ['heavy',\n",
       "  'product',\n",
       "  'would',\n",
       "  'yield',\n",
       "  \"n't\",\n",
       "  'roll',\n",
       "  'font',\n",
       "  'board',\n",
       "  'sound',\n",
       "  'prove',\n",
       "  'expect',\n",
       "  'suggestion',\n",
       "  'start',\n",
       "  'yes',\n",
       "  'roll',\n",
       "  'stop',\n",
       "  'time',\n",
       "  'care',\n",
       "  'board',\n",
       "  'good',\n",
       "  'god',\n",
       "  'big',\n",
       "  'annoying',\n",
       "  'become',\n",
       "  'crack',\n",
       "  'flash',\n",
       "  'font',\n",
       "  'cover',\n",
       "  'toward',\n",
       "  'wall',\n",
       "  'cover',\n",
       "  'care',\n",
       "  'rather',\n",
       "  'position',\n",
       "  'slow',\n",
       "  'act',\n",
       "  'amazons\\u200b',\n",
       "  'separate'],\n",
       " ['purchase',\n",
       "  'position',\n",
       "  'screw',\n",
       "  'inside',\n",
       "  'month',\n",
       "  'depart',\n",
       "  'bit',\n",
       "  'odd',\n",
       "  'would',\n",
       "  'contain',\n",
       "  'workingâcalled',\n",
       "  'learn',\n",
       "  'overheat',\n",
       "  'differentiate',\n",
       "  'disconnect',\n",
       "  'technical',\n",
       "  'living',\n",
       "  'would',\n",
       "  'phone',\n",
       "  'inside',\n",
       "  'minute',\n",
       "  'delay',\n",
       "  'minute',\n",
       "  'without',\n",
       "  'reply',\n",
       "  'response',\n",
       "  'email',\n",
       "  'expect',\n",
       "  'delay',\n",
       "  'week',\n",
       "  'week',\n",
       "  'perfectly',\n",
       "  'reply',\n",
       "  'inline',\n",
       "  'chat',\n",
       "  'per',\n",
       "  'command',\n",
       "  'differentiate',\n",
       "  'delay',\n",
       "  'long',\n",
       "  'real',\n",
       "  'unacceptableâexpected',\n",
       "  'determine',\n",
       "  'odd',\n",
       "  'forever',\n",
       "  'thank',\n",
       "  'member',\n",
       "  'take',\n",
       "  'arise',\n",
       "  'funny',\n",
       "  'become',\n",
       "  'assist'],\n",
       " ['awful',\n",
       "  'rcieved',\n",
       "  'clean',\n",
       "  'buld',\n",
       "  'discount',\n",
       "  'take',\n",
       "  'another',\n",
       "  'adapter',\n",
       "  'clean',\n",
       "  'buld',\n",
       "  'run',\n",
       "  'unmindful',\n",
       "  'disappoint'],\n",
       " ['particular',\n",
       "  'refund',\n",
       "  'fixing',\n",
       "  'receivded',\n",
       "  'particular',\n",
       "  'second',\n",
       "  'fixing',\n",
       "  'separate',\n",
       "  'drop',\n",
       "  'office',\n",
       "  'cord',\n",
       "  'included.please',\n",
       "  'suggest'],\n",
       " ['screw',\n",
       "  'depart',\n",
       "  'june',\n",
       "  'contain',\n",
       "  'run',\n",
       "  'crunchyroll',\n",
       "  'run',\n",
       "  'either',\n",
       "  'probably',\n",
       "  'exchange',\n",
       "  'something',\n",
       "  'else',\n",
       "  'shortly'],\n",
       " ['become',\n",
       "  'heavy',\n",
       "  'good',\n",
       "  'bass',\n",
       "  'loose',\n",
       "  'clock',\n",
       "  'yet',\n",
       "  'live',\n",
       "  'drop',\n",
       "  'acknowledge',\n",
       "  'matter'],\n",
       " ['forever',\n",
       "  'buffer',\n",
       "  'charge',\n",
       "  \"n't\",\n",
       "  'follow',\n",
       "  'anything',\n",
       "  'without',\n",
       "  'break',\n",
       "  'buy',\n",
       "  'day',\n",
       "  'positive',\n",
       "  'function',\n",
       "  'reward',\n",
       "  'yield',\n",
       "  'close',\n",
       "  'yield',\n",
       "  'future',\n",
       "  'zero',\n",
       "  'yield',\n",
       "  'fully',\n",
       "  'damage',\n",
       "  'power',\n",
       "  'lack',\n",
       "  'money',\n",
       "  'second',\n",
       "  'contain',\n",
       "  'prove',\n",
       "  'function',\n",
       "  'second',\n",
       "  'previous',\n",
       "  'stream',\n",
       "  'device',\n",
       "  'bed',\n",
       "  'internet',\n",
       "  'help',\n",
       "  'return',\n",
       "  'non',\n",
       "  'trouble',\n",
       "  'device',\n",
       "  'current'],\n",
       " ['heavy',\n",
       "  'setup',\n",
       "  'suppose',\n",
       "  'ground',\n",
       "  'default',\n",
       "  'twice',\n",
       "  'thru',\n",
       "  'many',\n",
       "  'step',\n",
       "  'setup',\n",
       "  'determine',\n",
       "  'device',\n",
       "  'would',\n",
       "  'decent',\n",
       "  'could',\n",
       "  'interact',\n",
       "  'xfinity',\n",
       "  'line',\n",
       "  'line',\n",
       "  'package',\n",
       "  'also',\n",
       "  'loose',\n",
       "  'xfinity',\n",
       "  'alert',\n",
       "  'home',\n",
       "  'camera',\n",
       "  'decent',\n",
       "  'correct',\n",
       "  'disarm',\n",
       "  'alert',\n",
       "  'install',\n",
       "  'skill',\n",
       "  'app',\n",
       "  'setup',\n",
       "  'lightbulb',\n",
       "  'whats',\n",
       "  'send',\n",
       "  'product',\n",
       "  'state',\n",
       "  'setup',\n",
       "  'lightbulb',\n",
       "  'determine',\n",
       "  'new',\n",
       "  'lightbulb',\n",
       "  'setup',\n",
       "  'nest',\n",
       "  'fine',\n",
       "  'function',\n",
       "  'third',\n",
       "  'company',\n",
       "  'apps',\n",
       "  'run'],\n",
       " ['disappoint', 'listen', 'reply', 'request'],\n",
       " ['really',\n",
       "  'trouble',\n",
       "  'run',\n",
       "  'alexi',\n",
       "  'stupid',\n",
       "  'head',\n",
       "  'expect',\n",
       "  'become',\n",
       "  'unsure',\n",
       "  'half',\n",
       "  'clock',\n",
       "  'yet',\n",
       "  'expect',\n",
       "  'head',\n",
       "  'alexi',\n",
       "  'state',\n",
       "  'unsure',\n",
       "  'music',\n",
       "  'heavy',\n",
       "  'run',\n",
       "  'good',\n",
       "  'far',\n",
       "  'baffle',\n",
       "  'know'],\n",
       " ['device', 'loose', 'watch', 'command', 'live', 'trouble'],\n",
       " ['charge',\n",
       "  'run',\n",
       "  'sound',\n",
       "  'remote',\n",
       "  'advance',\n",
       "  'regular',\n",
       "  'number',\n",
       "  'troubleshoot',\n",
       "  'step',\n",
       "  'run',\n",
       "  'link',\n",
       "  'charge',\n",
       "  'new',\n",
       "  'one',\n",
       "  'remote/no',\n",
       "  'room',\n",
       "  'contain',\n",
       "  'yield',\n",
       "  'become',\n",
       "  'run',\n",
       "  'heavy'],\n",
       " ['buy', 'function', 'road', 'semi', 'loose', 'application'],\n",
       " ['minute', 'one', 'refurbish', 'example', 'work-at', 'least', 'away'],\n",
       " ['short', 'characteristic'],\n",
       " ['view',\n",
       "  'would',\n",
       "  'right',\n",
       "  'deal',\n",
       "  'functionality',\n",
       "  'short',\n",
       "  'sound',\n",
       "  'worthlessness',\n",
       "  'money'],\n",
       " ['unhappy',\n",
       "  'every',\n",
       "  'clock',\n",
       "  'exchange',\n",
       "  'plan',\n",
       "  'line',\n",
       "  'inside',\n",
       "  'plan',\n",
       "  'long',\n",
       "  'wait',\n",
       "  'run',\n",
       "  'fine',\n",
       "  'fast'],\n",
       " ['awful',\n",
       "  'position',\n",
       "  'disappointment',\n",
       "  'short',\n",
       "  'contain',\n",
       "  'cover',\n",
       "  'point',\n",
       "  'time',\n",
       "  'expect',\n",
       "  'care',\n",
       "  'range',\n",
       "  'matter',\n",
       "  'point',\n",
       "  'etc',\n",
       "  'charge',\n",
       "  \"n't\",\n",
       "  'hold',\n",
       "  'package',\n",
       "  'away',\n",
       "  'directly',\n",
       "  'would',\n",
       "  'charge',\n",
       "  'second',\n",
       "  'become',\n",
       "  'another',\n",
       "  'fully',\n",
       "  'size'],\n",
       " ['previous',\n",
       "  'continue',\n",
       "  'crash',\n",
       "  'function',\n",
       "  'sling',\n",
       "  'tv.i',\n",
       "  'purchase',\n",
       "  'one',\n",
       "  'suppose',\n",
       "  'previous',\n",
       "  'one',\n",
       "  'defective.this',\n",
       "  'one',\n",
       "  'matter',\n",
       "  'second',\n",
       "  'sling',\n",
       "  'depart',\n",
       "  'provide',\n",
       "  'plan'],\n",
       " ['short', 'choice', 'yield', 'away'],\n",
       " ['think',\n",
       "  'arrive',\n",
       "  'loose',\n",
       "  'hue',\n",
       "  'bulb',\n",
       "  'day',\n",
       "  'clean',\n",
       "  'lightbulb',\n",
       "  'come',\n",
       "  'false',\n",
       "  'promote'],\n",
       " ['never',\n",
       "  'purchase',\n",
       "  'anything',\n",
       "  'brand',\n",
       "  'funny',\n",
       "  'year',\n",
       "  'previous',\n",
       "  'zero',\n",
       "  'restart',\n",
       "  'freeze',\n",
       "  'forever',\n",
       "  'guarantee',\n",
       "  'low',\n",
       "  'clue',\n",
       "  'horrible',\n",
       "  'device',\n",
       "  'never',\n",
       "  'purchase',\n",
       "  'anything',\n",
       "  'shape'],\n",
       " [\"n't\",\n",
       "  'week',\n",
       "  'already',\n",
       "  'disconnect',\n",
       "  'network',\n",
       "  'prove',\n",
       "  'reconnecting',\n",
       "  'manually',\n",
       "  'never',\n",
       "  'look',\n",
       "  'name',\n",
       "  'device',\n",
       "  'link',\n",
       "  'room',\n",
       "  'second'],\n",
       " ['function',\n",
       "  'child',\n",
       "  'reminder',\n",
       "  'buy',\n",
       "  'clear',\n",
       "  'record',\n",
       "  'review',\n",
       "  'skill',\n",
       "  'sync',\n",
       "  'nest',\n",
       "  'cam',\n",
       "  'view',\n",
       "  'short',\n",
       "  'review',\n",
       "  'fact',\n",
       "  'bare',\n",
       "  'ready',\n",
       "  'surprised',\n",
       "  'advance',\n",
       "  'package',\n",
       "  'provide',\n",
       "  'second',\n",
       "  'consider',\n",
       "  'alarm',\n",
       "  'care',\n",
       "  'become',\n",
       "  'nest',\n",
       "  'app'],\n",
       " ['heavy',\n",
       "  'product',\n",
       "  'refund',\n",
       "  'new',\n",
       "  'refurbish',\n",
       "  'already',\n",
       "  'yield',\n",
       "  'trouble',\n",
       "  'link'],\n",
       " ['negative',\n",
       "  'product',\n",
       "  'awful',\n",
       "  'good',\n",
       "  'choice',\n",
       "  'massive',\n",
       "  'difference',\n",
       "  'bad',\n",
       "  'ground',\n",
       "  'lack',\n",
       "  'buy',\n",
       "  'this.won',\n",
       "  'purchase',\n",
       "  'another',\n",
       "  'speaker',\n",
       "  'good',\n",
       "  'choice',\n",
       "  'improve'],\n",
       " ['damage',\n",
       "  'product',\n",
       "  'decent',\n",
       "  'choice',\n",
       "  'decent',\n",
       "  'characteristic',\n",
       "  'definitely',\n",
       "  'charge',\n",
       "  'ground',\n",
       "  'yield',\n",
       "  'leave',\n",
       "  'may',\n",
       "  'buyer',\n",
       "  'fault',\n",
       "  'low',\n",
       "  'bed',\n",
       "  'product',\n",
       "  'punch',\n",
       "  'clock',\n",
       "  'run',\n",
       "  'real',\n",
       "  'care',\n",
       "  'give',\n",
       "  'alone',\n",
       "  'device',\n",
       "  'also',\n",
       "  'speaker',\n",
       "  'easy',\n",
       "  'purchase',\n",
       "  'bluetooth',\n",
       "  'speaker',\n",
       "  'finally',\n",
       "  'certain',\n",
       "  'deal',\n",
       "  'rather',\n",
       "  'enter',\n",
       "  'function',\n",
       "  'full',\n",
       "  'form',\n",
       "  'look',\n",
       "  'care',\n",
       "  'unnecessary',\n",
       "  'device',\n",
       "  'positive',\n",
       "  'correct',\n",
       "  'terrible',\n",
       "  'would',\n",
       "  'definitely',\n",
       "  'keep',\n",
       "  'money',\n",
       "  'purchase',\n",
       "  'nice',\n",
       "  'one',\n",
       "  'really'],\n",
       " ['something',\n",
       "  'damage',\n",
       "  'low',\n",
       "  'one',\n",
       "  'regular',\n",
       "  'rep',\n",
       "  'talk',\n",
       "  'could',\n",
       "  'ready',\n",
       "  'switch',\n",
       "  'record',\n",
       "  'somebody',\n",
       "  'else',\n",
       "  'damage',\n",
       "  'damage',\n",
       "  'refurbish',\n",
       "  'one',\n",
       "  'purchase',\n",
       "  'mark',\n",
       "  'spank',\n",
       "  'new',\n",
       "  'one',\n",
       "  'trouble',\n",
       "  'new',\n",
       "  'one'],\n",
       " ['unhappy',\n",
       "  'speaker',\n",
       "  'heavy',\n",
       "  'ground',\n",
       "  'deal',\n",
       "  'clock',\n",
       "  'fun',\n",
       "  'music',\n",
       "  'depart',\n",
       "  'brand',\n",
       "  'weird',\n",
       "  'interference',\n",
       "  'contain',\n",
       "  'son',\n",
       "  'family',\n",
       "  'practically',\n",
       "  'sound'],\n",
       " ['big',\n",
       "  'device',\n",
       "  'bed',\n",
       "  'refurbish',\n",
       "  'trigger',\n",
       "  'nobody',\n",
       "  'speak',\n",
       "  'trigger',\n",
       "  'depart',\n",
       "  'speak',\n",
       "  'speak',\n",
       "  'call',\n",
       "  'crack',\n",
       "  'laud'],\n",
       " ['product',\n",
       "  'blue',\n",
       "  'stop',\n",
       "  'never',\n",
       "  'orange',\n",
       "  'reset',\n",
       "  'command',\n",
       "  'really',\n",
       "  'disagree',\n",
       "  'bundle',\n",
       "  'command',\n",
       "  'prove',\n",
       "  'product',\n",
       "  'bad'],\n",
       " ['product',\n",
       "  'good',\n",
       "  'emoji',\n",
       "  'speaker',\n",
       "  'five',\n",
       "  'baby',\n",
       "  'regular',\n",
       "  'one',\n",
       "  'bluetooth',\n",
       "  'take',\n",
       "  'punch',\n",
       "  'sound',\n",
       "  'matter',\n",
       "  'talk'],\n",
       " ['contact',\n",
       "  'device',\n",
       "  'lack',\n",
       "  'sync',\n",
       "  'call',\n",
       "  'turn',\n",
       "  'would',\n",
       "  'deny',\n",
       "  'state',\n",
       "  'turn',\n",
       "  'already',\n",
       "  'function',\n",
       "  'customer',\n",
       "  'help',\n",
       "  'could',\n",
       "  \"n't\",\n",
       "  'assist',\n",
       "  'essentially',\n",
       "  'differentiate',\n",
       "  'link',\n",
       "  'sprint',\n",
       "  'help',\n",
       "  'simple',\n",
       "  'minimal',\n",
       "  'without',\n",
       "  'approach',\n",
       "  'call',\n",
       "  'correct',\n",
       "  'form',\n",
       "  'wasted',\n",
       "  'yield'],\n",
       " ['take',\n",
       "  'purchase',\n",
       "  'become',\n",
       "  'run',\n",
       "  'samsung',\n",
       "  'many',\n",
       "  'device',\n",
       "  'lack',\n",
       "  'money',\n",
       "  'second',\n",
       "  'matter',\n",
       "  'funny',\n",
       "  'number',\n",
       "  'unless',\n",
       "  'purchase',\n",
       "  'another',\n",
       "  'charge',\n",
       "  'negate',\n",
       "  'half',\n",
       "  'device',\n",
       "  'deal',\n",
       "  'matter',\n",
       "  'unless',\n",
       "  'lack',\n",
       "  'drop',\n",
       "  'another',\n",
       "  'another',\n",
       "  'loose',\n",
       "  'many',\n",
       "  'device',\n",
       "  'must',\n",
       "  'evil',\n",
       "  'still',\n",
       "  'become',\n",
       "  'device',\n",
       "  'really',\n",
       "  'see',\n",
       "  'speak'],\n",
       " ['short', 'choice', 'yield', 'away'],\n",
       " ['range'],\n",
       " ['negative',\n",
       "  'product',\n",
       "  'awful',\n",
       "  'good',\n",
       "  'choice',\n",
       "  'massive',\n",
       "  'difference',\n",
       "  'bad',\n",
       "  'ground',\n",
       "  'lack',\n",
       "  'buy',\n",
       "  'this.won',\n",
       "  'purchase',\n",
       "  'another',\n",
       "  'speaker',\n",
       "  'good',\n",
       "  'choice',\n",
       "  'improve'],\n",
       " ['disappoint',\n",
       "  'product',\n",
       "  'prove',\n",
       "  'install',\n",
       "  'two',\n",
       "  'different',\n",
       "  'whole',\n",
       "  'neither',\n",
       "  'one',\n",
       "  'successfully',\n",
       "  'finish',\n",
       "  'minute',\n",
       "  'technician',\n",
       "  'reset',\n",
       "  'app',\n",
       "  'disconnect',\n",
       "  'positive',\n",
       "  'internet',\n",
       "  'link',\n",
       "  'prove',\n",
       "  'function',\n",
       "  'application',\n",
       "  'call',\n",
       "  'tablet',\n",
       "  'chromebook',\n",
       "  'chance',\n",
       "  'pick',\n",
       "  'charge',\n",
       "  'application',\n",
       "  'probably',\n",
       "  'charge',\n",
       "  'second',\n",
       "  'differentiate',\n",
       "  'unready',\n",
       "  'clock'],\n",
       " ['correct',\n",
       "  'run',\n",
       "  'minute',\n",
       "  'go',\n",
       "  'whole',\n",
       "  'deal',\n",
       "  'refurbish',\n",
       "  'charge',\n",
       "  'second',\n",
       "  'refund',\n",
       "  'day',\n",
       "  'find'],\n",
       " ['unhappy',\n",
       "  'position',\n",
       "  'reset',\n",
       "  'numerous',\n",
       "  'clock',\n",
       "  'look',\n",
       "  'dumb',\n",
       "  'way',\n",
       "  'much',\n",
       "  'cover',\n",
       "  'listen',\n",
       "  'regular',\n",
       "  'speak',\n",
       "  'living',\n",
       "  'yet',\n",
       "  'non',\n",
       "  'idea',\n",
       "  'card',\n",
       "  'opt'],\n",
       " ['evil'],\n",
       " ['run',\n",
       "  'month',\n",
       "  'contain',\n",
       "  \"'ve\",\n",
       "  'prove',\n",
       "  'everything',\n",
       "  'prove',\n",
       "  'brand',\n",
       "  'run',\n",
       "  'zero',\n",
       "  'run',\n",
       "  'lack',\n",
       "  'return'],\n",
       " ['contain',\n",
       "  'run',\n",
       "  'month',\n",
       "  'guarantee',\n",
       "  'sound',\n",
       "  'month',\n",
       "  'would',\n",
       "  'take',\n",
       "  'product',\n",
       "  'deal',\n",
       "  'would',\n",
       "  'high',\n",
       "  'standard',\n",
       "  'warranty',\n",
       "  'would',\n",
       "  'run',\n",
       "  'unit',\n",
       "  'month',\n",
       "  'think',\n",
       "  'product',\n",
       "  'think',\n",
       "  'bit',\n",
       "  'dust',\n",
       "  'crack',\n",
       "  'dismiss',\n",
       "  'lack',\n",
       "  'purchase',\n",
       "  'another',\n",
       "  'one',\n",
       "  'would',\n",
       "  'lack',\n",
       "  'purchase',\n",
       "  'another',\n",
       "  'one'],\n",
       " ['forever',\n",
       "  'buffer',\n",
       "  'charge',\n",
       "  \"n't\",\n",
       "  'follow',\n",
       "  'anything',\n",
       "  'without',\n",
       "  'break',\n",
       "  'buy',\n",
       "  'day',\n",
       "  'positive',\n",
       "  'function',\n",
       "  'reward',\n",
       "  'yield',\n",
       "  'close',\n",
       "  'yield',\n",
       "  'future',\n",
       "  'zero',\n",
       "  'yield',\n",
       "  'fully',\n",
       "  'damage',\n",
       "  'power',\n",
       "  'lack',\n",
       "  'money',\n",
       "  'second',\n",
       "  'contain',\n",
       "  'prove',\n",
       "  'function',\n",
       "  'second',\n",
       "  'previous',\n",
       "  'stream',\n",
       "  'device',\n",
       "  'bed',\n",
       "  'internet',\n",
       "  'help',\n",
       "  'return',\n",
       "  'non',\n",
       "  'trouble',\n",
       "  'device',\n",
       "  'current'],\n",
       " ['evil'],\n",
       " ['refund',\n",
       "  'loose',\n",
       "  'device',\n",
       "  'continue',\n",
       "  'arrive',\n",
       "  'fault',\n",
       "  'app',\n",
       "  'unable',\n",
       "  'clear',\n",
       "  'clock',\n",
       "  'shoot',\n",
       "  'drop',\n",
       "  'clock',\n",
       "  'contain',\n",
       "  'run',\n",
       "  'properly',\n",
       "  'eye',\n",
       "  'point',\n",
       "  'picture',\n",
       "  'positive',\n",
       "  'dumb',\n",
       "  'clear',\n",
       "  'apps'],\n",
       " ['lack',\n",
       "  'hear',\n",
       "  'music',\n",
       "  'arrive',\n",
       "  'several',\n",
       "  'echo/dot',\n",
       "  'whole',\n",
       "  'simultaneously',\n",
       "  'must',\n",
       "  'yield',\n",
       "  'monthly',\n",
       "  'fee',\n",
       "  'suppose',\n",
       "  'non',\n",
       "  'apple',\n",
       "  'yield',\n",
       "  'many',\n",
       "  'could',\n",
       "  'one',\n",
       "  'way',\n",
       "  'non',\n",
       "  'plenty',\n",
       "  'money'],\n",
       " ['good', 'awful', 'care', 'tin', 'screw', 'particular', 'terrible'],\n",
       " ['horrible', 'book', 'call', 'flash', 'device', 'bos', 'one', 'non', 'cause'],\n",
       " ['forever', 'run'],\n",
       " ['real',\n",
       "  'glad',\n",
       "  'original',\n",
       "  'view',\n",
       "  'become',\n",
       "  'function',\n",
       "  'bedroom',\n",
       "  'real',\n",
       "  'disappoint',\n",
       "  'sound',\n",
       "  'choice',\n",
       "  'link',\n",
       "  'external',\n",
       "  'speaker',\n",
       "  'via',\n",
       "  'bluetooth',\n",
       "  'sound',\n",
       "  'practically',\n",
       "  'sound',\n",
       "  'depart',\n",
       "  'trouble',\n",
       "  'free',\n",
       "  'link',\n",
       "  'wifi',\n",
       "  'presumably',\n",
       "  'due',\n",
       "  'noise',\n",
       "  'bluetooth',\n",
       "  'link',\n",
       "  'speaker',\n",
       "  'via',\n",
       "  'auxiliary',\n",
       "  'jack',\n",
       "  'auxiliary',\n",
       "  'jack',\n",
       "  'clean',\n",
       "  'noise',\n",
       "  'wifi',\n",
       "  'wake',\n",
       "  'eye',\n",
       "  'dark',\n",
       "  'horrible',\n",
       "  'buzzing',\n",
       "  'good',\n",
       "  'hop',\n",
       "  'deal',\n",
       "  'matter',\n",
       "  'second',\n",
       "  'yield',\n",
       "  'sound',\n",
       "  'bargain',\n",
       "  'position',\n",
       "  'trust',\n",
       "  'sound',\n",
       "  'nightstand',\n",
       "  'device'],\n",
       " ['take', 'harvard', 'law', 'point', 'run', 'matter', 'second', 'shortly'],\n",
       " ['fine',\n",
       "  'position',\n",
       "  'take',\n",
       "  'one',\n",
       "  'massive',\n",
       "  'fail',\n",
       "  'range',\n",
       "  'number',\n",
       "  'recur',\n",
       "  'alert',\n",
       "  'morning',\n",
       "  'fairly',\n",
       "  'practically',\n",
       "  'speak',\n",
       "  'non',\n",
       "  'matter',\n",
       "  'usually',\n",
       "  'lack',\n",
       "  'low',\n",
       "  'wake',\n",
       "  'screw',\n",
       "  'partner',\n",
       "  'definitely',\n",
       "  'dislike',\n",
       "  'yes',\n",
       "  'manually',\n",
       "  'hook',\n",
       "  'alert',\n",
       "  'font',\n",
       "  'drop',\n",
       "  'hook',\n",
       "  'quite',\n",
       "  'relate',\n",
       "  'cover',\n",
       "  'half',\n",
       "  'numb',\n",
       "  'hard',\n",
       "  'solution',\n",
       "  'correct',\n",
       "  'snooze',\n",
       "  'half',\n",
       "  'clock',\n",
       "  'regular',\n",
       "  'real',\n",
       "  'prove',\n",
       "  'hook',\n",
       "  'drop',\n",
       "  'care',\n",
       "  'hook',\n",
       "  'drop',\n",
       "  'whole',\n",
       "  'cancel',\n",
       "  'repeat',\n",
       "  'alarm.this',\n",
       "  'especially',\n",
       "  'irritate',\n",
       "  'could',\n",
       "  'easy',\n",
       "  'ready',\n",
       "  'simply',\n",
       "  'brand',\n",
       "  'relate',\n",
       "  'cover',\n",
       "  'number',\n",
       "  'alert',\n",
       "  'enter',\n",
       "  'least',\n",
       "  'brand',\n",
       "  'correct',\n",
       "  'determine',\n",
       "  'whether',\n",
       "  'relate',\n",
       "  'cover',\n",
       "  'repeat',\n",
       "  'alert',\n",
       "  'snooze',\n",
       "  'number',\n",
       "  'time',\n",
       "  'year',\n",
       "  'yet',\n",
       "  'subtract',\n",
       "  'put',\n",
       "  'clear',\n",
       "  'dematerialize',\n",
       "  'may',\n",
       "  'bad',\n",
       "  'product',\n",
       "  'purpose',\n",
       "  'love',\n",
       "  'always',\n",
       "  'brand'],\n",
       " ['real', 'run', 'still', 'brand', 'look', 'care'],\n",
       " ['run',\n",
       "  'good',\n",
       "  'month',\n",
       "  'contain',\n",
       "  'link',\n",
       "  'internet',\n",
       "  'wifi',\n",
       "  'none',\n",
       "  'upset',\n",
       "  'flash',\n",
       "  'attempt',\n",
       "  'run',\n",
       "  'customer',\n",
       "  'help',\n",
       "  'could',\n",
       "  \"n't\",\n",
       "  'assist',\n",
       "  'far',\n",
       "  'differentiate',\n",
       "  'guarantee',\n",
       "  'month',\n",
       "  'disappoint',\n",
       "  'disinherit',\n",
       "  'exchange'],\n",
       " ['dislike',\n",
       "  'virtually',\n",
       "  'everytime',\n",
       "  'expect',\n",
       "  'head',\n",
       "  'would',\n",
       "  'state',\n",
       "  'dont',\n",
       "  'bed',\n",
       "  'havent',\n",
       "  'determine'],\n",
       " ['reply', 'funny', 'speak', \"'ve\", 'disconnect', 'smell', 'care', 'spot'],\n",
       " ['practically', 'damage', 'couple', 'speaker'],\n",
       " ['product',\n",
       "  'attractive',\n",
       "  'fairly',\n",
       "  'useful',\n",
       "  'opt',\n",
       "  'push',\n",
       "  'user',\n",
       "  'consider',\n",
       "  'matter',\n",
       "  'prove',\n",
       "  'trend',\n",
       "  'greatly',\n",
       "  'depreciate',\n",
       "  'value',\n",
       "  'product',\n",
       "  'deal',\n",
       "  'unless',\n",
       "  'leave',\n",
       "  'consider',\n",
       "  'billboard'],\n",
       " ['run', 'fine', 'clear', 'take', 'function'],\n",
       " ['dumb', 'compare'],\n",
       " ['honestly',\n",
       "  'care',\n",
       "  'clock',\n",
       "  'could',\n",
       "  'purchase',\n",
       "  'little',\n",
       "  'one',\n",
       "  'take',\n",
       "  'matter',\n",
       "  'less',\n",
       "  'half',\n",
       "  'purchase',\n",
       "  'picture',\n",
       "  'chat',\n",
       "  'never',\n",
       "  'real',\n",
       "  'function'],\n",
       " ['particular',\n",
       "  'long',\n",
       "  'run',\n",
       "  'month',\n",
       "  'function',\n",
       "  'disconnect',\n",
       "  'wifi',\n",
       "  'unresponsive',\n",
       "  'reset',\n",
       "  'request'],\n",
       " ['honestly',\n",
       "  'different',\n",
       "  'already',\n",
       "  'occasionally',\n",
       "  'date',\n",
       "  'language',\n",
       "  'call',\n",
       "  'hear',\n",
       "  'real',\n",
       "  \"n't\",\n",
       "  'date',\n",
       "  'difference'],\n",
       " ['charge',\n",
       "  'second',\n",
       "  'due',\n",
       "  'crackle',\n",
       "  'interference',\n",
       "  'number',\n",
       "  'look',\n",
       "  'refurbish',\n",
       "  'particular'],\n",
       " ['heavy',\n",
       "  'device',\n",
       "  'characteristic',\n",
       "  'awful',\n",
       "  'interaction',\n",
       "  'marvelous',\n",
       "  'family',\n",
       "  'automation',\n",
       "  'run',\n",
       "  'complete',\n",
       "  'contact',\n",
       "  'history',\n",
       "  'right',\n",
       "  'take',\n",
       "  'point',\n",
       "  'charge',\n",
       "  'fixing',\n",
       "  'cover',\n",
       "  'glitching',\n",
       "  'less',\n",
       "  'month',\n",
       "  'previous',\n",
       "  'already',\n",
       "  'take',\n",
       "  'low',\n",
       "  'fixing',\n",
       "  'charge',\n",
       "  'update',\n",
       "  'firmware',\n",
       "  'become',\n",
       "  'device',\n",
       "  'second',\n",
       "  'zero',\n",
       "  'run',\n",
       "  'update',\n",
       "  'new',\n",
       "  'firmware',\n",
       "  'run',\n",
       "  'week',\n",
       "  'late',\n",
       "  'bug',\n",
       "  'depart',\n",
       "  'screw',\n",
       "  'point',\n",
       "  'become',\n",
       "  'real',\n",
       "  'baffle',\n",
       "  'glitching'],\n",
       " ['run',\n",
       "  'good',\n",
       "  'month',\n",
       "  'contain',\n",
       "  'link',\n",
       "  'internet',\n",
       "  'wifi',\n",
       "  'none',\n",
       "  'upset',\n",
       "  'flash',\n",
       "  'attempt',\n",
       "  'run',\n",
       "  'customer',\n",
       "  'help',\n",
       "  'could',\n",
       "  \"n't\",\n",
       "  'assist',\n",
       "  'far',\n",
       "  'differentiate',\n",
       "  'guarantee',\n",
       "  'month',\n",
       "  'disappoint',\n",
       "  'disinherit',\n",
       "  'exchange'],\n",
       " ['yet',\n",
       "  'unable',\n",
       "  'link',\n",
       "  'device',\n",
       "  'although',\n",
       "  'state',\n",
       "  'shape',\n",
       "  'purchase',\n",
       "  'bridge',\n",
       "  'link',\n",
       "  'device',\n",
       "  'suppose',\n",
       "  'everything',\n",
       "  'would',\n",
       "  'sync',\n",
       "  'device',\n",
       "  'yet',\n",
       "  'non',\n",
       "  'learn',\n",
       "  'via',\n",
       "  'positive',\n",
       "  'expect',\n",
       "  'forward',\n",
       "  'characteristic',\n",
       "  'able',\n",
       "  'fun',\n",
       "  'music',\n",
       "  'watch',\n",
       "  'weather',\n",
       "  'etc',\n",
       "  'fine'],\n",
       " ['product',\n",
       "  'currently',\n",
       "  'two',\n",
       "  'touch',\n",
       "  'package',\n",
       "  'fault',\n",
       "  'brand',\n",
       "  'whole',\n",
       "  'unusable',\n",
       "  'board',\n",
       "  'homescreen',\n",
       "  'phone',\n",
       "  'matter',\n",
       "  'prove',\n",
       "  'help',\n",
       "  'prove',\n",
       "  'number',\n",
       "  'homescreen',\n",
       "  'board',\n",
       "  'non',\n",
       "  'one',\n",
       "  'default',\n",
       "  'homescreen',\n",
       "  'board',\n",
       "  'cycle',\n",
       "  'automatically',\n",
       "  'incredibly',\n",
       "  'irritate',\n",
       "  'correct',\n",
       "  'choose',\n",
       "  'board',\n",
       "  'cycle',\n",
       "  'rather',\n",
       "  'cycle',\n",
       "  'continuously',\n",
       "  'critically',\n",
       "  'put',\n",
       "  'loose',\n",
       "  'whole',\n",
       "  'correct',\n",
       "  'cycle',\n",
       "  'board',\n",
       "  'yet',\n",
       "  'keep',\n",
       "  'cycle',\n",
       "  'clock',\n",
       "  'reboot',\n",
       "  'device',\n",
       "  're-set',\n",
       "  'etc',\n",
       "  'etc.until',\n",
       "  'two',\n",
       "  'obvious',\n",
       "  'package',\n",
       "  'take',\n",
       "  'ready',\n",
       "  'view',\n",
       "  'product',\n",
       "  'useless'],\n",
       " ['charge',\n",
       "  'run',\n",
       "  'sound',\n",
       "  'remote',\n",
       "  'advance',\n",
       "  'regular',\n",
       "  'number',\n",
       "  'troubleshoot',\n",
       "  'step',\n",
       "  'run',\n",
       "  'link',\n",
       "  'charge',\n",
       "  'new',\n",
       "  'one',\n",
       "  'remote/no',\n",
       "  'room',\n",
       "  'contain',\n",
       "  'yield',\n",
       "  'become',\n",
       "  'run',\n",
       "  'heavy'],\n",
       " ['exchange', 'assistant', 'shop', 'job', 'helper'],\n",
       " ['dislike',\n",
       "  'non',\n",
       "  'charge',\n",
       "  'history',\n",
       "  'also',\n",
       "  'dumb',\n",
       "  'bed',\n",
       "  'non',\n",
       "  'internet',\n",
       "  'link',\n",
       "  'xbox',\n",
       "  'one',\n",
       "  'run',\n",
       "  'fine',\n",
       "  'deal',\n",
       "  'always',\n",
       "  'charge',\n",
       "  'anything'],\n",
       " ['product',\n",
       "  'finish',\n",
       "  'waste',\n",
       "  'money',\n",
       "  'expect',\n",
       "  'head',\n",
       "  'either',\n",
       "  'discount',\n",
       "  'serve',\n",
       "  'yield',\n",
       "  'damage',\n",
       "  'serve',\n",
       "  'determine',\n",
       "  'info',\n",
       "  'wikipedia'],\n",
       " ['run',\n",
       "  'good',\n",
       "  'month',\n",
       "  'contain',\n",
       "  'link',\n",
       "  'internet',\n",
       "  'wifi',\n",
       "  'none',\n",
       "  'upset',\n",
       "  'flash',\n",
       "  'attempt',\n",
       "  'run',\n",
       "  'customer',\n",
       "  'help',\n",
       "  'could',\n",
       "  \"n't\",\n",
       "  'assist',\n",
       "  'far',\n",
       "  'differentiate',\n",
       "  'guarantee',\n",
       "  'month',\n",
       "  'disappoint',\n",
       "  'disinherit',\n",
       "  'exchange'],\n",
       " ['refund',\n",
       "  'bit',\n",
       "  'garbage',\n",
       "  'shortly',\n",
       "  'potential',\n",
       "  'life',\n",
       "  'drop',\n",
       "  'advance',\n",
       "  'virtually',\n",
       "  'certain',\n",
       "  'little',\n",
       "  'customer',\n",
       "  'seldom',\n",
       "  'disappoint',\n",
       "  'hundred',\n",
       "  'non',\n",
       "  'thousand',\n",
       "  'purchases.i',\n",
       "  'family',\n",
       "  'automation',\n",
       "  'purchase',\n",
       "  'positive',\n",
       "  'specifically',\n",
       "  'built-in',\n",
       "  'along',\n",
       "  'around',\n",
       "  'zigbee',\n",
       "  'clean',\n",
       "  'exchange',\n",
       "  'sound',\n",
       "  'contain',\n",
       "  'subpar',\n",
       "  'regular',\n",
       "  'run',\n",
       "  'rarity',\n",
       "  'much',\n",
       "  'zero',\n",
       "  'could',\n",
       "  'non',\n",
       "  'disappoint',\n",
       "  'product',\n",
       "  'strongly',\n",
       "  'discourage',\n",
       "  'gift',\n",
       "  'amazon/zigbee',\n",
       "  'ecosystem',\n",
       "  'value',\n",
       "  'money',\n",
       "  'look',\n",
       "  'form',\n",
       "  'product',\n",
       "  'take',\n",
       "  'expect',\n",
       "  'elsewhere'],\n",
       " ['dislike',\n",
       "  'virtually',\n",
       "  'everytime',\n",
       "  'expect',\n",
       "  'head',\n",
       "  'would',\n",
       "  'state',\n",
       "  'dont',\n",
       "  'bed',\n",
       "  'havent',\n",
       "  'determine'],\n",
       " ['expect',\n",
       "  'fun',\n",
       "  'motown',\n",
       "  'wireless',\n",
       "  'pandora',\n",
       "  'continue',\n",
       "  'expect',\n",
       "  'lack',\n",
       "  'total',\n",
       "  'salsa',\n",
       "  'send',\n",
       "  'motown',\n",
       "  'finish',\n",
       "  'salsa',\n",
       "  'phonetically'],\n",
       " ['want', 'battery', 'draw', 'good', 'punch', 'particular'],\n",
       " ['real', 'run', 'still', 'brand', 'look', 'care'],\n",
       " ['dont', 'hope', '....'],\n",
       " ['device',\n",
       "  'non',\n",
       "  'interact',\n",
       "  'family',\n",
       "  'take',\n",
       "  'apple',\n",
       "  'device',\n",
       "  'disappoint'],\n",
       " ['take',\n",
       "  'purchase',\n",
       "  'become',\n",
       "  'run',\n",
       "  'samsung',\n",
       "  'many',\n",
       "  'device',\n",
       "  'lack',\n",
       "  'money',\n",
       "  'second',\n",
       "  'matter',\n",
       "  'funny',\n",
       "  'number',\n",
       "  'unless',\n",
       "  'purchase',\n",
       "  'another',\n",
       "  'charge',\n",
       "  'negate',\n",
       "  'half',\n",
       "  'device',\n",
       "  'deal',\n",
       "  'matter',\n",
       "  'unless',\n",
       "  'lack',\n",
       "  'drop',\n",
       "  'another',\n",
       "  'another',\n",
       "  'loose',\n",
       "  'many',\n",
       "  'device',\n",
       "  'must',\n",
       "  'evil',\n",
       "  'still',\n",
       "  'become',\n",
       "  'device',\n",
       "  'really',\n",
       "  'see',\n",
       "  'speak'],\n",
       " [\"n't\",\n",
       "  'function',\n",
       "  'apple',\n",
       "  'music',\n",
       "  'worthless',\n",
       "  'still',\n",
       "  'choice',\n",
       "  'also',\n",
       "  'short'],\n",
       " ['fairly', 'slow'],\n",
       " ['product', 'contain', 'run', 'refund', 'clock', 'operate'],\n",
       " ['care',\n",
       "  'sleep',\n",
       "  'way',\n",
       "  'second',\n",
       "  'inactivity',\n",
       "  'wake',\n",
       "  'close',\n",
       "  'follow',\n",
       "  'point'],\n",
       " ['disconnect', 'call', 'playlist'],\n",
       " ['buy', 'function', 'road', 'semi', 'loose', 'application'],\n",
       " ['heavy',\n",
       "  'sound',\n",
       "  'good',\n",
       "  'choice',\n",
       "  'functionality',\n",
       "  'smart',\n",
       "  'family',\n",
       "  'draw',\n",
       "  'automation',\n",
       "  'geo-fencing',\n",
       "  'music',\n",
       "  'sync',\n",
       "  'hue',\n",
       "  'z-wave',\n",
       "  'number',\n",
       "  'matter',\n",
       "  'sound',\n",
       "  'close',\n",
       "  'purchase',\n",
       "  'smartthing',\n",
       "  'shift',\n",
       "  'everything'],\n",
       " ['pair', 'day', 'head', 'disconnection', 'date', 'sound', 'reconnecting'],\n",
       " ['point', 'zero'],\n",
       " ['disconnect', 'call', 'playlist'],\n",
       " ['point',\n",
       "  'interruption',\n",
       "  'anything',\n",
       "  'cover',\n",
       "  'miss',\n",
       "  'channel',\n",
       "  'solution',\n",
       "  'timer',\n",
       "  'monitor',\n",
       "  'minute',\n",
       "  'previous',\n",
       "  'monitor',\n",
       "  'activate',\n",
       "  'prove',\n",
       "  'correct',\n",
       "  'monitor',\n",
       "  'return',\n",
       "  'point',\n",
       "  'would',\n",
       "  'decent',\n",
       "  'could',\n",
       "  'become',\n",
       "  'bit',\n",
       "  'together',\n",
       "  'really',\n",
       "  'ready',\n",
       "  'matter'],\n",
       " ['matter',\n",
       "  'hardly',\n",
       "  'run',\n",
       "  'choose',\n",
       "  'company',\n",
       "  'apps',\n",
       "  'stuff',\n",
       "  'suppose',\n",
       "  'could',\n",
       "  'package',\n",
       "  'charge',\n",
       "  'mine',\n",
       "  'second',\n",
       "  'asap',\n",
       "  'waste',\n",
       "  'money'],\n",
       " ['flash', 'flash', 'good'],\n",
       " ['disconnect', 'call', 'playlist'],\n",
       " ['charge',\n",
       "  'prove',\n",
       "  'new',\n",
       "  'element',\n",
       "  'unfortunately',\n",
       "  'regular',\n",
       "  'though',\n",
       "  'pick',\n",
       "  'away',\n",
       "  'router',\n",
       "  'become',\n",
       "  'madden',\n",
       "  'disconnect',\n",
       "  'buffer',\n",
       "  'suppose',\n",
       "  'short',\n",
       "  'device',\n",
       "  'think',\n",
       "  'deal',\n",
       "  'manage',\n",
       "  'take'],\n",
       " ['range'],\n",
       " ['weary',\n",
       "  'clean',\n",
       "  'conversation',\n",
       "  'passively',\n",
       "  'function',\n",
       "  'hear',\n",
       "  'chance',\n",
       "  'word',\n",
       "  'interest',\n",
       "  'want',\n",
       "  'would',\n",
       "  'button',\n",
       "  'something',\n",
       "  'widespread',\n",
       "  'promote',\n",
       "  'firmware',\n",
       "  'keep',\n",
       "  'non',\n",
       "  'listen',\n",
       "  'still'],\n",
       " ['disappoint',\n",
       "  'device',\n",
       "  'unable',\n",
       "  'approach',\n",
       "  'dec',\n",
       "  'aware',\n",
       "  'buy',\n",
       "  'trouble',\n",
       "  'device',\n",
       "  'sound',\n",
       "  'contain',\n",
       "  'run',\n",
       "  'throughout',\n",
       "  'day',\n",
       "  'date',\n",
       "  'prove',\n",
       "  'reply',\n",
       "  'window',\n",
       "  'clear',\n",
       "  'stop',\n",
       "  'information',\n",
       "  'expect',\n",
       "  'care',\n",
       "  'device',\n",
       "  'become',\n",
       "  'action',\n",
       "  'contain',\n",
       "  'run',\n",
       "  'dark',\n",
       "  'stop',\n",
       "  'newsflash',\n",
       "  'continue',\n",
       "  'disconnect',\n",
       "  'restart',\n",
       "  'device',\n",
       "  'depart',\n",
       "  'run',\n",
       "  'annoying',\n",
       "  'device',\n",
       "  'could',\n",
       "  'real',\n",
       "  'heavy',\n",
       "  'device',\n",
       "  'would',\n",
       "  'bit',\n",
       "  'care',\n",
       "  'big'],\n",
       " ['book', 'first'],\n",
       " ['really',\n",
       "  'trouble',\n",
       "  'run',\n",
       "  'alexi',\n",
       "  'stupid',\n",
       "  'head',\n",
       "  'expect',\n",
       "  'become',\n",
       "  'unsure',\n",
       "  'half',\n",
       "  'clock',\n",
       "  'yet',\n",
       "  'expect',\n",
       "  'head',\n",
       "  'alexi',\n",
       "  'state',\n",
       "  'unsure',\n",
       "  'music',\n",
       "  'heavy',\n",
       "  'run',\n",
       "  'good',\n",
       "  'far',\n",
       "  'baffle',\n",
       "  'know'],\n",
       " ['card', 'run', 'state', 'link', 'network'],\n",
       " ['non',\n",
       "  'crack',\n",
       "  'move',\n",
       "  'sink',\n",
       "  'would',\n",
       "  'tightness',\n",
       "  'anything',\n",
       "  'stupid',\n",
       "  'plenty',\n",
       "  'mark',\n",
       "  'among',\n",
       "  'spotify',\n",
       "  'history',\n",
       "  \"n't\",\n",
       "  'function',\n",
       "  'either',\n",
       "  'randomly',\n",
       "  'talk',\n",
       "  'nobody',\n",
       "  'speak',\n",
       "  'today',\n",
       "  'disconnect',\n",
       "  'unsure',\n",
       "  \"'ll\",\n",
       "  'always',\n",
       "  'function'],\n",
       " ['garbage',\n",
       "  'regular',\n",
       "  'prove',\n",
       "  'follow',\n",
       "  'picture',\n",
       "  'bit',\n",
       "  'garbage',\n",
       "  'loos',\n",
       "  'internet',\n",
       "  'link',\n",
       "  'half',\n",
       "  'room',\n",
       "  'thru',\n",
       "  'point',\n",
       "  'flash',\n",
       "  'run',\n",
       "  'clock',\n",
       "  'good',\n",
       "  'conserve',\n",
       "  'clock',\n",
       "  'money',\n",
       "  'bit',\n",
       "  'garbage'],\n",
       " ['purchase',\n",
       "  'refurbish',\n",
       "  'contain',\n",
       "  'whatever',\n",
       "  'occasion',\n",
       "  'performing',\n",
       "  'rather',\n",
       "  'much',\n",
       "  'cause_to_sleep',\n",
       "  'every',\n",
       "  'clock',\n",
       "  'randomly',\n",
       "  'number',\n",
       "  'zero',\n",
       "  'deal',\n",
       "  'refurbish'],\n",
       " [\"n't\",\n",
       "  'week',\n",
       "  'already',\n",
       "  'disconnect',\n",
       "  'network',\n",
       "  'prove',\n",
       "  'reconnecting',\n",
       "  'manually',\n",
       "  'never',\n",
       "  'look',\n",
       "  'name',\n",
       "  'device',\n",
       "  'link',\n",
       "  'room',\n",
       "  'second'],\n",
       " ['forever',\n",
       "  'lack',\n",
       "  'one',\n",
       "  'till',\n",
       "  'become',\n",
       "  'one',\n",
       "  'non',\n",
       "  'super',\n",
       "  'heavy',\n",
       "  'navigate',\n",
       "  'really',\n",
       "  'care',\n",
       "  'good'],\n",
       " ['never',\n",
       "  'could',\n",
       "  'become',\n",
       "  'run',\n",
       "  'techie',\n",
       "  'friend',\n",
       "  'expect',\n",
       "  'state',\n",
       "  'adapter',\n",
       "  'impotent',\n",
       "  'plenty',\n",
       "  'office',\n",
       "  'expect',\n",
       "  'care',\n",
       "  'purchase',\n",
       "  'buck',\n",
       "  'shop',\n",
       "  'exchange',\n",
       "  'adapter',\n",
       "  'trust',\n",
       "  'run']]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_artifical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_cleaning(new_sent_tok, n):\n",
    "\n",
    "    tot_tokens = []\n",
    "\n",
    "    for sent in new_sent_tok:\n",
    "        for tok in sent:\n",
    "            tot_tokens.append(tok)\n",
    "\n",
    "    freqs = nltk.FreqDist(tot_tokens)\n",
    "    cleaned_reviews = []\n",
    "\n",
    "    for sent in new_sent_tok:\n",
    "        clean_sent = []\n",
    "        for tok in sent:\n",
    "            if freqs[tok] > n:\n",
    "                clean_sent.append(tok)\n",
    "        cleaned_reviews.append(clean_sent)\n",
    "\n",
    "    return cleaned_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino token con freq minore di 5\n",
    "cleaned_reviews = frequency_cleaning(new_sent_tok, 4)\n",
    "negative_artificial_cleaned = cleaned_reviews[-len(negative_artifical):]\n",
    "del cleaned_reviews[-len(negative_artifical):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item',\n",
       " 'longer',\n",
       " 'work',\n",
       " 'month',\n",
       " 'use',\n",
       " 'unplug',\n",
       " 'wifi',\n",
       " 'unresponsive',\n",
       " 'reset',\n",
       " 'request']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = Phrases(cleaned_reviews) #estrae le collocazioni tramite PMI\n",
    "bigrams[cleaned_reviews][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(bigrams[cleaned_reviews], list(dataset[\"feedback\"].values), test_size=0.20, random_state=10)\n",
    "X_train.extend(negative_artificial_cleaned)\n",
    "Y_train.extend([0 for x in range(len(negative_artifical))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[4.77421922e-04 2.26304836e-03 2.17009964e-04 2.01887156e-03\n 1.00821222e-02 3.44804721e-03 2.65234401e-03 6.30897361e-03\n 4.13153586e-04 2.01608914e-02 2.98388701e-04 3.09135267e-03\n 4.59059540e-05 3.88117326e-02 4.24375041e-04 3.03125030e-04\n 1.38111342e-03 3.48992633e-04 7.71590984e-05 9.72526137e-04\n 9.78342681e-04 8.28857503e-04 1.65771501e-05 1.85664081e-03\n 3.61013490e-04 5.14393990e-04 1.02304697e-03 2.48347811e-03\n 3.31543001e-04 1.32617200e-04 7.85233424e-04 3.01402728e-04\n 4.33704507e-03 2.45511843e-03 3.31543001e-04 3.11919240e-03\n 3.36212621e-03 2.65392279e-03 2.54992390e-02 3.05019561e-03\n 4.64160202e-04 1.49194351e-04 1.76822934e-04 1.02013231e-03\n 1.91631855e-03 1.22010111e-02 2.37728611e-03 1.56020236e-05\n 1.31702599e-03 1.51906975e-03 1.19355480e-04 5.22307743e-03\n 9.76504653e-03 7.29394602e-04 4.71527824e-04 1.54567634e-03\n 9.28320403e-04 1.25986340e-03 2.74771939e-03 3.52727307e-03\n 8.86124021e-04 1.32617200e-03 8.65745685e-03 3.15066319e-03\n 8.52539146e-05 1.06191273e-03 1.06462141e-03 2.63284148e-03\n 3.31543001e-05 8.55542671e-04 9.11901131e-04 6.97179185e-03\n 1.49194351e-04 4.52051675e-03 1.30456220e-02 1.72402361e-03\n 3.31543001e-04 1.98925801e-04 3.97899651e-03 5.69201444e-03\n 8.69418851e-03 6.72418324e-03 5.60307672e-04 1.40308998e-03\n 4.11113321e-03 8.32158704e-03 4.78077721e-03 6.82031317e-04\n 2.65234401e-04 1.60466813e-03 3.39351304e-03 4.14428751e-04\n 1.34912498e-03 4.97314502e-05 4.64160202e-04 1.23436010e-03\n 1.66365309e-03 7.10868381e-03 9.86735122e-04 5.61672849e-04\n 2.56746900e-03 9.20669411e-04 3.26442340e-04 2.98388701e-04\n 5.51737598e-04 2.44933768e-03 1.10514334e-04 3.03440785e-03\n 2.16608094e-04 4.99864832e-04 1.28070325e-03 1.47687337e-03\n 6.82031317e-04 1.33722344e-03 2.27584602e-03 6.14276890e-03\n 3.33735463e-03 4.47737978e-03 1.66686102e-03 1.03526976e-03\n 3.58066441e-04 5.04174012e-03 3.83642616e-04 2.30638609e-03\n 7.07291736e-04 3.50192295e-04 4.54687544e-04 6.17180048e-04\n 1.30999918e-04 7.45971753e-04 2.12924283e-03 1.20561091e-03\n 1.70022052e-04 3.18281281e-03 2.36009499e-03 6.13828185e-04\n 4.73632859e-04 7.69528755e-04 3.61013490e-04 8.52539146e-05\n 2.59374571e-03 9.58159273e-04 4.48154677e-04 7.80101179e-04\n 1.98117159e-03 5.96777402e-04 2.57014897e-03 4.77421922e-04\n 5.42077845e-03 2.65837206e-03 3.81614495e-03 5.96777402e-04\n 8.52539146e-04 5.30468802e-04 4.54687544e-04 3.31543001e-04\n 1.81545968e-03 1.25986340e-03 1.57533159e-03 6.63086002e-05\n 1.32617200e-04 1.76822934e-04 1.46413667e-03 1.92897746e-04\n 6.78156139e-04 3.14558693e-03 1.32617200e-04 2.65234401e-04\n 4.45741146e-04 2.41393106e-04 2.03070088e-04 3.75827673e-03\n 4.04166706e-04 3.22259797e-03 1.16467848e-03 9.64488731e-05\n 5.39497428e-03 3.86672300e-03 1.25986340e-03 6.49824282e-04\n 8.84114670e-05 1.12724620e-03 3.97851601e-04 2.65234401e-04\n 5.30468802e-04 1.32617200e-03 7.53506821e-05 9.20669411e-04\n 2.74144619e-03 2.45080076e-03 4.64160202e-04 3.31543001e-04\n 3.16987455e-04 6.82031317e-04 8.93421140e-04 3.53645868e-04\n 3.31543001e-04 2.65234401e-04 1.24512816e-03 1.76822934e-03\n 1.49415379e-03 3.97851601e-04 4.73632859e-04 7.29394602e-04\n 1.00220713e-03 9.58159273e-04 2.49932416e-04 6.59185496e-04\n 7.22026980e-04 1.21791307e-03 1.50764817e-03 1.76822934e-04\n 4.64160202e-04 2.18091711e-03 3.53645868e-04 5.14393990e-04\n 1.29915739e-03 5.30468802e-04 1.20231254e-03 1.47307106e-03\n 6.17180048e-04 5.96777402e-04 2.46872019e-03 1.01148712e-03\n 2.41122183e-05 6.28703765e-04 4.01167031e-04 1.98925801e-04\n 2.07214376e-04 4.95500398e-03 1.00706187e-03 6.02805457e-06\n 5.01458789e-04 7.10449288e-04 4.14428751e-04 1.65609772e-03\n 9.94629003e-04 4.42057335e-05 2.65234401e-04 1.98925801e-04\n 2.53734504e-03 1.50701364e-04 6.02805457e-06 3.15755239e-04\n 2.76285834e-04 2.16134461e-03 7.95703203e-04 4.24375041e-04\n 4.64160202e-04 1.06093760e-04 3.03125030e-04 6.17180048e-04\n 1.53492130e-03 2.55761744e-04 2.32080101e-03 1.74267290e-03\n 3.48189223e-03 1.98925801e-04 1.21147605e-03 5.10066156e-04\n 3.41790694e-03 5.96777402e-04 3.97851601e-04 6.49824282e-04\n 1.98925801e-04 3.97851601e-04 1.28373450e-03 2.98388701e-04\n 4.88272420e-04 1.12724620e-03 7.95703203e-04 1.48316737e-03\n 8.48750083e-04 6.79000066e-04 3.85795492e-04 1.99478372e-03\n 3.33735463e-03 1.77993086e-03 2.65234401e-04 2.95374674e-04\n 9.16953215e-04 8.30298994e-04 2.85812932e-03 2.65234401e-04\n 8.08333412e-04 1.42906466e-03 1.32617200e-04 1.06093760e-04\n 1.46481726e-03 7.66527419e-04 4.06140176e-04 2.12187521e-04\n 1.65771501e-03 1.10514334e-04 2.23355285e-04 5.83839139e-04\n 1.65771501e-03 5.30468802e-04 5.02549391e-04 3.90050590e-04\n 2.76285834e-04 1.78684228e-03 7.66527419e-04 1.91124789e-04\n 9.94629003e-05 1.03168381e-03 4.88272420e-04 3.31543001e-04\n 2.70760118e-04 5.61672849e-04 2.36816429e-04 1.12724620e-03\n 3.31543001e-04 2.22870573e-04 2.65234401e-04 1.20561091e-03\n 6.84025560e-04 1.55932160e-03 2.98388701e-04 1.51562515e-04\n 1.51562515e-04 2.07214376e-04 2.17612770e-03 1.65771501e-04\n 5.96777402e-04 4.82244365e-05 4.71527824e-04 1.49194351e-04\n 1.46336221e-04 3.31543001e-05 1.06093760e-03 8.84114670e-05\n 2.21028667e-05 4.14428751e-04 7.57812574e-05 8.93421140e-04\n 7.95703203e-04 2.65234401e-04 1.51562515e-04 1.17881956e-04\n 2.98388701e-04 3.31543001e-04 1.06977875e-03 9.43922427e-04\n 5.32836966e-04 1.32617200e-04 3.31543001e-04 3.31543001e-04\n 4.22281086e-04 5.30468802e-04 2.32080101e-04 2.23355285e-04\n 6.84399481e-04 5.52571669e-04 5.96777402e-04 2.01725497e-03\n 3.97851601e-04 2.65234401e-04 2.65234401e-04 4.88272420e-04\n 1.84190556e-04 5.96777402e-04 8.62011803e-04 3.05168569e-03\n 3.97851601e-04 3.24912141e-04 4.77421922e-04 9.94629003e-04\n 4.13153586e-04 1.63221170e-04 2.54890259e-03 3.44862887e-03\n 2.70760118e-04 3.31543001e-04 3.31543001e-04 3.67247632e-04\n 6.63086002e-04 3.31543001e-04 2.36816429e-04 3.97851601e-04\n 8.62011803e-04 1.25986340e-03 5.89797549e-04 3.97851601e-04\n 1.51562515e-04 5.34889375e-04 5.96777402e-04 6.18880269e-04\n 1.74570142e-03 1.32617200e-05 5.42524911e-05 2.49000226e-03\n 2.49932416e-04 9.94629003e-04 1.62456071e-04 8.28857503e-04\n 3.31543001e-04 9.28320403e-04 4.59059540e-05 9.58159273e-04\n 2.58817440e-04 5.30468802e-04 9.57496187e-04 3.53645868e-04\n 1.20561091e-03 4.64160202e-04 6.63086002e-05 8.54907310e-04\n 1.10514334e-05 4.47583052e-04 8.45772962e-04 7.71590984e-04\n 2.78496121e-03 3.31543001e-04 8.52539146e-05 2.12187521e-04\n 2.65234401e-04 3.31543001e-04 2.07214376e-04 1.65771501e-04\n 4.88272420e-04 3.97851601e-04 4.24375041e-04 6.68611719e-04\n 1.55932160e-03 1.49194351e-04 2.17009964e-04 2.65234401e-04\n 2.03070088e-04 5.30468802e-05 2.65234401e-04 8.77613827e-04\n 1.10514334e-05 3.01402728e-04 3.97851601e-04 3.97851601e-04\n 8.62011803e-04 2.98388701e-04 2.05556661e-03 1.17881956e-04\n 3.97851601e-04 8.52539146e-05 1.51562515e-04 3.90050590e-04\n 1.49194351e-04 1.19355480e-04 2.65234401e-04 1.83623816e-04\n 1.65771501e-04 5.30468802e-04 4.48154677e-04 1.40418212e-04\n 9.94629003e-05 7.29394602e-04 5.01458789e-04 5.37099662e-04\n 4.88272420e-04 9.28320403e-04 3.55224644e-04 2.88298262e-04\n 5.30468802e-04 2.98388701e-04 2.70760118e-04 3.61013490e-04\n 5.64328513e-04 3.97851601e-04 8.48750083e-04 1.19355480e-04\n 1.08304047e-03 3.97851601e-04 4.15149497e-04 6.63086002e-05\n 8.08333412e-04 1.19355480e-04 6.82031317e-04 1.84190556e-04\n 2.36816429e-04 1.03607188e-04 8.95166103e-04 4.42057335e-05\n 1.12724620e-03 5.02549391e-04 2.65234401e-04 2.65234401e-04\n 2.65234401e-04 1.06093760e-04 5.30468802e-04 6.63086002e-05\n 3.97851601e-04 3.94767480e-04 3.61013490e-04 1.17881956e-04\n 1.84190556e-04 1.13073613e-03 5.04294354e-04 5.30468802e-04\n 1.19355480e-04 3.64697301e-04 8.08333412e-04 8.99416654e-04\n 5.96777402e-04 1.65771501e-05 7.55609630e-05 9.82349633e-04\n 6.63086002e-05 3.01402728e-04 2.44136210e-04 2.21028667e-05\n 1.06093760e-04 6.36562562e-04 9.64488731e-05 4.64160202e-04\n 3.97851601e-04 1.54812162e-03 1.76822934e-04 6.63086002e-05\n 1.32617200e-04 2.17009964e-04 9.94629003e-05 3.72985876e-05\n 1.32617200e-05 9.97391862e-04 1.16467848e-03 4.97314502e-05\n 7.57812574e-05 7.55609630e-05 5.60307672e-04 5.96777402e-04\n 5.10066156e-04 2.65234401e-04 9.47265718e-06 5.30468802e-04\n 8.16105849e-05 7.95703203e-04 3.97851601e-04 1.13671886e-04\n 9.76544840e-04 2.65234401e-04 3.31543001e-04 2.65234401e-05\n 1.98925801e-04 3.31543001e-04 4.47583052e-04 2.94704890e-05\n 2.82916694e-04 4.88272420e-04 2.04026462e-05 1.76822934e-04\n 1.51562515e-04 6.63086002e-05 2.98388701e-04 5.96777402e-04\n 4.64160202e-04 3.97851601e-04 6.63086002e-05 1.56020236e-05\n 1.32617200e-04 9.47265718e-06 1.50701364e-04 9.94629003e-05\n 3.97851601e-04 7.47076896e-04 3.31543001e-04 3.53645868e-04\n 2.65234401e-04 3.58066441e-04 1.69750017e-04 2.65234401e-04\n 5.30468802e-05 4.64160202e-04 1.98925801e-05 2.65234401e-04\n 1.65771501e-05 4.73632859e-04 3.41015658e-04 5.30468802e-05\n 9.64488731e-05 4.42057335e-05 6.63086002e-05 2.65234401e-04\n 5.30468802e-05 4.45741146e-04 2.45587408e-04 5.37099662e-04\n 1.63221170e-04 5.52571669e-04 8.52539146e-05 6.71374577e-04\n 2.21028667e-05 4.19241472e-04 3.81937537e-04 1.98925801e-04\n 5.30468802e-04 3.97851601e-04 2.65234401e-04 5.96777402e-04\n 4.99864832e-04 9.76544840e-04 4.24375041e-04 1.18408215e-04\n 3.97851601e-04 4.06140176e-04 1.80506745e-04 1.98925801e-04\n 3.31543001e-05 1.25986340e-03 6.63086002e-05 1.51562515e-04\n 1.50701364e-04 3.31543001e-04 1.06093760e-04 3.24912141e-04\n 9.94629003e-04 4.42057335e-04 1.17881956e-04 4.64160202e-04\n 1.76822934e-04 6.06250059e-04 1.32617200e-04 3.31543001e-04\n 1.00858871e-03 2.07214376e-04 6.63086002e-04 2.88254745e-03\n 1.19355480e-04 1.32617200e-04 1.17881956e-04 5.96777402e-04\n 4.88272420e-04 1.49194351e-04 2.98388701e-04 6.60799499e-04\n 1.70507829e-04 4.64160202e-04 2.41122183e-05 5.30468802e-04\n 8.62011803e-04 4.24375041e-04 1.49194351e-04 1.65771501e-04\n 3.26442340e-04 2.16608094e-04 4.24375041e-04 7.47076896e-04\n 1.51562515e-04 2.65234401e-04 5.30468802e-05 1.32617200e-04\n 3.53645868e-04 1.32617200e-05 1.76822934e-04 4.64160202e-04\n 6.63086002e-05 9.94629003e-05 6.63086002e-05 3.31543001e-04\n 5.33626354e-04 7.29394602e-04 4.61277219e-05 4.71961213e-04\n 7.29394602e-04 1.65771501e-05 6.63086002e-05 6.49824282e-04\n 4.64160202e-04 3.26442340e-04 6.63086002e-05 2.03070088e-04\n 1.19355480e-04 3.85795492e-04 1.38142917e-04 3.31543001e-05\n 2.76285834e-04 1.19355480e-04 3.78906287e-05 1.65771501e-05\n 5.30468802e-05 3.97851601e-04 1.65771501e-04 1.16040050e-04\n 5.30468802e-04 4.97314502e-05 7.38043550e-04 9.64488731e-05\n 2.65234401e-04 4.64160202e-04 9.47265718e-06 8.28857503e-04\n 5.30468802e-05 1.65771501e-05 3.31543001e-04 4.26269573e-05\n 5.30468802e-04 3.31543001e-05 1.50701364e-04 1.03607188e-04\n 3.24912141e-04 8.84114670e-05 3.31543001e-04 2.36816429e-04\n 4.64160202e-04 1.70507829e-04 3.31543001e-04 1.98925801e-04\n 1.84190556e-04 2.36816429e-04 2.65234401e-04 3.31543001e-04\n 5.96777402e-04 5.30468802e-04 2.36816429e-04 1.19355480e-04\n 2.65234401e-04 3.31543001e-04 9.47265718e-06 2.65234401e-04\n 1.76822934e-04 6.63086002e-05 1.19355480e-04 6.63086002e-06\n 3.31543001e-04 3.31543001e-04 3.58066441e-04 1.89453144e-05\n 3.15755239e-06 2.07214376e-04 9.94629003e-05 1.51562515e-04\n 2.49932416e-04 3.31543001e-04 1.91124789e-04 6.63086002e-05\n 2.38710961e-04 4.42057335e-05 4.24375041e-04 7.07291736e-04\n 1.32617200e-05 1.76822934e-04 1.38142917e-04 5.30468802e-05\n 3.53645868e-04 8.84114670e-05 1.32617200e-04 3.31543001e-04\n 1.06093760e-04 8.84114670e-05 3.68381112e-04 1.19355480e-04\n 2.17009964e-04 3.31543001e-04 8.62011803e-04 3.31543001e-05\n 4.73632859e-04 1.76822934e-04 8.16105849e-05 1.17881956e-04\n 2.21028667e-06 4.42057335e-05 2.38710961e-04 4.42057335e-05\n 1.32617200e-05 3.78906287e-05 1.10514334e-05 1.32617200e-05\n 1.19355480e-04 2.65234401e-04 1.76822934e-04 6.17180048e-04\n 3.03125030e-04 3.61013490e-04 5.30468802e-05 1.98925801e-05\n 6.63086002e-05 4.64160202e-04 2.65234401e-04 2.11140543e-04\n 1.83623816e-04 2.21028667e-05 3.26442340e-04 2.12187521e-04\n 6.63086002e-05 3.83642616e-04 3.97851601e-04 2.02083353e-04\n 3.31543001e-04 1.40418212e-04 1.65771501e-04 8.52539146e-05\n 4.24375041e-04 6.63086002e-05 3.31543001e-04 3.31543001e-04\n 2.33521592e-04 3.24912141e-04 1.47687337e-04 4.64160202e-04\n 6.63086002e-05 5.30468802e-04 1.19355480e-04 1.98925801e-04\n 2.49932416e-04 2.65234401e-04 3.72985876e-05 7.45971753e-05\n 2.12187521e-04 1.65771501e-05 3.78906287e-05 3.78906287e-05\n 4.64160202e-04 1.65771501e-05 2.65234401e-04 2.65234401e-04\n 3.97851601e-04 6.63086002e-05 3.78906287e-05 9.94629003e-05\n 5.96777402e-04 9.94629003e-05 2.21028667e-05 3.31543001e-04\n 3.15755239e-04 2.65234401e-04 2.36816429e-04 3.31543001e-04\n 5.30468802e-04 7.45971753e-05 1.76822934e-04 1.51562515e-04\n 1.27516539e-04 1.32617200e-04 1.65771501e-05 2.21028667e-05\n 4.42057335e-05 9.94629003e-05 2.55033078e-06 1.65771501e-05\n 1.32617200e-04 8.16105849e-05 1.32617200e-05 8.52539146e-05\n 9.94629003e-05 5.30468802e-05 1.50701364e-04 1.76822934e-04\n 9.64488731e-05 1.32617200e-04 3.97851601e-04 1.19355480e-04\n 1.98925801e-04 7.53506821e-05 6.63086002e-05 3.31543001e-05\n 1.32617200e-05 5.30468802e-05 7.45971753e-05 8.28857503e-06\n 1.89453144e-05 1.65771501e-05 6.63086002e-05 8.52539146e-05\n 4.06140176e-04 5.30468802e-04 1.32617200e-05 5.30468802e-05\n 8.28857503e-06 2.38710961e-04 3.31543001e-05 1.49194351e-04\n 1.10514334e-05 3.97851601e-04 2.07214376e-04 1.76822934e-04\n 2.65234401e-04 5.30468802e-05 2.36816429e-04 2.98388701e-05\n 1.49194351e-04 8.52539146e-05 7.45971753e-05 1.47352445e-05\n 1.98925801e-04 1.32617200e-04 3.31543001e-04 6.02805457e-06\n 6.24080943e-05 3.92939853e-05 2.65234401e-04 3.15940978e-04\n 4.64160202e-04 1.10514334e-05 1.19355480e-04 1.32617200e-04\n 1.51562515e-04 2.76285834e-04 5.30468802e-05 2.94704890e-05\n 1.10514334e-05 1.39597053e-05 1.49194351e-04 2.07214376e-04\n 1.32617200e-04 2.94704890e-05 3.78906287e-05 1.19355480e-04\n 5.42524911e-05 5.42524911e-05 6.24080943e-05 6.63086002e-05\n 4.42057335e-05 4.64160202e-04 1.32617200e-05 3.78906287e-05\n 1.32617200e-05 1.32617200e-04 1.89453144e-05 3.31543001e-05\n 1.10514334e-05 4.42057335e-05 1.65771501e-05 1.10514334e-05\n 1.32617200e-04 1.32617200e-04 2.65234401e-05 6.63086002e-06\n 8.84114670e-05 1.32617200e-05 2.21028667e-05 1.10514334e-05\n 9.94629003e-05 7.36762225e-06 2.38710961e-05 8.52539146e-05\n 5.30468802e-05 1.65771501e-05 4.42057335e-05 6.63086002e-05\n 2.65234401e-04 1.10514334e-05 6.63086002e-05 9.47265718e-06\n 5.30468802e-05 9.47265718e-06 1.65771501e-05 5.30468802e-05\n 1.10514334e-05 8.84114670e-05 7.45971753e-05 2.65234401e-05\n 1.10514334e-05 6.63086002e-05 2.21028667e-05 9.94629003e-05\n 1.10514334e-05 1.65771501e-05 6.63086002e-05 9.47265718e-06\n 3.31543001e-05 3.48992633e-06 2.21028667e-05 1.10514334e-05\n 8.28857503e-06 2.21028667e-05 4.42057335e-06 3.48992633e-06\n 1.10514334e-05 2.21028667e-05 1.10514334e-05 8.55594842e-06\n 1.10514334e-05 1.10514334e-05 1.65771501e-05 9.47265718e-06\n 6.02805457e-06 9.47265718e-06 6.63086002e-05 1.32617200e-05\n 2.21028667e-05].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\crist\\OneDrive\\Desktop\\unipi\\ta\\progetto\\progettoTA\\cristiano_stuff.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/crist/OneDrive/Desktop/unipi/ta/progetto/progettoTA/cristiano_stuff.ipynb#X20sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     data_dict[\u001b[39m\"\u001b[39m\u001b[39mneg\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m neg_sorted\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/crist/OneDrive/Desktop/unipi/ta/progetto/progettoTA/cristiano_stuff.ipynb#X20sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m data_dict\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/crist/OneDrive/Desktop/unipi/ta/progetto/progettoTA/cristiano_stuff.ipynb#X20sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m data_dict \u001b[39m=\u001b[39m get_pos_neg_score(pos_tokenized, neg_tokenized)\n",
      "\u001b[1;32mc:\\Users\\crist\\OneDrive\\Desktop\\unipi\\ta\\progetto\\progettoTA\\cristiano_stuff.ipynb Cell 18\u001b[0m in \u001b[0;36mget_pos_neg_score\u001b[1;34m(pos, neg)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/crist/OneDrive/Desktop/unipi/ta/progetto/progettoTA/cristiano_stuff.ipynb#X20sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     data_dict[\u001b[39m\"\u001b[39m\u001b[39mneg\u001b[39m\u001b[39m\"\u001b[39m][w] \u001b[39m=\u001b[39m p_category \u001b[39m*\u001b[39m p\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/crist/OneDrive/Desktop/unipi/ta/progetto/progettoTA/cristiano_stuff.ipynb#X20sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m scaler \u001b[39m=\u001b[39m MinMaxScaler()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/crist/OneDrive/Desktop/unipi/ta/progetto/progettoTA/cristiano_stuff.ipynb#X20sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m scaled_pos \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mfit_transform(\u001b[39mlist\u001b[39;49m(data_dict[\u001b[39m\"\u001b[39;49m\u001b[39mpos\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues()))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/crist/OneDrive/Desktop/unipi/ta/progetto/progettoTA/cristiano_stuff.ipynb#X20sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m scaled_neg \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mfit_transform(\u001b[39mlist\u001b[39m(data_dict[\u001b[39m\"\u001b[39m\u001b[39mneg\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues()))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/crist/OneDrive/Desktop/unipi/ta/progetto/progettoTA/cristiano_stuff.ipynb#X20sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m data_dict[\u001b[39m\"\u001b[39m\u001b[39mpos\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(data_dict[\u001b[39m\"\u001b[39m\u001b[39mpos\u001b[39m\u001b[39m\"\u001b[39m], scaled_pos)}\n",
      "File \u001b[1;32mc:\\Users\\crist\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:867\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    868\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\crist\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:420\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 420\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y)\n",
      "File \u001b[1;32mc:\\Users\\crist\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:457\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMinMaxScaler does not support sparse input. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider using MaxAbsScaler instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m     )\n\u001b[0;32m    456\u001b[0m first_pass \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 457\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    458\u001b[0m     X,\n\u001b[0;32m    459\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_pass,\n\u001b[0;32m    460\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    461\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    462\u001b[0m )\n\u001b[0;32m    464\u001b[0m data_min \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmin(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    465\u001b[0m data_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmax(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\crist\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\crist\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    878\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 879\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    880\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    881\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    882\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    884\u001b[0m         )\n\u001b[0;32m    886\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    888\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    889\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    890\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[4.77421922e-04 2.26304836e-03 2.17009964e-04 2.01887156e-03\n 1.00821222e-02 3.44804721e-03 2.65234401e-03 6.30897361e-03\n 4.13153586e-04 2.01608914e-02 2.98388701e-04 3.09135267e-03\n 4.59059540e-05 3.88117326e-02 4.24375041e-04 3.03125030e-04\n 1.38111342e-03 3.48992633e-04 7.71590984e-05 9.72526137e-04\n 9.78342681e-04 8.28857503e-04 1.65771501e-05 1.85664081e-03\n 3.61013490e-04 5.14393990e-04 1.02304697e-03 2.48347811e-03\n 3.31543001e-04 1.32617200e-04 7.85233424e-04 3.01402728e-04\n 4.33704507e-03 2.45511843e-03 3.31543001e-04 3.11919240e-03\n 3.36212621e-03 2.65392279e-03 2.54992390e-02 3.05019561e-03\n 4.64160202e-04 1.49194351e-04 1.76822934e-04 1.02013231e-03\n 1.91631855e-03 1.22010111e-02 2.37728611e-03 1.56020236e-05\n 1.31702599e-03 1.51906975e-03 1.19355480e-04 5.22307743e-03\n 9.76504653e-03 7.29394602e-04 4.71527824e-04 1.54567634e-03\n 9.28320403e-04 1.25986340e-03 2.74771939e-03 3.52727307e-03\n 8.86124021e-04 1.32617200e-03 8.65745685e-03 3.15066319e-03\n 8.52539146e-05 1.06191273e-03 1.06462141e-03 2.63284148e-03\n 3.31543001e-05 8.55542671e-04 9.11901131e-04 6.97179185e-03\n 1.49194351e-04 4.52051675e-03 1.30456220e-02 1.72402361e-03\n 3.31543001e-04 1.98925801e-04 3.97899651e-03 5.69201444e-03\n 8.69418851e-03 6.72418324e-03 5.60307672e-04 1.40308998e-03\n 4.11113321e-03 8.32158704e-03 4.78077721e-03 6.82031317e-04\n 2.65234401e-04 1.60466813e-03 3.39351304e-03 4.14428751e-04\n 1.34912498e-03 4.97314502e-05 4.64160202e-04 1.23436010e-03\n 1.66365309e-03 7.10868381e-03 9.86735122e-04 5.61672849e-04\n 2.56746900e-03 9.20669411e-04 3.26442340e-04 2.98388701e-04\n 5.51737598e-04 2.44933768e-03 1.10514334e-04 3.03440785e-03\n 2.16608094e-04 4.99864832e-04 1.28070325e-03 1.47687337e-03\n 6.82031317e-04 1.33722344e-03 2.27584602e-03 6.14276890e-03\n 3.33735463e-03 4.47737978e-03 1.66686102e-03 1.03526976e-03\n 3.58066441e-04 5.04174012e-03 3.83642616e-04 2.30638609e-03\n 7.07291736e-04 3.50192295e-04 4.54687544e-04 6.17180048e-04\n 1.30999918e-04 7.45971753e-04 2.12924283e-03 1.20561091e-03\n 1.70022052e-04 3.18281281e-03 2.36009499e-03 6.13828185e-04\n 4.73632859e-04 7.69528755e-04 3.61013490e-04 8.52539146e-05\n 2.59374571e-03 9.58159273e-04 4.48154677e-04 7.80101179e-04\n 1.98117159e-03 5.96777402e-04 2.57014897e-03 4.77421922e-04\n 5.42077845e-03 2.65837206e-03 3.81614495e-03 5.96777402e-04\n 8.52539146e-04 5.30468802e-04 4.54687544e-04 3.31543001e-04\n 1.81545968e-03 1.25986340e-03 1.57533159e-03 6.63086002e-05\n 1.32617200e-04 1.76822934e-04 1.46413667e-03 1.92897746e-04\n 6.78156139e-04 3.14558693e-03 1.32617200e-04 2.65234401e-04\n 4.45741146e-04 2.41393106e-04 2.03070088e-04 3.75827673e-03\n 4.04166706e-04 3.22259797e-03 1.16467848e-03 9.64488731e-05\n 5.39497428e-03 3.86672300e-03 1.25986340e-03 6.49824282e-04\n 8.84114670e-05 1.12724620e-03 3.97851601e-04 2.65234401e-04\n 5.30468802e-04 1.32617200e-03 7.53506821e-05 9.20669411e-04\n 2.74144619e-03 2.45080076e-03 4.64160202e-04 3.31543001e-04\n 3.16987455e-04 6.82031317e-04 8.93421140e-04 3.53645868e-04\n 3.31543001e-04 2.65234401e-04 1.24512816e-03 1.76822934e-03\n 1.49415379e-03 3.97851601e-04 4.73632859e-04 7.29394602e-04\n 1.00220713e-03 9.58159273e-04 2.49932416e-04 6.59185496e-04\n 7.22026980e-04 1.21791307e-03 1.50764817e-03 1.76822934e-04\n 4.64160202e-04 2.18091711e-03 3.53645868e-04 5.14393990e-04\n 1.29915739e-03 5.30468802e-04 1.20231254e-03 1.47307106e-03\n 6.17180048e-04 5.96777402e-04 2.46872019e-03 1.01148712e-03\n 2.41122183e-05 6.28703765e-04 4.01167031e-04 1.98925801e-04\n 2.07214376e-04 4.95500398e-03 1.00706187e-03 6.02805457e-06\n 5.01458789e-04 7.10449288e-04 4.14428751e-04 1.65609772e-03\n 9.94629003e-04 4.42057335e-05 2.65234401e-04 1.98925801e-04\n 2.53734504e-03 1.50701364e-04 6.02805457e-06 3.15755239e-04\n 2.76285834e-04 2.16134461e-03 7.95703203e-04 4.24375041e-04\n 4.64160202e-04 1.06093760e-04 3.03125030e-04 6.17180048e-04\n 1.53492130e-03 2.55761744e-04 2.32080101e-03 1.74267290e-03\n 3.48189223e-03 1.98925801e-04 1.21147605e-03 5.10066156e-04\n 3.41790694e-03 5.96777402e-04 3.97851601e-04 6.49824282e-04\n 1.98925801e-04 3.97851601e-04 1.28373450e-03 2.98388701e-04\n 4.88272420e-04 1.12724620e-03 7.95703203e-04 1.48316737e-03\n 8.48750083e-04 6.79000066e-04 3.85795492e-04 1.99478372e-03\n 3.33735463e-03 1.77993086e-03 2.65234401e-04 2.95374674e-04\n 9.16953215e-04 8.30298994e-04 2.85812932e-03 2.65234401e-04\n 8.08333412e-04 1.42906466e-03 1.32617200e-04 1.06093760e-04\n 1.46481726e-03 7.66527419e-04 4.06140176e-04 2.12187521e-04\n 1.65771501e-03 1.10514334e-04 2.23355285e-04 5.83839139e-04\n 1.65771501e-03 5.30468802e-04 5.02549391e-04 3.90050590e-04\n 2.76285834e-04 1.78684228e-03 7.66527419e-04 1.91124789e-04\n 9.94629003e-05 1.03168381e-03 4.88272420e-04 3.31543001e-04\n 2.70760118e-04 5.61672849e-04 2.36816429e-04 1.12724620e-03\n 3.31543001e-04 2.22870573e-04 2.65234401e-04 1.20561091e-03\n 6.84025560e-04 1.55932160e-03 2.98388701e-04 1.51562515e-04\n 1.51562515e-04 2.07214376e-04 2.17612770e-03 1.65771501e-04\n 5.96777402e-04 4.82244365e-05 4.71527824e-04 1.49194351e-04\n 1.46336221e-04 3.31543001e-05 1.06093760e-03 8.84114670e-05\n 2.21028667e-05 4.14428751e-04 7.57812574e-05 8.93421140e-04\n 7.95703203e-04 2.65234401e-04 1.51562515e-04 1.17881956e-04\n 2.98388701e-04 3.31543001e-04 1.06977875e-03 9.43922427e-04\n 5.32836966e-04 1.32617200e-04 3.31543001e-04 3.31543001e-04\n 4.22281086e-04 5.30468802e-04 2.32080101e-04 2.23355285e-04\n 6.84399481e-04 5.52571669e-04 5.96777402e-04 2.01725497e-03\n 3.97851601e-04 2.65234401e-04 2.65234401e-04 4.88272420e-04\n 1.84190556e-04 5.96777402e-04 8.62011803e-04 3.05168569e-03\n 3.97851601e-04 3.24912141e-04 4.77421922e-04 9.94629003e-04\n 4.13153586e-04 1.63221170e-04 2.54890259e-03 3.44862887e-03\n 2.70760118e-04 3.31543001e-04 3.31543001e-04 3.67247632e-04\n 6.63086002e-04 3.31543001e-04 2.36816429e-04 3.97851601e-04\n 8.62011803e-04 1.25986340e-03 5.89797549e-04 3.97851601e-04\n 1.51562515e-04 5.34889375e-04 5.96777402e-04 6.18880269e-04\n 1.74570142e-03 1.32617200e-05 5.42524911e-05 2.49000226e-03\n 2.49932416e-04 9.94629003e-04 1.62456071e-04 8.28857503e-04\n 3.31543001e-04 9.28320403e-04 4.59059540e-05 9.58159273e-04\n 2.58817440e-04 5.30468802e-04 9.57496187e-04 3.53645868e-04\n 1.20561091e-03 4.64160202e-04 6.63086002e-05 8.54907310e-04\n 1.10514334e-05 4.47583052e-04 8.45772962e-04 7.71590984e-04\n 2.78496121e-03 3.31543001e-04 8.52539146e-05 2.12187521e-04\n 2.65234401e-04 3.31543001e-04 2.07214376e-04 1.65771501e-04\n 4.88272420e-04 3.97851601e-04 4.24375041e-04 6.68611719e-04\n 1.55932160e-03 1.49194351e-04 2.17009964e-04 2.65234401e-04\n 2.03070088e-04 5.30468802e-05 2.65234401e-04 8.77613827e-04\n 1.10514334e-05 3.01402728e-04 3.97851601e-04 3.97851601e-04\n 8.62011803e-04 2.98388701e-04 2.05556661e-03 1.17881956e-04\n 3.97851601e-04 8.52539146e-05 1.51562515e-04 3.90050590e-04\n 1.49194351e-04 1.19355480e-04 2.65234401e-04 1.83623816e-04\n 1.65771501e-04 5.30468802e-04 4.48154677e-04 1.40418212e-04\n 9.94629003e-05 7.29394602e-04 5.01458789e-04 5.37099662e-04\n 4.88272420e-04 9.28320403e-04 3.55224644e-04 2.88298262e-04\n 5.30468802e-04 2.98388701e-04 2.70760118e-04 3.61013490e-04\n 5.64328513e-04 3.97851601e-04 8.48750083e-04 1.19355480e-04\n 1.08304047e-03 3.97851601e-04 4.15149497e-04 6.63086002e-05\n 8.08333412e-04 1.19355480e-04 6.82031317e-04 1.84190556e-04\n 2.36816429e-04 1.03607188e-04 8.95166103e-04 4.42057335e-05\n 1.12724620e-03 5.02549391e-04 2.65234401e-04 2.65234401e-04\n 2.65234401e-04 1.06093760e-04 5.30468802e-04 6.63086002e-05\n 3.97851601e-04 3.94767480e-04 3.61013490e-04 1.17881956e-04\n 1.84190556e-04 1.13073613e-03 5.04294354e-04 5.30468802e-04\n 1.19355480e-04 3.64697301e-04 8.08333412e-04 8.99416654e-04\n 5.96777402e-04 1.65771501e-05 7.55609630e-05 9.82349633e-04\n 6.63086002e-05 3.01402728e-04 2.44136210e-04 2.21028667e-05\n 1.06093760e-04 6.36562562e-04 9.64488731e-05 4.64160202e-04\n 3.97851601e-04 1.54812162e-03 1.76822934e-04 6.63086002e-05\n 1.32617200e-04 2.17009964e-04 9.94629003e-05 3.72985876e-05\n 1.32617200e-05 9.97391862e-04 1.16467848e-03 4.97314502e-05\n 7.57812574e-05 7.55609630e-05 5.60307672e-04 5.96777402e-04\n 5.10066156e-04 2.65234401e-04 9.47265718e-06 5.30468802e-04\n 8.16105849e-05 7.95703203e-04 3.97851601e-04 1.13671886e-04\n 9.76544840e-04 2.65234401e-04 3.31543001e-04 2.65234401e-05\n 1.98925801e-04 3.31543001e-04 4.47583052e-04 2.94704890e-05\n 2.82916694e-04 4.88272420e-04 2.04026462e-05 1.76822934e-04\n 1.51562515e-04 6.63086002e-05 2.98388701e-04 5.96777402e-04\n 4.64160202e-04 3.97851601e-04 6.63086002e-05 1.56020236e-05\n 1.32617200e-04 9.47265718e-06 1.50701364e-04 9.94629003e-05\n 3.97851601e-04 7.47076896e-04 3.31543001e-04 3.53645868e-04\n 2.65234401e-04 3.58066441e-04 1.69750017e-04 2.65234401e-04\n 5.30468802e-05 4.64160202e-04 1.98925801e-05 2.65234401e-04\n 1.65771501e-05 4.73632859e-04 3.41015658e-04 5.30468802e-05\n 9.64488731e-05 4.42057335e-05 6.63086002e-05 2.65234401e-04\n 5.30468802e-05 4.45741146e-04 2.45587408e-04 5.37099662e-04\n 1.63221170e-04 5.52571669e-04 8.52539146e-05 6.71374577e-04\n 2.21028667e-05 4.19241472e-04 3.81937537e-04 1.98925801e-04\n 5.30468802e-04 3.97851601e-04 2.65234401e-04 5.96777402e-04\n 4.99864832e-04 9.76544840e-04 4.24375041e-04 1.18408215e-04\n 3.97851601e-04 4.06140176e-04 1.80506745e-04 1.98925801e-04\n 3.31543001e-05 1.25986340e-03 6.63086002e-05 1.51562515e-04\n 1.50701364e-04 3.31543001e-04 1.06093760e-04 3.24912141e-04\n 9.94629003e-04 4.42057335e-04 1.17881956e-04 4.64160202e-04\n 1.76822934e-04 6.06250059e-04 1.32617200e-04 3.31543001e-04\n 1.00858871e-03 2.07214376e-04 6.63086002e-04 2.88254745e-03\n 1.19355480e-04 1.32617200e-04 1.17881956e-04 5.96777402e-04\n 4.88272420e-04 1.49194351e-04 2.98388701e-04 6.60799499e-04\n 1.70507829e-04 4.64160202e-04 2.41122183e-05 5.30468802e-04\n 8.62011803e-04 4.24375041e-04 1.49194351e-04 1.65771501e-04\n 3.26442340e-04 2.16608094e-04 4.24375041e-04 7.47076896e-04\n 1.51562515e-04 2.65234401e-04 5.30468802e-05 1.32617200e-04\n 3.53645868e-04 1.32617200e-05 1.76822934e-04 4.64160202e-04\n 6.63086002e-05 9.94629003e-05 6.63086002e-05 3.31543001e-04\n 5.33626354e-04 7.29394602e-04 4.61277219e-05 4.71961213e-04\n 7.29394602e-04 1.65771501e-05 6.63086002e-05 6.49824282e-04\n 4.64160202e-04 3.26442340e-04 6.63086002e-05 2.03070088e-04\n 1.19355480e-04 3.85795492e-04 1.38142917e-04 3.31543001e-05\n 2.76285834e-04 1.19355480e-04 3.78906287e-05 1.65771501e-05\n 5.30468802e-05 3.97851601e-04 1.65771501e-04 1.16040050e-04\n 5.30468802e-04 4.97314502e-05 7.38043550e-04 9.64488731e-05\n 2.65234401e-04 4.64160202e-04 9.47265718e-06 8.28857503e-04\n 5.30468802e-05 1.65771501e-05 3.31543001e-04 4.26269573e-05\n 5.30468802e-04 3.31543001e-05 1.50701364e-04 1.03607188e-04\n 3.24912141e-04 8.84114670e-05 3.31543001e-04 2.36816429e-04\n 4.64160202e-04 1.70507829e-04 3.31543001e-04 1.98925801e-04\n 1.84190556e-04 2.36816429e-04 2.65234401e-04 3.31543001e-04\n 5.96777402e-04 5.30468802e-04 2.36816429e-04 1.19355480e-04\n 2.65234401e-04 3.31543001e-04 9.47265718e-06 2.65234401e-04\n 1.76822934e-04 6.63086002e-05 1.19355480e-04 6.63086002e-06\n 3.31543001e-04 3.31543001e-04 3.58066441e-04 1.89453144e-05\n 3.15755239e-06 2.07214376e-04 9.94629003e-05 1.51562515e-04\n 2.49932416e-04 3.31543001e-04 1.91124789e-04 6.63086002e-05\n 2.38710961e-04 4.42057335e-05 4.24375041e-04 7.07291736e-04\n 1.32617200e-05 1.76822934e-04 1.38142917e-04 5.30468802e-05\n 3.53645868e-04 8.84114670e-05 1.32617200e-04 3.31543001e-04\n 1.06093760e-04 8.84114670e-05 3.68381112e-04 1.19355480e-04\n 2.17009964e-04 3.31543001e-04 8.62011803e-04 3.31543001e-05\n 4.73632859e-04 1.76822934e-04 8.16105849e-05 1.17881956e-04\n 2.21028667e-06 4.42057335e-05 2.38710961e-04 4.42057335e-05\n 1.32617200e-05 3.78906287e-05 1.10514334e-05 1.32617200e-05\n 1.19355480e-04 2.65234401e-04 1.76822934e-04 6.17180048e-04\n 3.03125030e-04 3.61013490e-04 5.30468802e-05 1.98925801e-05\n 6.63086002e-05 4.64160202e-04 2.65234401e-04 2.11140543e-04\n 1.83623816e-04 2.21028667e-05 3.26442340e-04 2.12187521e-04\n 6.63086002e-05 3.83642616e-04 3.97851601e-04 2.02083353e-04\n 3.31543001e-04 1.40418212e-04 1.65771501e-04 8.52539146e-05\n 4.24375041e-04 6.63086002e-05 3.31543001e-04 3.31543001e-04\n 2.33521592e-04 3.24912141e-04 1.47687337e-04 4.64160202e-04\n 6.63086002e-05 5.30468802e-04 1.19355480e-04 1.98925801e-04\n 2.49932416e-04 2.65234401e-04 3.72985876e-05 7.45971753e-05\n 2.12187521e-04 1.65771501e-05 3.78906287e-05 3.78906287e-05\n 4.64160202e-04 1.65771501e-05 2.65234401e-04 2.65234401e-04\n 3.97851601e-04 6.63086002e-05 3.78906287e-05 9.94629003e-05\n 5.96777402e-04 9.94629003e-05 2.21028667e-05 3.31543001e-04\n 3.15755239e-04 2.65234401e-04 2.36816429e-04 3.31543001e-04\n 5.30468802e-04 7.45971753e-05 1.76822934e-04 1.51562515e-04\n 1.27516539e-04 1.32617200e-04 1.65771501e-05 2.21028667e-05\n 4.42057335e-05 9.94629003e-05 2.55033078e-06 1.65771501e-05\n 1.32617200e-04 8.16105849e-05 1.32617200e-05 8.52539146e-05\n 9.94629003e-05 5.30468802e-05 1.50701364e-04 1.76822934e-04\n 9.64488731e-05 1.32617200e-04 3.97851601e-04 1.19355480e-04\n 1.98925801e-04 7.53506821e-05 6.63086002e-05 3.31543001e-05\n 1.32617200e-05 5.30468802e-05 7.45971753e-05 8.28857503e-06\n 1.89453144e-05 1.65771501e-05 6.63086002e-05 8.52539146e-05\n 4.06140176e-04 5.30468802e-04 1.32617200e-05 5.30468802e-05\n 8.28857503e-06 2.38710961e-04 3.31543001e-05 1.49194351e-04\n 1.10514334e-05 3.97851601e-04 2.07214376e-04 1.76822934e-04\n 2.65234401e-04 5.30468802e-05 2.36816429e-04 2.98388701e-05\n 1.49194351e-04 8.52539146e-05 7.45971753e-05 1.47352445e-05\n 1.98925801e-04 1.32617200e-04 3.31543001e-04 6.02805457e-06\n 6.24080943e-05 3.92939853e-05 2.65234401e-04 3.15940978e-04\n 4.64160202e-04 1.10514334e-05 1.19355480e-04 1.32617200e-04\n 1.51562515e-04 2.76285834e-04 5.30468802e-05 2.94704890e-05\n 1.10514334e-05 1.39597053e-05 1.49194351e-04 2.07214376e-04\n 1.32617200e-04 2.94704890e-05 3.78906287e-05 1.19355480e-04\n 5.42524911e-05 5.42524911e-05 6.24080943e-05 6.63086002e-05\n 4.42057335e-05 4.64160202e-04 1.32617200e-05 3.78906287e-05\n 1.32617200e-05 1.32617200e-04 1.89453144e-05 3.31543001e-05\n 1.10514334e-05 4.42057335e-05 1.65771501e-05 1.10514334e-05\n 1.32617200e-04 1.32617200e-04 2.65234401e-05 6.63086002e-06\n 8.84114670e-05 1.32617200e-05 2.21028667e-05 1.10514334e-05\n 9.94629003e-05 7.36762225e-06 2.38710961e-05 8.52539146e-05\n 5.30468802e-05 1.65771501e-05 4.42057335e-05 6.63086002e-05\n 2.65234401e-04 1.10514334e-05 6.63086002e-05 9.47265718e-06\n 5.30468802e-05 9.47265718e-06 1.65771501e-05 5.30468802e-05\n 1.10514334e-05 8.84114670e-05 7.45971753e-05 2.65234401e-05\n 1.10514334e-05 6.63086002e-05 2.21028667e-05 9.94629003e-05\n 1.10514334e-05 1.65771501e-05 6.63086002e-05 9.47265718e-06\n 3.31543001e-05 3.48992633e-06 2.21028667e-05 1.10514334e-05\n 8.28857503e-06 2.21028667e-05 4.42057335e-06 3.48992633e-06\n 1.10514334e-05 2.21028667e-05 1.10514334e-05 8.55594842e-06\n 1.10514334e-05 1.10514334e-05 1.65771501e-05 9.47265718e-06\n 6.02805457e-06 9.47265718e-06 6.63086002e-05 1.32617200e-05\n 2.21028667e-05].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Questa parte estrare le parole piÃ¹ rilevanti per ogni categoria, ma non la uso alla fine.\n",
    "# Lo riprenderÃ² piÃ¹ avanti\n",
    "# FARE IL K-SQUARED\n",
    "\n",
    "neg_tokenized = [rev for rev, feedback in zip(X_train, Y_train) if feedback == 0]\n",
    "pos_tokenized = [rev for rev, feedback in zip(X_train, Y_train) if feedback == 1]\n",
    "neg_tokenized = [w for rev in neg_tokenized for w in rev]\n",
    "pos_tokenized = [w for rev in pos_tokenized for w in rev]\n",
    "\n",
    "import math \n",
    "\n",
    "def get_pos_neg_score(pos, neg):\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    total_tokens = pos + neg\n",
    "    total_tokens_freq = nltk.FreqDist(total_tokens)\n",
    "    pos_freq = nltk.FreqDist(pos)\n",
    "    neg_freq = nltk.FreqDist(neg)\n",
    "    data_dict = {\"pos\": {}, \"neg\": {}}\n",
    "\n",
    "    for w in pos:\n",
    "        p_category = pos_freq[w] / total_tokens_freq[w]\n",
    "        p = pos_freq[w] / len(pos)\n",
    "        data_dict[\"pos\"][w] = p_category * p\n",
    "    \n",
    "    for w in neg:\n",
    "        p_category = neg_freq[w] / total_tokens_freq[w]\n",
    "        p = neg_freq[w] / len(neg)\n",
    "        data_dict[\"neg\"][w] = p_category * p\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_pos = scaler.fit_transform(list(data_dict[\"pos\"].values()))\n",
    "    scaled_neg = scaler.fit_transform(list(data_dict[\"neg\"].values()))\n",
    "\n",
    "    data_dict[\"pos\"] = {k: v for k, v in zip(data_dict[\"pos\"], scaled_pos)}\n",
    "    data_dict[\"neg\"] = {k: v for k, v in zip(data_dict[\"neg\"], scaled_neg)}\n",
    "    \n",
    "    pos_sorted = {k: v for k, v in sorted(data_dict[\"pos\"].items(), key = lambda item: item[1], reverse=True)}\n",
    "    neg_sorted = {k: v for k, v in sorted(data_dict[\"neg\"].items(), key = lambda item: item[1], reverse=True)}\n",
    "    data_dict[\"pos\"] = pos_sorted\n",
    "    data_dict[\"neg\"] = neg_sorted\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "data_dict = get_pos_neg_score(pos_tokenized, neg_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.009673925634605968,\n",
       " 0.00786365448715125,\n",
       " 0.006621516184031125,\n",
       " 0.004997940256298918,\n",
       " 0.004796076809170098,\n",
       " 0.004695304695304696,\n",
       " 0.004133926483850496,\n",
       " 0.003988433113886754,\n",
       " 0.003980416746374193,\n",
       " 0.003951367781155015,\n",
       " 0.0038275690485183125,\n",
       " 0.0035234434046903127,\n",
       " 0.0035234434046903127,\n",
       " 0.003293653617427901,\n",
       " 0.003277219234666043,\n",
       " 0.0032733224222585926,\n",
       " 0.0031715024851606865,\n",
       " 0.003156418050035072,\n",
       " 0.002919757979436236,\n",
       " 0.002840776245031564,\n",
       " 0.002840776245031564,\n",
       " 0.002822405557967868,\n",
       " 0.0028102012553731046,\n",
       " 0.0026720999365376264,\n",
       " 0.0025718961889174656,\n",
       " 0.0025209378728200333,\n",
       " 0.002519490780679335,\n",
       " 0.00250720153632775,\n",
       " 0.00250261952389612,\n",
       " 0.0024720167252701855,\n",
       " 0.0023823880486814417,\n",
       " 0.002290459737268248,\n",
       " 0.002290459737268248,\n",
       " 0.0022632686462473696,\n",
       " 0.0022586807010733143,\n",
       " 0.002242718088182814,\n",
       " 0.0022267499471146884,\n",
       " 0.0021059978819678443,\n",
       " 0.002078616764657242,\n",
       " 0.0020295897955472423,\n",
       " 0.0020291258893082604,\n",
       " 0.0019935271894958345,\n",
       " 0.0019935271894958345,\n",
       " 0.0019819369151383008,\n",
       " 0.0019286712739365465,\n",
       " 0.0019091238205857287,\n",
       " 0.0019091238205857287,\n",
       " 0.0018938508300210427,\n",
       " 0.001881603705311912,\n",
       " 0.0018713170887083932,\n",
       " 0.0018704699555763386,\n",
       " 0.0018704699555763386,\n",
       " 0.0018598422853742004,\n",
       " 0.0018412438625204583,\n",
       " 0.0018348903640300494,\n",
       " 0.001813261432998871,\n",
       " 0.0017781770301367166,\n",
       " 0.001777752694847339,\n",
       " 0.0017216825727464028,\n",
       " 0.0016892681786298807,\n",
       " 0.0016880991349076454,\n",
       " 0.0016663826616945983,\n",
       " 0.0016626399605123008,\n",
       " 0.0016366612111292963,\n",
       " 0.0016366612111292963,\n",
       " 0.0016079478565480805,\n",
       " 0.0015857512425803432,\n",
       " 0.0015857512425803432,\n",
       " 0.0015717143376717847,\n",
       " 0.00156034863481672,\n",
       " 0.0015472637500171917,\n",
       " 0.0015472637500171917,\n",
       " 0.0015356983442089826,\n",
       " 0.0015356983442089826,\n",
       " 0.0015275504637206766,\n",
       " 0.001519756838905775,\n",
       " 0.001519756838905775,\n",
       " 0.001519756838905775,\n",
       " 0.0015197568389057749,\n",
       " 0.0015084435125615632,\n",
       " 0.0014917484997272231,\n",
       " 0.0014568083307854177,\n",
       " 0.0014568083307854177,\n",
       " 0.0014458320152938423,\n",
       " 0.0014320785597381344,\n",
       " 0.001403877943631583,\n",
       " 0.0014032555852071624,\n",
       " 0.001402852466682254,\n",
       " 0.0014028524666822538,\n",
       " 0.0014028524666822538,\n",
       " 0.0014028524666822538,\n",
       " 0.0014028524666822538,\n",
       " 0.0014028524666822538,\n",
       " 0.0014028524666822538,\n",
       " 0.0013800418574679086,\n",
       " 0.001374222824505065,\n",
       " 0.001356706003962443,\n",
       " 0.0013514145429039048,\n",
       " 0.0013261339724105683,\n",
       " 0.0013226618642479375,\n",
       " 0.001318827449146598,\n",
       " 0.0013171225937183384,\n",
       " 0.001311127497706876,\n",
       " 0.0012913728913136525,\n",
       " 0.0012899792797078195,\n",
       " 0.0012859480944587328,\n",
       " 0.0012859480944587328,\n",
       " 0.0012525468452520125,\n",
       " 0.00125130976194806,\n",
       " 0.0012348024316109422,\n",
       " 0.0012348024316109422,\n",
       " 0.0012300373077431357,\n",
       " 0.0012024449714419319,\n",
       " 0.0012024449714419319,\n",
       " 0.0012024449714419319,\n",
       " 0.0011956128977405572,\n",
       " 0.0011898024425365844,\n",
       " 0.0011795127704940344,\n",
       " 0.0011784714941887214,\n",
       " 0.0011690437222352116,\n",
       " 0.0011690437222352116,\n",
       " 0.0011621669944573572,\n",
       " 0.0011621669944573572,\n",
       " 0.0011456628477905073,\n",
       " 0.0011456628477905073,\n",
       " 0.0010898504378257295,\n",
       " 0.0010881099260804663,\n",
       " 0.0010740589198036006,\n",
       " 0.001067579550116684,\n",
       " 0.0010657328816655884,\n",
       " 0.0010627670202138287,\n",
       " 0.0010627670202138287,\n",
       " 0.0010627670202138287,\n",
       " 0.0010627670202138287,\n",
       " 0.0010521393500116905,\n",
       " 0.0010521393500116905,\n",
       " 0.0010521393500116905,\n",
       " 0.0010521393500116905,\n",
       " 0.0010521393500116905,\n",
       " 0.0010521393500116903,\n",
       " 0.0010521393500116903,\n",
       " 0.0010521393500116903,\n",
       " 0.0010415116798095521,\n",
       " 0.0010237988961393216,\n",
       " 0.0010237988961393216,\n",
       " 0.00101038778850329,\n",
       " 0.0010010646242829676,\n",
       " 0.0009962285632960934,\n",
       " 0.000987841945288754,\n",
       " 0.0009742031018626764,\n",
       " 0.0009652961020742176,\n",
       " 0.0009469254150105215,\n",
       " 0.0009469254150105215,\n",
       " 0.000940801852655956,\n",
       " 0.0009352349777881693,\n",
       " 0.0009352349777881693,\n",
       " 0.0009352349777881693,\n",
       " 0.0009352349777881693,\n",
       " 0.0009352349777881693,\n",
       " 0.0009352349777881693,\n",
       " 0.0009352349777881693,\n",
       " 0.0009352349777881693,\n",
       " 0.0009352349777881693,\n",
       " 0.0009352349777881692,\n",
       " 0.0009352349777881692,\n",
       " 0.0009238296731809965,\n",
       " 0.0009224235397362764,\n",
       " 0.0009070166810445608,\n",
       " 0.0009070166810445608,\n",
       " 0.0009044706693082952,\n",
       " 0.0008992644017193935,\n",
       " 0.0008992644017193935,\n",
       " 0.0008980381320806853,\n",
       " 0.0008890885150683583,\n",
       " 0.0008840893149403788,\n",
       " 0.0008840893149403788,\n",
       " 0.0008812791136850056,\n",
       " 0.0008612750688304313,\n",
       " 0.0008608412863732014,\n",
       " 0.0008608412863732014,\n",
       " 0.0008589929959032641,\n",
       " 0.000850213616171063,\n",
       " 0.0008417114800093522,\n",
       " 0.0008350312301680083,\n",
       " 0.0008350312301680083,\n",
       " 0.0008320840611203566,\n",
       " 0.0008320840611203566,\n",
       " 0.0008313199802561504,\n",
       " 0.0008209576701089969,\n",
       " 0.0008183306055646482,\n",
       " 0.0008183306055646482,\n",
       " 0.0008183306055646482,\n",
       " 0.0008183306055646482,\n",
       " 0.0008183306055646482,\n",
       " 0.0008183306055646482,\n",
       " 0.0008183306055646482,\n",
       " 0.0008183306055646482,\n",
       " 0.0008183306055646482,\n",
       " 0.0008183306055646482,\n",
       " 0.000813715959292667,\n",
       " 0.0008044134183951814,\n",
       " 0.0008016299809612879,\n",
       " 0.0007902735562310031,\n",
       " 0.000789104512508768,\n",
       " 0.000789104512508768,\n",
       " 0.000789104512508768,\n",
       " 0.0007858571688358924,\n",
       " 0.000779362481490141,\n",
       " 0.000779362481490141,\n",
       " 0.000779362481490141,\n",
       " 0.0007673722894672158,\n",
       " 0.0007651922545539566,\n",
       " 0.0007651922545539566,\n",
       " 0.0007651922545539566,\n",
       " 0.0007610961733302159,\n",
       " 0.0007544228820824566,\n",
       " 0.0007481879822305355,\n",
       " 0.0007481879822305355,\n",
       " 0.0007481879822305355,\n",
       " 0.0007444962652129506,\n",
       " 0.0007444962652129506,\n",
       " 0.0007306523263970072,\n",
       " 0.0007306523263970072,\n",
       " 0.0007284041653927088,\n",
       " 0.0007284041653927088,\n",
       " 0.0007284041653927088,\n",
       " 0.0007255156191326404,\n",
       " 0.0007160392798690672,\n",
       " 0.0007160392798690672,\n",
       " 0.0007160392798690672,\n",
       " 0.0007160392798690672,\n",
       " 0.000705601389491967,\n",
       " 0.0007014262333411269,\n",
       " 0.0007014262333411269,\n",
       " 0.0007014262333411269,\n",
       " 0.0007014262333411269,\n",
       " 0.0007014262333411269,\n",
       " 0.0007014262333411269,\n",
       " 0.0007014262333411269,\n",
       " 0.0007014262333411269,\n",
       " 0.0007014262333411269,\n",
       " 0.0007014262333411269,\n",
       " 0.0007014262333411269,\n",
       " 0.0007014262333411269,\n",
       " 0.0007014262333411269,\n",
       " 0.0007014262333411269,\n",
       " 0.0007014262333411269,\n",
       " 0.0007014262333411269,\n",
       " 0.0007014262333411269,\n",
       " 0.0006876727777854186,\n",
       " 0.0006876727777854186,\n",
       " 0.0006801708929368505,\n",
       " 0.0006801708929368505,\n",
       " 0.0006801708929368505,\n",
       " 0.0006763752964360868,\n",
       " 0.0006739193222297102,\n",
       " 0.0006735918590021935,\n",
       " 0.0006735918590021935,\n",
       " 0.0006735918590021935,\n",
       " 0.0006474703692379634,\n",
       " 0.0006474703692379634,\n",
       " 0.0006429740472293664,\n",
       " 0.0006364793598836152,\n",
       " 0.0006364793598836152,\n",
       " 0.0006364793598836152,\n",
       " 0.0006234899851921129,\n",
       " 0.0006150186538715678,\n",
       " 0.0006012224857209659,\n",
       " 0.0006012224857209659,\n",
       " 0.0006012224857209659,\n",
       " 0.0006012224857209659,\n",
       " 0.0006012224857209659,\n",
       " 0.0006012224857209659,\n",
       " 0.0006012224857209659,\n",
       " 0.0006012224857209659,\n",
       " 0.0006012224857209659,\n",
       " 0.0005918283843815759,\n",
       " 0.0005918283843815759,\n",
       " 0.0005918283843815759,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005845218611176058,\n",
       " 0.0005804906758685188,\n",
       " 0.000575529217100412,\n",
       " 0.0005644811115935736,\n",
       " 0.0005344199873075253,\n",
       " 0.0005344199873075253,\n",
       " 0.0005288010855718153,\n",
       " 0.0005260696750058452,\n",
       " 0.0005260696750058452,\n",
       " 0.0005260696750058452,\n",
       " 0.0005260696750058452,\n",
       " 0.0005260696750058452,\n",
       " 0.0005260696750058452,\n",
       " 0.0005260696750058452,\n",
       " 0.0005260696750058452,\n",
       " 0.0005260696750058452,\n",
       " 0.0005239047792239282,\n",
       " 0.0005207558399047761,\n",
       " 0.0005207558399047761,\n",
       " 0.0005207558399047761,\n",
       " 0.0005207558399047761,\n",
       " 0.0005207558399047761,\n",
       " 0.0005188632411016556,\n",
       " 0.0005101281697026378,\n",
       " 0.0005058362259671588,\n",
       " 0.000505193894251645,\n",
       " 0.0004987919881536903,\n",
       " 0.0004987919881536903,\n",
       " 0.0004983817973739586,\n",
       " 0.0004951244000055014,\n",
       " 0.0004871015509313382,\n",
       " 0.0004871015509313382,\n",
       " 0.0004871015509313382,\n",
       " 0.0004871015509313382,\n",
       " 0.0004871015509313382,\n",
       " 0.0004871015509313382,\n",
       " 0.0004871015509313382,\n",
       " 0.0004871015509313382,\n",
       " 0.0004871015509313382,\n",
       " 0.0004871015509313382,\n",
       " 0.0004871015509313382,\n",
       " 0.0004871015509313382,\n",
       " 0.0004871015509313382,\n",
       " 0.0004871015509313382,\n",
       " 0.0004871015509313382,\n",
       " 0.0004871015509313382,\n",
       " 0.0004871015509313382,\n",
       " 0.0004871015509313382,\n",
       " 0.00048270192401970026,\n",
       " 0.00048097798857677274,\n",
       " 0.00047735951991271147,\n",
       " 0.00047735951991271147,\n",
       " 0.00047346270750526077,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.00046761748889408465,\n",
       " 0.0004676174888940846,\n",
       " 0.0004676174888940846,\n",
       " 0.0004676174888940846,\n",
       " 0.0004676174888940846,\n",
       " 0.0004676174888940846,\n",
       " 0.0004676174888940846,\n",
       " 0.0004676174888940846,\n",
       " 0.0004676174888940846,\n",
       " 0.0004604233736803295,\n",
       " 0.0004509168642907245,\n",
       " 0.0004509168642907245,\n",
       " 0.0004492795481531402,\n",
       " 0.0004490612393347956,\n",
       " 0.0004406395568425028,\n",
       " 0.0004406395568425028,\n",
       " 0.0004406395568425028,\n",
       " 0.0004401105777826679,\n",
       " 0.00042864936481957756,\n",
       " 0.00042542643726454317,\n",
       " 0.0004208557400046761,\n",
       " 0.0004208557400046761,\n",
       " 0.0004208557400046761,\n",
       " 0.0004208557400046761,\n",
       " 0.0004208557400046761,\n",
       " 0.0004208557400046761,\n",
       " 0.00041751561508400416,\n",
       " 0.00041751561508400416,\n",
       " 0.00041751561508400416,\n",
       " 0.00041751561508400416,\n",
       " 0.00041751561508400416,\n",
       " 0.00041751561508400416,\n",
       " 0.00041751561508400416,\n",
       " 0.0004160420305601783,\n",
       " 0.0004156599901280752,\n",
       " 0.0004091653027823241,\n",
       " 0.00039378314854238703,\n",
       " 0.0003883602873866127,\n",
       " 0.0003825961272769783,\n",
       " 0.0003825961272769783,\n",
       " 0.0003825961272769783,\n",
       " 0.0003825961272769783,\n",
       " 0.0003825961272769783,\n",
       " 0.00038230889294719084,\n",
       " 0.00038188761593016914,\n",
       " 0.0003787701660042086,\n",
       " 0.00037409399111526775,\n",
       " 0.00037409399111526775,\n",
       " 0.00037409399111526775,\n",
       " 0.00037409399111526775,\n",
       " 0.00037409399111526775,\n",
       " 0.00037409399111526775,\n",
       " 0.00037409399111526775,\n",
       " 0.00037409399111526775,\n",
       " 0.00037409399111526775,\n",
       " 0.00037409399111526775,\n",
       " 0.00037409399111526775,\n",
       " 0.00037409399111526775,\n",
       " 0.00037409399111526775,\n",
       " 0.00037409399111526775,\n",
       " 0.00037409399111526775,\n",
       " 0.0003740939911152677,\n",
       " 0.0003653261631985036,\n",
       " 0.0003653261631985036,\n",
       " 0.0003653261631985036,\n",
       " 0.0003653261631985036,\n",
       " 0.0003653261631985036,\n",
       " 0.00035627999153835016,\n",
       " 0.0003554524831120576,\n",
       " 0.0003507131166705635,\n",
       " 0.00035071311667056346,\n",
       " 0.00035071311667056346,\n",
       " 0.00035071311667056346,\n",
       " 0.00035071311667056346,\n",
       " 0.00035071311667056346,\n",
       " 0.00035071311667056346,\n",
       " 0.00035071311667056346,\n",
       " 0.00035071311667056346,\n",
       " 0.0003381876482180434,\n",
       " 0.0003369596611148551,\n",
       " 0.0003369596611148551,\n",
       " 0.0003247343672875588,\n",
       " 0.0003247343672875588,\n",
       " 0.0003247343672875588,\n",
       " 0.0003247343672875588,\n",
       " 0.0003247343672875588,\n",
       " 0.0003247343672875588,\n",
       " 0.0003247343672875588,\n",
       " 0.0003237351846189817,\n",
       " 0.0003237351846189817,\n",
       " 0.0003237351846189817,\n",
       " 0.0003237351846189817,\n",
       " 0.0003187298450245058,\n",
       " 0.0003182396799418076,\n",
       " 0.0003182396799418076,\n",
       " 0.0003131367113130031,\n",
       " 0.00031174499259605643,\n",
       " 0.00031174499259605643,\n",
       " 0.00031174499259605643,\n",
       " 0.00031174499259605643,\n",
       " 0.00031174499259605643,\n",
       " 0.00031174499259605643,\n",
       " 0.00031174499259605643,\n",
       " 0.00031174499259605643,\n",
       " 0.00031174499259605643,\n",
       " 0.00031174499259605643,\n",
       " 0.00031174499259605643,\n",
       " 0.00031174499259605643,\n",
       " 0.0003054598112937166,\n",
       " 0.0003014902231027651,\n",
       " 0.0003014902231027651,\n",
       " 0.00030061124286048297,\n",
       " 0.00030061124286048297,\n",
       " 0.00030061124286048297,\n",
       " 0.0002992751928922142,\n",
       " 0.0002992751928922142,\n",
       " 0.0002975747656598721,\n",
       " 0.0002922609305588029,\n",
       " 0.0002922609305588029,\n",
       " 0.0002922609305588029,\n",
       " 0.0002922609305588029,\n",
       " 0.0002922609305588029,\n",
       " 0.0002922609305588029,\n",
       " 0.0002864157119476268,\n",
       " 0.0002864157119476268,\n",
       " 0.0002805704933364508,\n",
       " 0.0002805704933364508,\n",
       " 0.0002805704933364508,\n",
       " 0.00027277686852154935,\n",
       " 0.00027055011857443466,\n",
       " 0.00026720999365376265,\n",
       " 0.00026720999365376265,\n",
       " 0.00026720999365376265,\n",
       " 0.00026720999365376265,\n",
       " 0.00026720999365376265,\n",
       " 0.00026720999365376265,\n",
       " 0.00026720999365376265,\n",
       " 0.00026720999365376265,\n",
       " 0.00026720999365376265,\n",
       " 0.00026720999365376265,\n",
       " 0.0002656917550534572,\n",
       " 0.0002656917550534572,\n",
       " 0.0002656917550534572,\n",
       " 0.0002656917550534572,\n",
       " 0.0002630348375029226,\n",
       " 0.0002630348375029226,\n",
       " 0.0002630348375029226,\n",
       " 0.0002630348375029226,\n",
       " 0.0002630348375029226,\n",
       " 0.0002630348375029226,\n",
       " 0.0002630348375029226,\n",
       " 0.0002630348375029226,\n",
       " 0.0002630348375029226,\n",
       " 0.0002630348375029226,\n",
       " 0.0002630348375029226,\n",
       " 0.0002630348375029226,\n",
       " 0.0002630348375029226,\n",
       " 0.0002630348375029226,\n",
       " 0.0002630348375029226,\n",
       " 0.0002630348375029226,\n",
       " 0.0002630348375029226,\n",
       " 0.0002630348375029226,\n",
       " 0.00026037791995238803,\n",
       " 0.00025658232345162436,\n",
       " 0.00024939599407684517,\n",
       " 0.00024905714082402335,\n",
       " 0.0002475622000027507,\n",
       " 0.0002435507754656691,\n",
       " 0.0002435507754656691,\n",
       " 0.0002435507754656691,\n",
       " 0.0002435507754656691,\n",
       " 0.00023380874444704232,\n",
       " 0.00023380874444704232,\n",
       " 0.00023380874444704232,\n",
       " 0.00023380874444704232,\n",
       " 0.00023380874444704232,\n",
       " 0.00023380874444704232,\n",
       " 0.00023380874444704232,\n",
       " 0.00023380874444704232,\n",
       " 0.00023380874444704232,\n",
       " 0.00023380874444704232,\n",
       " 0.00023380874444704232,\n",
       " 0.00023380874444704232,\n",
       " 0.00023380874444704232,\n",
       " 0.00023380874444704232,\n",
       " 0.0002338087444470423,\n",
       " 0.0002338087444470423,\n",
       " 0.00023095741829524914,\n",
       " 0.00022481610042984838,\n",
       " 0.00022481610042984838,\n",
       " 0.00022481610042984838,\n",
       " 0.00022481610042984838,\n",
       " 0.00022150302105509268,\n",
       " 0.0002203197784212514,\n",
       " 0.0002203197784212514,\n",
       " 0.00021648957819170582,\n",
       " 0.00021376799492301012,\n",
       " 0.00021215978662787174,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00021042787000233806,\n",
       " 0.00020875780754200208,\n",
       " 0.00020875780754200208,\n",
       " 0.0002078299950640376,\n",
       " 0.0002078299950640376,\n",
       " 0.0002078299950640376,\n",
       " 0.0002078299950640376,\n",
       " 0.00020040749524032197,\n",
       " 0.0001992313949161417,\n",
       " 0.00019484062037253524,\n",
       " 0.00019129806363848916,\n",
       " 0.00018704699555763387,\n",
       " 0.00018704699555763387,\n",
       " 0.00018704699555763387,\n",
       " 0.0001826630815992518,\n",
       " 0.0001826630815992518,\n",
       " 0.0001816720818921846,\n",
       " 0.00018135165434674436,\n",
       " 0.00017712783670230478,\n",
       " 0.00017535655833528173,\n",
       " 0.00017535655833528173,\n",
       " 0.00017535655833528173,\n",
       " 0.00017535655833528173,\n",
       " 0.00017535655833528173,\n",
       " 0.00017535655833528173,\n",
       " 0.00017535655833528173,\n",
       " 0.00017535655833528173,\n",
       " 0.00017535655833528173,\n",
       " 0.00017535655833528173,\n",
       " 0.00017535655833528173,\n",
       " 0.00017535655833528173,\n",
       " 0.00017535655833528173,\n",
       " 0.00017191819444635465,\n",
       " 0.00017191819444635465,\n",
       " 0.0001700427232342126,\n",
       " 0.00016834229600187046,\n",
       " 0.0001662639960512301,\n",
       " 0.0001644817330121635,\n",
       " 0.00016186759230949084,\n",
       " 0.00015587249629802822,\n",
       " 0.00015587249629802822,\n",
       " 0.00015587249629802822,\n",
       " 0.00015587249629802822,\n",
       " 0.00015587249629802822,\n",
       " 0.00015587249629802822,\n",
       " 0.00015587249629802822,\n",
       " 0.00015587249629802822,\n",
       " 0.00015587249629802822,\n",
       " 0.00015587249629802822,\n",
       " 0.00015587249629802822,\n",
       " 0.00015587249629802822,\n",
       " 0.00015587249629802822,\n",
       " 0.00015587249629802822,\n",
       " 0.00015587249629802822,\n",
       " 0.00015587249629802822,\n",
       " 0.00015587249629802822,\n",
       " 0.0001558724962980282,\n",
       " 0.00015382154239936994,\n",
       " 0.00015030562143024149,\n",
       " 0.00015030562143024149,\n",
       " 0.00015030562143024149,\n",
       " 0.00015030562143024149,\n",
       " 0.00015030562143024149,\n",
       " 0.00015030562143024149,\n",
       " 0.00015030562143024149,\n",
       " 0.00015030562143024149,\n",
       " 0.00015030562143024149,\n",
       " 0.00015030562143024149,\n",
       " 0.00015030562143024149,\n",
       " 0.00014613046527940144,\n",
       " 0.000143882304275103,\n",
       " 0.000143882304275103,\n",
       " 0.000143882304275103,\n",
       " 0.00013917187169466803,\n",
       " 0.00013917187169466803,\n",
       " 0.00013917187169466803,\n",
       " 0.00013360499682688132,\n",
       " 0.00013360499682688132,\n",
       " 0.00013360499682688132,\n",
       " 0.00013360499682688132,\n",
       " 0.0001315174187514613,\n",
       " 0.0001315174187514613,\n",
       " 0.0001315174187514613,\n",
       " 0.0001315174187514613,\n",
       " 0.0001315174187514613,\n",
       " 0.0001315174187514613,\n",
       " 0.0001315174187514613,\n",
       " 0.00012899792797078197,\n",
       " 0.0001284663431027705,\n",
       " 0.00012753204242565945,\n",
       " 0.00012469799703842258,\n",
       " 0.00012177538773283455,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352116,\n",
       " 0.00011690437222352115,\n",
       " 0.00011690437222352115,\n",
       " 0.00011690437222352115,\n",
       " 0.00011690437222352115,\n",
       " 0.00011690437222352115,\n",
       " 0.00011690437222352115,\n",
       " 0.00011690437222352115,\n",
       " 0.00011690437222352115,\n",
       " 0.00011690437222352115,\n",
       " 0.00011075151052754634,\n",
       " 0.00011002764444566698,\n",
       " 0.00010521393500116903,\n",
       " 0.00010521393500116903,\n",
       " 0.00010521393500116903,\n",
       " 0.00010521393500116903,\n",
       " 0.00010521393500116903,\n",
       " 0.0001039149975320188,\n",
       " 0.00010264774146455515,\n",
       " 0.00010077963122717341,\n",
       " 9.844578713559676e-05,\n",
       " 9.564903181924458e-05,\n",
       " 9.564903181924458e-05,\n",
       " 9.564903181924458e-05,\n",
       " 9.352349777881694e-05,\n",
       " 9.352349777881694e-05,\n",
       " 9.352349777881694e-05,\n",
       " 9.352349777881694e-05,\n",
       " 9.352349777881694e-05,\n",
       " 9.352349777881694e-05,\n",
       " 9.352349777881694e-05,\n",
       " 9.352349777881694e-05,\n",
       " 9.352349777881694e-05,\n",
       " 9.352349777881694e-05,\n",
       " 9.352349777881694e-05,\n",
       " 9.352349777881694e-05,\n",
       " 9.352349777881694e-05,\n",
       " 9.352349777881694e-05,\n",
       " 9.352349777881694e-05,\n",
       " 9.352349777881694e-05,\n",
       " 9.149037826188612e-05,\n",
       " 8.856391835115239e-05,\n",
       " 8.767827916764086e-05,\n",
       " 8.767827916764086e-05,\n",
       " 8.50213616171063e-05,\n",
       " 8.50213616171063e-05,\n",
       " 8.417114800093523e-05,\n",
       " 8.252073333425022e-05,\n",
       " 8.093379615474542e-05,\n",
       " 8.093379615474542e-05,\n",
       " 7.793624814901411e-05,\n",
       " 7.793624814901411e-05,\n",
       " 7.793624814901411e-05,\n",
       " 7.793624814901411e-05,\n",
       " 7.793624814901411e-05,\n",
       " 7.793624814901411e-05,\n",
       " 7.793624814901411e-05,\n",
       " 7.793624814901411e-05,\n",
       " 7.793624814901411e-05,\n",
       " 7.793624814901411e-05,\n",
       " 7.793624814901411e-05,\n",
       " 7.793624814901411e-05,\n",
       " 7.793624814901411e-05,\n",
       " 7.793624814901411e-05,\n",
       " 7.256133448356485e-05,\n",
       " 7.19411521375515e-05,\n",
       " 7.01426233341127e-05,\n",
       " 7.01426233341127e-05,\n",
       " 6.958593584733401e-05,\n",
       " 6.927666502134587e-05,\n",
       " 6.680249841344066e-05,\n",
       " 6.680249841344066e-05,\n",
       " 6.680249841344066e-05,\n",
       " 6.680249841344066e-05,\n",
       " 6.680249841344066e-05,\n",
       " 6.680249841344066e-05,\n",
       " 6.680249841344066e-05,\n",
       " 6.680249841344066e-05,\n",
       " 6.449896398539099e-05,\n",
       " 6.234899851921129e-05,\n",
       " 6.033774050246253e-05,\n",
       " 6.033774050246253e-05,\n",
       " 5.845218611176058e-05,\n",
       " 5.845218611176058e-05,\n",
       " 5.845218611176058e-05,\n",
       " 5.845218611176058e-05,\n",
       " 5.845218611176058e-05,\n",
       " 5.845218611176058e-05,\n",
       " 5.845218611176058e-05,\n",
       " 5.845218611176058e-05,\n",
       " 5.845218611176058e-05,\n",
       " 5.845218611176058e-05,\n",
       " 5.8452186111760574e-05,\n",
       " 5.8452186111760574e-05,\n",
       " 5.8452186111760574e-05,\n",
       " 5.537575526377317e-05,\n",
       " 5.537575526377317e-05,\n",
       " 5.514357180354772e-05,\n",
       " 5.2606967500584514e-05,\n",
       " 5.2606967500584514e-05,\n",
       " 5.2606967500584514e-05,\n",
       " 5.19574987660094e-05,\n",
       " 5.19574987660094e-05,\n",
       " 5.19574987660094e-05,\n",
       " 5.19574987660094e-05,\n",
       " 5.1273847466456645e-05,\n",
       " 5.010187381008049e-05,\n",
       " 4.676174888940847e-05,\n",
       " 4.676174888940847e-05,\n",
       " 4.676174888940847e-05,\n",
       " 4.676174888940847e-05,\n",
       " 4.676174888940847e-05,\n",
       " 4.676174888940847e-05,\n",
       " 4.676174888940847e-05,\n",
       " 4.676174888940847e-05,\n",
       " 4.251068080855315e-05,\n",
       " 4.251068080855315e-05,\n",
       " 4.251068080855315e-05,\n",
       " 4.251068080855315e-05,\n",
       " 4.251068080855315e-05,\n",
       " 4.251068080855315e-05,\n",
       " 4.251068080855315e-05,\n",
       " 4.2085574000467614e-05,\n",
       " 4.046689807737271e-05,\n",
       " 3.8968124074507054e-05,\n",
       " 3.8968124074507054e-05,\n",
       " 3.8968124074507054e-05,\n",
       " 3.8968124074507054e-05,\n",
       " 3.8968124074507054e-05,\n",
       " 3.8968124074507054e-05,\n",
       " 3.8968124074507054e-05,\n",
       " 3.8968124074507054e-05,\n",
       " 3.737888573541623e-05,\n",
       " 3.628066724178243e-05,\n",
       " 3.597057606877575e-05,\n",
       " 3.597057606877575e-05,\n",
       " 3.597057606877575e-05,\n",
       " 3.597057606877575e-05,\n",
       " 3.340124920672033e-05,\n",
       " 3.340124920672033e-05,\n",
       " 3.340124920672033e-05,\n",
       " 3.340124920672033e-05,\n",
       " 3.287935468786532e-05,\n",
       " 3.1174499259605646e-05,\n",
       " 3.1174499259605646e-05,\n",
       " 2.922609305588029e-05,\n",
       " 2.922609305588029e-05,\n",
       " 2.922609305588029e-05,\n",
       " 2.922609305588029e-05,\n",
       " 2.922609305588029e-05,\n",
       " 2.922609305588029e-05,\n",
       " 2.922609305588029e-05,\n",
       " 2.922609305588029e-05,\n",
       " 2.7506911111416745e-05,\n",
       " 2.461144678389919e-05,\n",
       " 2.3380874444704234e-05,\n",
       " 2.3380874444704234e-05,\n",
       " 2.3380874444704234e-05,\n",
       " 2.1255340404276577e-05,\n",
       " 2.1255340404276577e-05,\n",
       " 2.1255340404276577e-05,\n",
       " 1.9484062037253527e-05,\n",
       " 1.9484062037253527e-05,\n",
       " 1.9484062037253527e-05,\n",
       " 1.9484062037253527e-05,\n",
       " 1.9484062037253527e-05,\n",
       " 1.8704699555763387e-05,\n",
       " 1.7319166255336468e-05,\n",
       " 1.6700624603360165e-05,\n",
       " 1.6552831465277332e-05,\n",
       " 1.6124740996347747e-05,\n",
       " 1.4613046527940145e-05,\n",
       " 1.4613046527940145e-05,\n",
       " 1.4613046527940145e-05,\n",
       " 1.298937469150235e-05,\n",
       " 1.298937469150235e-05,\n",
       " 1.298937469150235e-05,\n",
       " 1.1690437222352117e-05,\n",
       " 1.1690437222352117e-05,\n",
       " 1.0627670202138288e-05,\n",
       " 9.742031018626763e-06,\n",
       " 6.494687345751175e-06,\n",
       " 6.152861695974797e-06,\n",
       " 2.7834374338933606e-06]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[\"neg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "able 0.2249249015304568\n",
      "bedroom 0.24097804450421667\n",
      "completely 0.33130002262354297\n",
      "dark 0.3253626203370814\n",
      "display 0.28769579953237184\n",
      "easy 0.1978179622227001\n",
      "favorite 0.28511012221747173\n",
      "love 0.12106485427700273\n",
      "music 0.17379176912088873\n",
      "night 0.2583613347239237\n",
      "skill 0.25547999875620503\n",
      "spot 0.22569452954549868\n",
      "try 0.20985334058742994\n",
      "turn 0.2280765312063493\n",
      "use 0.1389891369758205\n",
      "wake 0.2583613347239237\n",
      "yet 0.2501688114270335\n"
     ]
    }
   ],
   "source": [
    "# tfidf weighting sui token, per ora senza pos. Mi sono reso conto che la pos per averla piÃ¹ accurata la devo fare prima del pre processing.\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=lambda i:i, lowercase=False, min_df = 0)\n",
    "tfidf_model = tfidf.fit_transform(X_train)\n",
    "X_test_tf = tfidf.transform(X_test)\n",
    "review = 12\n",
    "for score, feature in zip(tfidf_model.toarray()[review], tfidf.get_feature_names_out()):\n",
    "    if score > 0.0:\n",
    "        print(feature, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(X_train, vector_size=300, window = 5, min_count = 0, sg=1, hs = 1, alpha=0.03, min_alpha=0.0007, seed = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1921430, 2363500)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(X_train, total_examples=len(X_train), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.25955426692962646),\n",
       " ('blast', 0.22110874950885773),\n",
       " ('security_camera', 0.21915099024772644),\n",
       " ('travel', 0.21872034668922424),\n",
       " ('like', 0.20897917449474335),\n",
       " ('improvement', 0.20838351547718048),\n",
       " ('guy', 0.20754249393939972),\n",
       " ('absolutely_love', 0.20073740184307098),\n",
       " ('outstanding', 0.19625253975391388),\n",
       " ('listen', 0.1946718841791153)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(\"love\", topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('point', -0.03687885403633118),\n",
       " ('research', -0.038739051669836044),\n",
       " ('shortly', -0.03875153511762619),\n",
       " ('loose', -0.04134296253323555),\n",
       " ('switch', -0.04256429150700569),\n",
       " ('source', -0.045874983072280884),\n",
       " ('solution', -0.04850295931100845),\n",
       " ('previous', -0.04925130307674408),\n",
       " ('characteristic', -0.055115025490522385),\n",
       " ('assume', -0.07657280564308167)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(\"love\", topn = 2000)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'ll</th>\n",
       "      <th>'re</th>\n",
       "      <th>'ve</th>\n",
       "      <th>....</th>\n",
       "      <th>.....</th>\n",
       "      <th>......</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absolutely_love</th>\n",
       "      <th>...</th>\n",
       "      <th>yard</th>\n",
       "      <th>year</th>\n",
       "      <th>year_old</th>\n",
       "      <th>yell</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>yield</th>\n",
       "      <th>z-wave</th>\n",
       "      <th>zero</th>\n",
       "      <th>zigbee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298178</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2103 rows Ã 1093 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      'll  're  've  ....  .....  ......  ability  able  absolutely  \\\n",
       "0     0.0  0.0  0.0   0.0    0.0     0.0      0.0   0.0         0.0   \n",
       "1     0.0  0.0  0.0   0.0    0.0     0.0      0.0   0.0         0.0   \n",
       "2     0.0  0.0  0.0   0.0    0.0     0.0      0.0   0.0         0.0   \n",
       "3     0.0  0.0  0.0   0.0    0.0     0.0      0.0   0.0         0.0   \n",
       "4     0.0  0.0  0.0   0.0    0.0     0.0      0.0   0.0         0.0   \n",
       "...   ...  ...  ...   ...    ...     ...      ...   ...         ...   \n",
       "2098  0.0  0.0  0.0   0.0    0.0     0.0      0.0   0.0         0.0   \n",
       "2099  0.0  0.0  0.0   0.0    0.0     0.0      0.0   0.0         0.0   \n",
       "2100  0.0  0.0  0.0   0.0    0.0     0.0      0.0   0.0         0.0   \n",
       "2101  0.0  0.0  0.0   0.0    0.0     0.0      0.0   0.0         0.0   \n",
       "2102  0.0  0.0  0.0   0.0    0.0     0.0      0.0   0.0         0.0   \n",
       "\n",
       "      absolutely_love  ...  yard  year  year_old  yell  yes  yet  yield  \\\n",
       "0                 0.0  ...   0.0   0.0       0.0   0.0  0.0  0.0    0.0   \n",
       "1                 0.0  ...   0.0   0.0       0.0   0.0  0.0  0.0    0.0   \n",
       "2                 0.0  ...   0.0   0.0       0.0   0.0  0.0  0.0    0.0   \n",
       "3                 0.0  ...   0.0   0.0       0.0   0.0  0.0  0.0    0.0   \n",
       "4                 0.0  ...   0.0   0.0       0.0   0.0  0.0  0.0    0.0   \n",
       "...               ...  ...   ...   ...       ...   ...  ...  ...    ...   \n",
       "2098              0.0  ...   0.0   0.0       0.0   0.0  0.0  0.0    0.0   \n",
       "2099              0.0  ...   0.0   0.0       0.0   0.0  0.0  0.0    0.0   \n",
       "2100              0.0  ...   0.0   0.0       0.0   0.0  0.0  0.0    0.0   \n",
       "2101              0.0  ...   0.0   0.0       0.0   0.0  0.0  0.0    0.0   \n",
       "2102              0.0  ...   0.0   0.0       0.0   0.0  0.0  0.0    0.0   \n",
       "\n",
       "      z-wave      zero  zigbee  \n",
       "0        0.0  0.000000     0.0  \n",
       "1        0.0  0.000000     0.0  \n",
       "2        0.0  0.000000     0.0  \n",
       "3        0.0  0.000000     0.0  \n",
       "4        0.0  0.000000     0.0  \n",
       "...      ...       ...     ...  \n",
       "2098     0.0  0.000000     0.0  \n",
       "2099     0.0  0.298178     0.0  \n",
       "2100     0.0  0.000000     0.0  \n",
       "2101     0.0  0.000000     0.0  \n",
       "2102     0.0  0.000000     0.0  \n",
       "\n",
       "[2103 rows x 1093 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tfidf_model.toarray(), columns = tfidf.get_feature_names_out())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model = []\n",
    "# google_model = api.load('word2vec-google-news-300', True)\n",
    "# g_model = KeyedVectors.load_word2vec_format(google_model, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_vectors(tokens, size = 300, weights = [], pretrained = False, test = False):\n",
    "\n",
    "    \"\"\"Genera un vettore per ogni recensione: questo vettore\n",
    "    Ã¨ calcolato come la media ponderata (t * w: token vettore * peso tfidf) dei vettori dei token nella recensione.\n",
    "    Il vettore risultante Ã¨ normalizzato alla fine.\"\"\"\n",
    "\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "\n",
    "    if test:\n",
    "        for word in tokens:\n",
    "            try:\n",
    "                if pretrained:\n",
    "                    vec += g_model[word] * weight\n",
    "                else:\n",
    "                    vec += w2v_model.wv[word] * weight\n",
    "                count +=1\n",
    "            except KeyError:\n",
    "                print(\"non trovo\", word)\n",
    "                continue\n",
    "\n",
    "        if count!= 0:\n",
    "            vec = vec / norm(vec)\n",
    "        \n",
    "        return vec\n",
    "\n",
    "    if len(tokens) != len(weights):\n",
    "        print(\"nope\")\n",
    "\n",
    "    for word, weight in zip(tokens, weights):\n",
    "        try:\n",
    "            if pretrained:\n",
    "                vec += g_model[word] * weight\n",
    "            else:\n",
    "                vec += w2v_model.wv[word] * weight\n",
    "            count +=1\n",
    "        except KeyError:\n",
    "            print(\"non trovo\", word)\n",
    "            continue\n",
    "\n",
    "    if count!= 0:\n",
    "        vec = vec / norm(vec)\n",
    "        \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.037436</td>\n",
       "      <td>0.024968</td>\n",
       "      <td>0.109724</td>\n",
       "      <td>0.018178</td>\n",
       "      <td>0.082140</td>\n",
       "      <td>0.041093</td>\n",
       "      <td>-0.019538</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>-0.007271</td>\n",
       "      <td>-0.107329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037278</td>\n",
       "      <td>0.026202</td>\n",
       "      <td>0.067330</td>\n",
       "      <td>0.017581</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>-0.000364</td>\n",
       "      <td>0.014661</td>\n",
       "      <td>0.089783</td>\n",
       "      <td>0.076761</td>\n",
       "      <td>-0.055050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.058679</td>\n",
       "      <td>-0.103617</td>\n",
       "      <td>-0.081639</td>\n",
       "      <td>0.074817</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>-0.001366</td>\n",
       "      <td>-0.010609</td>\n",
       "      <td>0.008731</td>\n",
       "      <td>0.018614</td>\n",
       "      <td>0.029657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012424</td>\n",
       "      <td>0.019532</td>\n",
       "      <td>0.081359</td>\n",
       "      <td>0.070816</td>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.028387</td>\n",
       "      <td>-0.135459</td>\n",
       "      <td>0.072594</td>\n",
       "      <td>0.043265</td>\n",
       "      <td>-0.056014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.037436</td>\n",
       "      <td>0.024968</td>\n",
       "      <td>0.109724</td>\n",
       "      <td>0.018178</td>\n",
       "      <td>0.082140</td>\n",
       "      <td>0.041093</td>\n",
       "      <td>-0.019538</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>-0.007271</td>\n",
       "      <td>-0.107329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037278</td>\n",
       "      <td>0.026202</td>\n",
       "      <td>0.067330</td>\n",
       "      <td>0.017581</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>-0.000364</td>\n",
       "      <td>0.014661</td>\n",
       "      <td>0.089783</td>\n",
       "      <td>0.076761</td>\n",
       "      <td>-0.055050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027533</td>\n",
       "      <td>0.021382</td>\n",
       "      <td>0.023901</td>\n",
       "      <td>0.103499</td>\n",
       "      <td>0.074559</td>\n",
       "      <td>0.028210</td>\n",
       "      <td>-0.081313</td>\n",
       "      <td>-0.008650</td>\n",
       "      <td>-0.088448</td>\n",
       "      <td>0.039854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011349</td>\n",
       "      <td>0.045512</td>\n",
       "      <td>0.066154</td>\n",
       "      <td>0.027690</td>\n",
       "      <td>0.040464</td>\n",
       "      <td>0.008225</td>\n",
       "      <td>-0.022252</td>\n",
       "      <td>0.074263</td>\n",
       "      <td>0.148502</td>\n",
       "      <td>-0.050379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.029783</td>\n",
       "      <td>-0.014268</td>\n",
       "      <td>0.085866</td>\n",
       "      <td>0.041078</td>\n",
       "      <td>0.038151</td>\n",
       "      <td>0.006630</td>\n",
       "      <td>0.034895</td>\n",
       "      <td>0.016084</td>\n",
       "      <td>-0.048982</td>\n",
       "      <td>-0.034830</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004770</td>\n",
       "      <td>-0.027468</td>\n",
       "      <td>0.075778</td>\n",
       "      <td>0.040369</td>\n",
       "      <td>-0.132114</td>\n",
       "      <td>-0.042492</td>\n",
       "      <td>-0.024968</td>\n",
       "      <td>0.010592</td>\n",
       "      <td>0.081344</td>\n",
       "      <td>-0.039806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>-0.063894</td>\n",
       "      <td>0.128551</td>\n",
       "      <td>-0.016874</td>\n",
       "      <td>0.079798</td>\n",
       "      <td>-0.042847</td>\n",
       "      <td>0.069412</td>\n",
       "      <td>-0.085770</td>\n",
       "      <td>0.042757</td>\n",
       "      <td>-0.067661</td>\n",
       "      <td>0.048353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>-0.029823</td>\n",
       "      <td>0.114998</td>\n",
       "      <td>0.048743</td>\n",
       "      <td>-0.115133</td>\n",
       "      <td>0.058256</td>\n",
       "      <td>-0.088071</td>\n",
       "      <td>-0.015225</td>\n",
       "      <td>-0.013587</td>\n",
       "      <td>-0.108568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>-0.042294</td>\n",
       "      <td>0.006577</td>\n",
       "      <td>0.009470</td>\n",
       "      <td>0.067912</td>\n",
       "      <td>-0.086389</td>\n",
       "      <td>0.072339</td>\n",
       "      <td>-0.040169</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>-0.029050</td>\n",
       "      <td>-0.006668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071058</td>\n",
       "      <td>0.027249</td>\n",
       "      <td>0.094250</td>\n",
       "      <td>-0.000389</td>\n",
       "      <td>-0.128791</td>\n",
       "      <td>0.038306</td>\n",
       "      <td>-0.065405</td>\n",
       "      <td>0.047628</td>\n",
       "      <td>0.112749</td>\n",
       "      <td>0.108817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>-0.003261</td>\n",
       "      <td>-0.057798</td>\n",
       "      <td>-0.012224</td>\n",
       "      <td>0.090025</td>\n",
       "      <td>-0.089591</td>\n",
       "      <td>0.070062</td>\n",
       "      <td>-0.078967</td>\n",
       "      <td>0.041580</td>\n",
       "      <td>-0.035892</td>\n",
       "      <td>-0.029071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068082</td>\n",
       "      <td>-0.068496</td>\n",
       "      <td>0.049755</td>\n",
       "      <td>0.012977</td>\n",
       "      <td>-0.085023</td>\n",
       "      <td>-0.012781</td>\n",
       "      <td>-0.061325</td>\n",
       "      <td>0.154539</td>\n",
       "      <td>0.070906</td>\n",
       "      <td>-0.032483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>-0.011849</td>\n",
       "      <td>0.050466</td>\n",
       "      <td>-0.038193</td>\n",
       "      <td>0.036060</td>\n",
       "      <td>0.039839</td>\n",
       "      <td>0.016367</td>\n",
       "      <td>-0.068111</td>\n",
       "      <td>0.007635</td>\n",
       "      <td>-0.055993</td>\n",
       "      <td>-0.030789</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037224</td>\n",
       "      <td>-0.005990</td>\n",
       "      <td>0.074731</td>\n",
       "      <td>0.037903</td>\n",
       "      <td>0.027928</td>\n",
       "      <td>-0.049965</td>\n",
       "      <td>-0.084224</td>\n",
       "      <td>0.102279</td>\n",
       "      <td>0.076535</td>\n",
       "      <td>-0.035102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>-0.041355</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>0.083357</td>\n",
       "      <td>-0.000439</td>\n",
       "      <td>0.008450</td>\n",
       "      <td>-0.115060</td>\n",
       "      <td>-0.065789</td>\n",
       "      <td>-0.059427</td>\n",
       "      <td>-0.048365</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026843</td>\n",
       "      <td>0.022689</td>\n",
       "      <td>0.099811</td>\n",
       "      <td>0.088141</td>\n",
       "      <td>0.067153</td>\n",
       "      <td>-0.048194</td>\n",
       "      <td>-0.187285</td>\n",
       "      <td>0.049097</td>\n",
       "      <td>0.137798</td>\n",
       "      <td>-0.034750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2103 rows Ã 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -0.037436  0.024968  0.109724  0.018178  0.082140  0.041093 -0.019538   \n",
       "1    -0.058679 -0.103617 -0.081639  0.074817  0.011864 -0.001366 -0.010609   \n",
       "2    -0.037436  0.024968  0.109724  0.018178  0.082140  0.041093 -0.019538   \n",
       "3     0.027533  0.021382  0.023901  0.103499  0.074559  0.028210 -0.081313   \n",
       "4    -0.029783 -0.014268  0.085866  0.041078  0.038151  0.006630  0.034895   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2098 -0.063894  0.128551 -0.016874  0.079798 -0.042847  0.069412 -0.085770   \n",
       "2099 -0.042294  0.006577  0.009470  0.067912 -0.086389  0.072339 -0.040169   \n",
       "2100 -0.003261 -0.057798 -0.012224  0.090025 -0.089591  0.070062 -0.078967   \n",
       "2101 -0.011849  0.050466 -0.038193  0.036060  0.039839  0.016367 -0.068111   \n",
       "2102 -0.041355  0.039476  0.085113  0.083357 -0.000439  0.008450 -0.115060   \n",
       "\n",
       "           7         8         9    ...       290       291       292  \\\n",
       "0     0.019814 -0.007271 -0.107329  ... -0.037278  0.026202  0.067330   \n",
       "1     0.008731  0.018614  0.029657  ... -0.012424  0.019532  0.081359   \n",
       "2     0.019814 -0.007271 -0.107329  ... -0.037278  0.026202  0.067330   \n",
       "3    -0.008650 -0.088448  0.039854  ...  0.011349  0.045512  0.066154   \n",
       "4     0.016084 -0.048982 -0.034830  ... -0.004770 -0.027468  0.075778   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2098  0.042757 -0.067661  0.048353  ...  0.001023 -0.029823  0.114998   \n",
       "2099  0.002420 -0.029050 -0.006668  ...  0.071058  0.027249  0.094250   \n",
       "2100  0.041580 -0.035892 -0.029071  ... -0.068082 -0.068496  0.049755   \n",
       "2101  0.007635 -0.055993 -0.030789  ... -0.037224 -0.005990  0.074731   \n",
       "2102 -0.065789 -0.059427 -0.048365  ... -0.026843  0.022689  0.099811   \n",
       "\n",
       "           293       294       295       296       297       298       299  \n",
       "0     0.017581  0.005319 -0.000364  0.014661  0.089783  0.076761 -0.055050  \n",
       "1     0.070816  0.034008  0.028387 -0.135459  0.072594  0.043265 -0.056014  \n",
       "2     0.017581  0.005319 -0.000364  0.014661  0.089783  0.076761 -0.055050  \n",
       "3     0.027690  0.040464  0.008225 -0.022252  0.074263  0.148502 -0.050379  \n",
       "4     0.040369 -0.132114 -0.042492 -0.024968  0.010592  0.081344 -0.039806  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2098  0.048743 -0.115133  0.058256 -0.088071 -0.015225 -0.013587 -0.108568  \n",
       "2099 -0.000389 -0.128791  0.038306 -0.065405  0.047628  0.112749  0.108817  \n",
       "2100  0.012977 -0.085023 -0.012781 -0.061325  0.154539  0.070906 -0.032483  \n",
       "2101  0.037903  0.027928 -0.049965 -0.084224  0.102279  0.076535 -0.035102  \n",
       "2102  0.088141  0.067153 -0.048194 -0.187285  0.049097  0.137798 -0.034750  \n",
       "\n",
       "[2103 rows x 300 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qui viene creato per ogni recensione il vettore\n",
    "\n",
    "w2v_X_train = np.zeros((len(X_train), 300))\n",
    "for i in range(len(X_train)):\n",
    "    w2v_X_train[i,:] = review_vectors(tfidf.inverse_transform(tfidf_model[i, :])[0], 300, tfidf_model[i,:].data, False)\n",
    "w2v_df = pd.DataFrame(w2v_X_train)\n",
    "w2v_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.05013369e-02,  3.18331525e-02,  1.03953749e-04,  7.04872237e-02,\n",
       "       -3.75421942e-02,  9.59559557e-02, -8.49666755e-02,  2.62024787e-02,\n",
       "        4.08488146e-02, -7.77732907e-02, -8.29825782e-02,  6.39312411e-02,\n",
       "       -3.85351705e-02, -9.85354431e-03, -5.60825939e-02, -7.34746177e-03,\n",
       "        2.67223191e-02, -4.68593325e-02,  5.29977439e-02, -6.61357467e-02,\n",
       "        9.87989856e-02,  7.01824383e-03, -2.12569635e-02, -5.96846640e-02,\n",
       "        2.93789424e-02, -3.17789459e-02, -8.63818565e-02,  2.72658673e-02,\n",
       "        1.00540260e-02,  3.64937733e-02,  4.96376616e-02, -2.97857677e-03,\n",
       "       -7.31932823e-02, -8.63674473e-02,  1.17384774e-02, -2.19364326e-02,\n",
       "       -6.72807633e-02,  5.73805180e-02,  4.67527008e-02,  9.97386124e-03,\n",
       "       -4.56938607e-02, -1.59690151e-01,  1.10843650e-02, -1.03785154e-01,\n",
       "       -2.72021819e-03,  2.59736979e-02, -1.74989699e-03, -7.82405835e-03,\n",
       "       -1.43918794e-02, -4.99542362e-02, -5.00860720e-03,  7.22378863e-02,\n",
       "       -2.21282360e-02,  4.07502936e-02,  2.19643983e-02,  8.24663253e-02,\n",
       "        3.01755271e-03, -9.65847585e-02,  6.16064379e-02,  2.09708930e-02,\n",
       "        6.31481040e-02, -8.83689268e-02, -2.82651783e-02,  6.60921484e-02,\n",
       "       -6.66264548e-02, -2.68183029e-02,  1.40795509e-02,  9.13316788e-02,\n",
       "        2.18701782e-02, -2.05551631e-02,  2.20723104e-02, -5.72366385e-02,\n",
       "       -3.54377531e-02, -5.49172693e-02,  8.62195594e-03, -3.44821468e-02,\n",
       "        2.19747106e-02, -2.67891073e-02, -9.82080753e-03, -1.82514659e-02,\n",
       "        9.71645512e-02,  8.05426868e-02,  6.74693547e-02,  4.20202238e-02,\n",
       "       -5.50334516e-02, -4.53853857e-02,  4.29695952e-02, -5.44449590e-02,\n",
       "       -8.42471143e-02,  1.33603424e-01, -4.59112499e-02,  5.47975252e-02,\n",
       "        1.90838274e-02,  4.44952672e-03, -1.39627309e-02, -4.43167450e-02,\n",
       "        4.84921314e-03,  7.78499557e-02, -1.57551925e-01,  1.24994491e-01,\n",
       "       -7.35057692e-02, -3.81644391e-02,  5.02007790e-02,  4.74899541e-03,\n",
       "        2.55319920e-02, -8.17744174e-02,  3.70415054e-02, -2.68154802e-02,\n",
       "        7.29042894e-02, -4.21709466e-02,  2.74569355e-02,  1.20312362e-02,\n",
       "        2.80305630e-02,  4.94513654e-02,  8.89969779e-02,  2.65024988e-04,\n",
       "        1.54795107e-02,  7.46690413e-02, -5.62161767e-02, -6.73154314e-02,\n",
       "       -3.11898966e-02,  3.09958837e-03, -3.59722527e-02, -5.74521144e-02,\n",
       "       -2.41256451e-02, -3.64539029e-02, -4.49866564e-02,  4.19264063e-02,\n",
       "       -7.11514008e-02, -3.77389378e-02,  9.05274656e-02, -5.26087203e-03,\n",
       "       -3.09647856e-02,  4.56087256e-03, -7.26099675e-02, -3.22064836e-02,\n",
       "        7.45102953e-03, -1.48446084e-02,  1.48562675e-01, -6.68088856e-02,\n",
       "       -5.32913426e-02, -6.96669828e-02, -8.21042246e-02,  4.02386452e-02,\n",
       "       -2.70465981e-02,  5.01132618e-02,  5.83267093e-02, -3.09917689e-02,\n",
       "        3.85144985e-02,  3.82255695e-02,  7.79800447e-02, -1.76093203e-02,\n",
       "       -2.40097222e-02, -4.67170234e-02,  1.64060991e-02,  9.25248557e-03,\n",
       "        3.87152002e-02,  2.52395672e-03, -1.02304871e-01,  8.81087937e-02,\n",
       "        3.81490906e-02,  4.76211944e-02,  2.13293273e-02, -3.32302561e-02,\n",
       "        4.71021524e-02, -1.78972033e-02,  4.48567992e-02,  3.24422512e-02,\n",
       "       -3.57075480e-03, -4.16634421e-02,  3.96271017e-02,  6.36591684e-02,\n",
       "        1.15622847e-01,  7.37242485e-02, -1.41895199e-02,  1.51496426e-02,\n",
       "       -5.56583738e-02, -7.49051374e-02,  1.45664245e-02, -6.80112490e-02,\n",
       "       -2.27214856e-02,  3.23652544e-02, -5.26751765e-02,  5.96816996e-02,\n",
       "       -1.52246771e-02,  3.04409829e-02, -1.09933099e-01, -1.83867345e-02,\n",
       "       -8.00170758e-02, -9.74427563e-03, -4.40585099e-02, -4.90399803e-02,\n",
       "       -1.59912549e-02, -3.64171220e-02, -6.99398621e-02,  6.58549064e-02,\n",
       "       -2.65636839e-02, -3.01717058e-03,  3.17616995e-02,  2.15021944e-02,\n",
       "       -1.56854698e-02,  4.14634662e-02,  4.95106002e-02, -6.17785217e-02,\n",
       "        7.66907276e-02, -8.78763098e-03,  1.58849722e-01, -1.41914164e-02,\n",
       "        1.40528836e-01,  2.32467079e-02, -1.30790881e-01, -7.88794178e-02,\n",
       "        3.28230562e-02, -6.56413750e-02, -9.51322437e-02, -9.63119096e-02,\n",
       "       -7.82866019e-03, -4.29937354e-02,  5.43592681e-02,  1.50424096e-02,\n",
       "       -2.57374014e-02, -6.74112162e-02,  2.37764050e-02, -8.04643770e-02,\n",
       "       -6.30493589e-03,  3.02312644e-02,  7.02077264e-02, -3.68425133e-02,\n",
       "       -2.03061221e-02, -7.34229834e-02,  4.65524854e-02,  2.64472316e-02,\n",
       "        2.53018035e-02,  5.59512786e-02, -1.74073224e-02, -8.93734218e-02,\n",
       "        4.47204536e-02,  8.63033220e-03, -5.02780447e-02,  7.13707870e-02,\n",
       "       -3.12609313e-02,  1.32877969e-02, -1.31321900e-02, -2.82242490e-02,\n",
       "        2.37667501e-02,  4.04120071e-02,  7.90838830e-02,  3.61802990e-02,\n",
       "        3.76927776e-03,  1.35292799e-02, -2.03295057e-02,  5.94908031e-03,\n",
       "       -2.50844053e-02,  1.68340327e-02,  3.42249210e-02, -1.52764387e-02,\n",
       "       -1.51480198e-01, -1.44898715e-02,  1.24765273e-01, -5.58506287e-02,\n",
       "        2.82186426e-02, -1.12778802e-01,  1.13633074e-02, -7.25892485e-02,\n",
       "       -3.99477368e-02, -2.06126414e-02, -2.33733437e-03, -1.62451727e-02,\n",
       "        3.95671048e-02, -5.41462382e-02,  6.52913687e-02, -7.49240583e-02,\n",
       "        1.59730006e-02, -5.43334067e-03,  3.07481079e-02, -1.54980823e-02,\n",
       "       -5.63060081e-02,  1.47849727e-01,  6.94297104e-02, -2.52224886e-02,\n",
       "        5.43109476e-02,  9.23163565e-02, -6.50647714e-02,  1.18117647e-01,\n",
       "        5.14616903e-03,  2.15317099e-02, -2.48816708e-02,  3.50965150e-02,\n",
       "       -1.31265125e-02, -6.86942492e-02, -8.42826205e-03,  9.58114995e-04,\n",
       "        1.18409102e-01, -1.30711322e-02, -1.08000122e-01,  2.15675658e-02,\n",
       "       -1.48992050e-01,  6.79404530e-02,  1.03568184e-01, -8.75795744e-02])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vec = np.zeros((len(X_test), 300))\n",
    "for i in range(len(X_test)):\n",
    "    X_test_vec[i,:] = review_vectors(tfidf.inverse_transform(X_test_tf[i, :])[0], 300, X_test_tf[i,:].data, False)\n",
    "\n",
    "X_test_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90        85\n",
      "           1       0.99      0.97      0.98       406\n",
      "\n",
      "    accuracy                           0.96       491\n",
      "   macro avg       0.92      0.96      0.94       491\n",
      "weighted avg       0.97      0.96      0.96       491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(max_iter=3000, class_weight = \"balanced\", C = 100, gamma = 1, kernel = \"rbf\")\n",
    "svm_model = svm.fit(w2v_X_train, Y_train)\n",
    "predictions = svm_model.predict(X_test_vec)\n",
    "print(metrics.classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# risultati migliori:\n",
    "\n",
    "# w2v + tf-idf weights + pos/neg score + svm and word count > 4\n",
    "\n",
    "# w2v configuration:\n",
    "# w2v_model = Word2Vec(cleaned_reviews, vector_size=300, window = 5, min_count = 0, sg=1, hs = 1, alpha=0.03, min_alpha=0.0007) and 100 epochs for training\n",
    "\n",
    "# otherwise the balanced dataset performs better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001],\n",
    "              'kernel': ['rbf','linear', 'poly'],\n",
    "              'class_weight':['balanced', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.876 total time=   0.5s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.851 total time=   0.4s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.851 total time=   0.4s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.892 total time=   0.4s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.895 total time=   0.5s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=1, kernel=linear;, score=0.857 total time=   0.2s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=1, kernel=linear;, score=0.833 total time=   0.2s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=1, kernel=linear;, score=0.817 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=1, kernel=linear;, score=0.876 total time=   0.2s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=1, kernel=linear;, score=0.871 total time=   0.2s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=1, kernel=poly;, score=0.866 total time=   0.3s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=1, kernel=poly;, score=0.868 total time=   0.3s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=1, kernel=poly;, score=0.858 total time=   0.3s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=1, kernel=poly;, score=0.878 total time=   0.3s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=1, kernel=poly;, score=0.907 total time=   0.3s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.843 total time=   0.5s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.823 total time=   0.5s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.813 total time=   0.5s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.852 total time=   0.5s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.895 total time=   0.5s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.857 total time=   0.2s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.833 total time=   0.2s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.817 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.876 total time=   0.2s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.871 total time=   0.2s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.197 total time=   0.3s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.198 total time=   0.5s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.198 total time=   0.5s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.198 total time=   0.5s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.198 total time=   0.5s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.197 total time=   0.5s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.857 total time=   0.2s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.833 total time=   0.2s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.817 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.876 total time=   0.2s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.871 total time=   0.2s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.197 total time=   0.3s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.198 total time=   0.5s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.198 total time=   0.5s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.198 total time=   0.5s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.198 total time=   0.5s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.197 total time=   0.5s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.857 total time=   0.2s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.833 total time=   0.2s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.817 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.876 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.871 total time=   0.2s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.197 total time=   0.3s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=1, kernel=rbf;, score=0.652 total time=   0.2s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=1, kernel=rbf;, score=0.631 total time=   0.2s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=1, kernel=rbf;, score=0.624 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=1, kernel=rbf;, score=0.636 total time=   0.2s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=1, kernel=rbf;, score=0.699 total time=   0.2s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=1, kernel=linear;, score=0.772 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=1, kernel=linear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=1, kernel=linear;, score=0.732 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=1, kernel=linear;, score=0.772 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=1, kernel=linear;, score=0.802 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=1, kernel=poly;, score=0.588 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=1, kernel=poly;, score=0.548 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=1, kernel=poly;, score=0.532 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=1, kernel=poly;, score=0.556 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=1, kernel=poly;, score=0.619 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.429 total time=   0.2s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.1, kernel=linear;, score=0.772 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.1, kernel=linear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.1, kernel=linear;, score=0.732 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.1, kernel=linear;, score=0.772 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.1, kernel=linear;, score=0.802 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.1, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.1, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.1, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.1, kernel=poly;, score=0.429 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.1, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.429 total time=   0.2s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.01, kernel=linear;, score=0.772 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.01, kernel=linear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.01, kernel=linear;, score=0.732 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.01, kernel=linear;, score=0.772 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.01, kernel=linear;, score=0.802 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.01, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.01, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.01, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.01, kernel=poly;, score=0.429 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.01, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.429 total time=   0.2s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.001, kernel=linear;, score=0.772 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.001, kernel=linear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.001, kernel=linear;, score=0.732 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.001, kernel=linear;, score=0.772 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.001, kernel=linear;, score=0.802 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.001, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.001, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.001, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.001, kernel=poly;, score=0.429 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.001, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.912 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.911 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.911 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.915 total time=   0.2s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.926 total time=   0.2s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=1, kernel=linear;, score=0.853 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=1, kernel=linear;, score=0.844 total time=   0.0s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=1, kernel=linear;, score=0.835 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=1, kernel=linear;, score=0.859 total time=   0.1s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=1, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=1, kernel=poly;, score=0.929 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=1, kernel=poly;, score=0.919 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=1, kernel=poly;, score=0.940 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=1, kernel=poly;, score=0.915 total time=   0.1s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=1, kernel=poly;, score=0.935 total time=   0.1s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.863 total time=   0.2s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.838 total time=   0.2s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.819 total time=   0.2s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.877 total time=   0.2s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.869 total time=   0.2s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.853 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.844 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.835 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.859 total time=   0.1s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.843 total time=   0.1s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.430 total time=   0.3s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.838 total time=   0.4s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.825 total time=   0.4s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.812 total time=   0.4s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.852 total time=   0.4s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.897 total time=   0.4s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.853 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.844 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.859 total time=   0.1s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.843 total time=   0.1s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.430 total time=   0.3s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.198 total time=   0.4s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.198 total time=   0.4s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.198 total time=   0.4s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.198 total time=   0.4s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.430 total time=   0.4s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.853 total time=   0.0s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.844 total time=   0.0s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.859 total time=   0.1s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.430 total time=   0.3s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=1, kernel=rbf;, score=0.893 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=1, kernel=rbf;, score=0.882 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=1, kernel=rbf;, score=0.888 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=1, kernel=rbf;, score=0.900 total time=   0.1s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=1, kernel=rbf;, score=0.906 total time=   0.1s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=1, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=1, kernel=linear;, score=0.849 total time=   0.0s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=1, kernel=linear;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=1, kernel=linear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=1, kernel=linear;, score=0.878 total time=   0.0s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=1, kernel=poly;, score=0.924 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=1, kernel=poly;, score=0.922 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=1, kernel=poly;, score=0.937 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=1, kernel=poly;, score=0.899 total time=   0.1s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=1, kernel=poly;, score=0.933 total time=   0.2s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.822 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.779 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.782 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.825 total time=   0.1s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.838 total time=   0.1s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.1, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.1, kernel=linear;, score=0.849 total time=   0.0s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.1, kernel=linear;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.1, kernel=linear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.1, kernel=linear;, score=0.878 total time=   0.0s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.1, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.1, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.1, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.1, kernel=poly;, score=0.429 total time=   0.1s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.1, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.429 total time=   0.2s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.01, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.01, kernel=linear;, score=0.849 total time=   0.0s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.01, kernel=linear;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.01, kernel=linear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.01, kernel=linear;, score=0.878 total time=   0.0s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.01, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.01, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.01, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.01, kernel=poly;, score=0.429 total time=   0.1s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.01, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.429 total time=   0.2s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.001, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.001, kernel=linear;, score=0.849 total time=   0.0s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.001, kernel=linear;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.001, kernel=linear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.001, kernel=linear;, score=0.878 total time=   0.0s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.001, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.001, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.001, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.001, kernel=poly;, score=0.429 total time=   0.1s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.001, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=1, kernel=rbf;, score=0.925 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=1, kernel=rbf;, score=0.926 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=1, kernel=rbf;, score=0.935 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=1, kernel=rbf;, score=0.924 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=1, kernel=rbf;, score=0.931 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=1, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=1, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=1, kernel=linear;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=1, kernel=linear;, score=0.882 total time=   0.0s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=1, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=1, kernel=poly;, score=0.915 total time=   0.2s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=1, kernel=poly;, score=0.899 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=1, kernel=poly;, score=0.893 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=1, kernel=poly;, score=0.917 total time=   0.2s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=1, kernel=poly;, score=0.897 total time=   0.2s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.871 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.873 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.862 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.874 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.865 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.882 total time=   0.0s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.430 total time=   0.3s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.430 total time=   0.3s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.430 total time=   0.3s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.197 total time=   0.3s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.857 total time=   0.2s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.838 total time=   0.2s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.822 total time=   0.2s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.874 total time=   0.3s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.866 total time=   0.2s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.882 total time=   0.0s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.430 total time=   0.3s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.430 total time=   0.3s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.430 total time=   0.3s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.197 total time=   0.3s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.838 total time=   0.4s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.825 total time=   0.4s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.815 total time=   0.4s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.852 total time=   0.4s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.897 total time=   0.4s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.882 total time=   0.0s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.430 total time=   0.3s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.430 total time=   0.3s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.430 total time=   0.3s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.197 total time=   0.3s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=1, kernel=rbf;, score=0.919 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=1, kernel=rbf;, score=0.928 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=1, kernel=rbf;, score=0.927 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=1, kernel=rbf;, score=0.915 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=1, kernel=rbf;, score=0.931 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=1, kernel=linear;, score=0.861 total time=   0.0s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=1, kernel=linear;, score=0.877 total time=   0.0s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=1, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=1, kernel=linear;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=1, kernel=linear;, score=0.891 total time=   0.0s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=1, kernel=poly;, score=0.925 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=1, kernel=poly;, score=0.930 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=1, kernel=poly;, score=0.935 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=1, kernel=poly;, score=0.899 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=1, kernel=poly;, score=0.937 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.1, kernel=rbf;, score=0.884 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.1, kernel=rbf;, score=0.860 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.1, kernel=rbf;, score=0.851 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.1, kernel=rbf;, score=0.867 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.1, kernel=rbf;, score=0.897 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.1, kernel=linear;, score=0.861 total time=   0.0s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.1, kernel=linear;, score=0.877 total time=   0.0s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.1, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.1, kernel=linear;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.1, kernel=linear;, score=0.891 total time=   0.0s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.1, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.1, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.1, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.1, kernel=poly;, score=0.429 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.1, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.01, kernel=rbf;, score=0.826 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.01, kernel=rbf;, score=0.784 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.01, kernel=rbf;, score=0.787 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.01, kernel=rbf;, score=0.825 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.01, kernel=rbf;, score=0.849 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.01, kernel=linear;, score=0.861 total time=   0.0s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.01, kernel=linear;, score=0.877 total time=   0.0s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.01, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.01, kernel=linear;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.01, kernel=linear;, score=0.891 total time=   0.0s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.01, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.01, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.01, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.01, kernel=poly;, score=0.429 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.01, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.001, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.001, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.001, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.001, kernel=rbf;, score=0.429 total time=   0.2s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.001, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.001, kernel=linear;, score=0.861 total time=   0.0s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.001, kernel=linear;, score=0.877 total time=   0.0s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.001, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.001, kernel=linear;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.001, kernel=linear;, score=0.891 total time=   0.0s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.001, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.001, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.001, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.001, kernel=poly;, score=0.429 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.001, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=1, kernel=rbf;, score=0.925 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=1, kernel=rbf;, score=0.926 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=1, kernel=rbf;, score=0.935 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=1, kernel=rbf;, score=0.924 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=1, kernel=rbf;, score=0.931 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=1, kernel=linear;, score=0.886 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=1, kernel=linear;, score=0.886 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=1, kernel=linear;, score=0.897 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=1, kernel=linear;, score=0.901 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=1, kernel=linear;, score=0.883 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=1, kernel=poly;, score=0.886 total time=   0.2s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=1, kernel=poly;, score=0.899 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=1, kernel=poly;, score=0.885 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=1, kernel=poly;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=1, kernel=poly;, score=0.891 total time=   0.2s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.893 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.913 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.901 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.920 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.901 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.886 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.886 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.897 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.901 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.883 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.866 total time=   0.2s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.868 total time=   0.2s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.858 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.878 total time=   0.2s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.907 total time=   0.2s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.846 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.855 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.859 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.859 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.845 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.886 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.886 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.897 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.901 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.883 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.430 total time=   0.3s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.2s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.836 total time=   0.2s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.822 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.874 total time=   0.2s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.864 total time=   0.2s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.886 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.886 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.897 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.901 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.883 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.198 total time=   0.3s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.430 total time=   0.3s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=1, kernel=rbf;, score=0.919 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=1, kernel=rbf;, score=0.928 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=1, kernel=rbf;, score=0.927 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=1, kernel=rbf;, score=0.915 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=1, kernel=rbf;, score=0.931 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=1, kernel=linear;, score=0.870 total time=   0.2s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=1, kernel=linear;, score=0.879 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=1, kernel=linear;, score=0.878 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=1, kernel=linear;, score=0.909 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=1, kernel=linear;, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=1, kernel=poly;, score=0.914 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=1, kernel=poly;, score=0.930 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=1, kernel=poly;, score=0.938 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=1, kernel=poly;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=1, kernel=poly;, score=0.910 total time=   0.2s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.1, kernel=rbf;, score=0.894 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.1, kernel=rbf;, score=0.912 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.1, kernel=rbf;, score=0.902 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.1, kernel=rbf;, score=0.914 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.1, kernel=rbf;, score=0.913 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.1, kernel=linear;, score=0.870 total time=   0.2s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.1, kernel=linear;, score=0.879 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.1, kernel=linear;, score=0.878 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.1, kernel=linear;, score=0.909 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.1, kernel=linear;, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.1, kernel=poly;, score=0.588 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.1, kernel=poly;, score=0.548 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.1, kernel=poly;, score=0.532 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.1, kernel=poly;, score=0.556 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.1, kernel=poly;, score=0.619 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.01, kernel=rbf;, score=0.889 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.01, kernel=rbf;, score=0.857 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.01, kernel=rbf;, score=0.830 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.01, kernel=rbf;, score=0.867 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.01, kernel=rbf;, score=0.894 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.01, kernel=linear;, score=0.870 total time=   0.2s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.01, kernel=linear;, score=0.879 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.01, kernel=linear;, score=0.878 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.01, kernel=linear;, score=0.909 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.01, kernel=linear;, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.01, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.01, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.01, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.01, kernel=poly;, score=0.429 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.01, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.001, kernel=rbf;, score=0.830 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.001, kernel=rbf;, score=0.784 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.001, kernel=rbf;, score=0.787 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.001, kernel=rbf;, score=0.829 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.001, kernel=rbf;, score=0.849 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.001, kernel=linear;, score=0.870 total time=   0.2s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.001, kernel=linear;, score=0.879 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.001, kernel=linear;, score=0.878 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.001, kernel=linear;, score=0.909 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.001, kernel=linear;, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.001, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.001, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.001, kernel=poly;, score=0.430 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.001, kernel=poly;, score=0.429 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.001, kernel=poly;, score=0.430 total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100],\n",
       "                         &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;linear&#x27;, &#x27;poly&#x27;]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100],\n",
       "                         &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;linear&#x27;, &#x27;poly&#x27;]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100],\n",
       "                         'class_weight': ['balanced', None],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001],\n",
       "                         'kernel': ['rbf', 'linear', 'poly']},\n",
       "             scoring='f1_macro', verbose=3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(), param_grid, refit = True, scoring = \"f1_macro\", cv=kfold, verbose=3)\n",
    "grid.fit(w2v_X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89        85\n",
      "           1       0.98      0.97      0.98       406\n",
      "\n",
      "    accuracy                           0.96       491\n",
      "   macro avg       0.92      0.94      0.93       491\n",
      "weighted avg       0.96      0.96      0.96       491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = grid.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(Y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       138\n",
      "           1       0.98      0.96      0.97       598\n",
      "\n",
      "    accuracy                           0.95       736\n",
      "   macro avg       0.91      0.93      0.92       736\n",
      "weighted avg       0.95      0.95      0.95       736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(max_iter=3000, class_weight = \"balanced\", C = 100, gamma = 1, kernel = \"rbf\")\n",
    "svm_model = svm.fit(w2v_X_train, Y_train)\n",
    "predictions = svm_model.predict(X_test_vec)\n",
    "print(metrics.classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43973268aa23c7cf4b4cafe0e819fac9b2412fcc991a21988492c3271a4e3f9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
