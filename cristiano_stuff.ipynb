{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import gensim.downloader as api\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = ['echo', 'alexa', 'dot', \"star\", 'amazon', 'prime', '2nd', 'generation', \"fire\", \"stick\", \"firestick\", \"skype\", \"facetime\", '1st', '3rd', '4th', '5th', \"hub\", \"hulu\", 'google', 'netflix', 'youtube', 'philip', 'tp-link', 'fourth', 'roku', \"siri\", 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"...\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n",
    "\n",
    "def negation_handler(sentence):\t\n",
    "\n",
    "    \"\"\"Handle negations using WordNet. See https://github.com/UtkarshRedd/Negation_handling for a clear explenation.\"\"\"\n",
    "\n",
    "    temp = int(0)\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i-1] in ['not',\"n't\", \"no\", \"without\"]:\n",
    "            antonyms = []\n",
    "            for syn in wordnet.synsets(sentence[i]):\n",
    "                syns = wordnet.synsets(sentence[i])\n",
    "                w1 = syns[0].name()\n",
    "                temp = 0\n",
    "                for l in syn.lemmas():\n",
    "                    if l.antonyms():\n",
    "                        antonyms.append(l.antonyms()[0].name())\n",
    "                max_dissimilarity = 0\n",
    "                for ant in antonyms:\n",
    "                    syns = wordnet.synsets(ant)\n",
    "                    w2 = syns[0].name()\n",
    "                    syns = wordnet.synsets(sentence[i])\n",
    "                    w1 = syns[0].name()\n",
    "                    word1 = wordnet.synset(w1)\n",
    "                    word2 = wordnet.synset(w2)\n",
    "                    if isinstance(word1.wup_similarity(word2), float) or isinstance(word1.wup_similarity(word2), int):\n",
    "                        temp = 1 - word1.wup_similarity(word2)\n",
    "                    if temp>max_dissimilarity:\n",
    "                        max_dissimilarity = temp\n",
    "                        antonym_max = ant\n",
    "                        sentence[i] = antonym_max\n",
    "                        sentence[i-1] = ''\n",
    "    while '' in sentence:\n",
    "        sentence.remove('')\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>love it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>Perfect for kids, adults and everyone in betwe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>Listening to music, searching locations, check...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>I do love these things, i have them running my...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>White  Dot</td>\n",
       "      <td>Only complaint I have is that the sound qualit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating       date   variation  \\\n",
       "3144       5  30-Jul-18  Black  Dot   \n",
       "3145       5  30-Jul-18  Black  Dot   \n",
       "3146       5  30-Jul-18  Black  Dot   \n",
       "3147       5  30-Jul-18  Black  Dot   \n",
       "3148       5  30-Jul-18  White  Dot   \n",
       "\n",
       "                                       verified_reviews  feedback  \n",
       "3144                                            love it         1  \n",
       "3145  Perfect for kids, adults and everyone in betwe...         1  \n",
       "3146  Listening to music, searching locations, check...         1  \n",
       "3147  I do love these things, i have them running my...         1  \n",
       "3148  Only complaint I have is that the sound qualit...         1  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"amazon_alexa.tsv\", sep = \"\\t\")\n",
    "dataset.drop(dataset[dataset.rating == 3].index, inplace=True) #droppa recensioni con 3-4 stelle\n",
    "dataset.drop(dataset[dataset.rating == 4].index, inplace=True) #droppa recensioni con 3-4 stelle\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CREAZIONE DI UN SAMPLE DATASET BILANCIATO\n",
    "# prende le prime n recensioni positive di lunghezza maggiore, dove n Ã¨ il numero di recensioni negative\n",
    "def create_balanced_dataset(dataset):\n",
    "    \"\"\"Bilancia il dataset uniformando il numero di recensioni negative e positive. Prende in input il dataset\"\"\"\n",
    "    reviews_1 = list(dataset[dataset[\"feedback\"] == 1][\"verified_reviews\"])\n",
    "    reviews_0 = list(dataset[dataset[\"feedback\"] == 0][\"verified_reviews\"])\n",
    "    reviews_1.sort(key=len, reverse = True)\n",
    "    sample_1 = reviews_1[:len(reviews_0)]\n",
    "    verified_reviews_sample = []\n",
    "    feedback_sample = []\n",
    "    verified_reviews_sample.extend(sample_1)\n",
    "    verified_reviews_sample.extend(reviews_0)\n",
    "    feedback_sample.extend([1 for i in range(len(sample_1))])\n",
    "    feedback_sample.extend([0 for i in range(len(reviews_0))])\n",
    "    dataset = pd.DataFrame({\"verified_reviews\":verified_reviews_sample, \"feedback\": feedback_sample})\n",
    "    print(dataset[\"feedback\"].value_counts())\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# dataset = create_balanced_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"\n",
    "    return WORDNET POS compliance to WORDENT lemmatization (a,n,r,v).\n",
    "    This was done in order to have compatibility with the wordnet lemmatizer.\n",
    "    For example the pos \"JJ\" is transformed in \"a\".\n",
    "    \"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return \"a\"\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return \"v\"\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return \"n\"\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return \"r\"\n",
    "    else:\n",
    "        return \"n\"\n",
    "        \n",
    "pos_list = [\"JJ\", \"JJR\", \"JJS\", \"RB\", \"RBR\", \"RBS\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"]\n",
    "\n",
    "def tokenize_list_of_text(list_of_text, custom_stopwords = [], pos_filter = False, pos_list = []):\n",
    "    \"\"\"Tokenizza tutte le recensioni, pulisce da stopwords, elimina token <= 2 caratteri e lemmatizza.\n",
    "    Ritorna sia il la lista tokenizzata ma come stringa sia come lista di tokens, dunque ritorna due elementi\"\"\"\n",
    "\n",
    "    tokenizer = nltk.tokenize.TweetTokenizer()\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    detokenizer = TreebankWordDetokenizer()\n",
    "\n",
    "    tokenized_reviews = []\n",
    "    sent_tokenized_reviews = []\n",
    "    pos_reviews = []\n",
    "    for review in list_of_text: #pulisce le recensioni\n",
    "        review = re.sub(r'\\d+', '', review) # elimina i numeri\n",
    "        clean_text = \"\"\n",
    "        tokens = nltk.tokenize.word_tokenize(review, language='english', preserve_line=False)\n",
    "        tokens = negation_handler(tokens)\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "        tokens_pos = pos_tag(tokens)\n",
    "        lemmatized_tokens = [(lemmatizer.lemmatize(w, get_wordnet_pos(pos)), pos) for w, pos in tokens_pos]\n",
    "        if pos_filter:\n",
    "            clean_tokens = [(w, pos) for w, pos in lemmatized_tokens if w not in string.punctuation and len(w)>2 and w not in custom_stopwords and pos in pos_list]\n",
    "        else:\n",
    "            clean_tokens = [(w, pos) for w, pos in lemmatized_tokens if w not in string.punctuation and len(w)>2 and w not in custom_stopwords]\n",
    "        sent_tokenized_reviews.append([w for w, pos in clean_tokens])\n",
    "        tokenized_reviews.append(detokenizer.detokenize([w for w, pos in clean_tokens]))\n",
    "    \n",
    "    n_tokens = []\n",
    "    for sent in sent_tokenized_reviews:\n",
    "        for w in sent:\n",
    "            n_tokens.append(w)\n",
    "    print(\"total number of tokens extracted are:\", len(set(n_tokens)))\n",
    "    return tokenized_reviews,  sent_tokenized_reviews # ritorna una tupla!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of tokens extracted are: 2766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['expect', '....']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text, new_sent_tok = tokenize_list_of_text(dataset[\"verified_reviews\"], custom_stopwords, False, pos_list)\n",
    "# contengono una lista di tutte le frasi pre processate, nella prima variabile in stringa, nella seconda in tokens \n",
    "bigrams = Phrases(new_sent_tok) #estrare le collocazioni tramite PMI\n",
    "bigrams[new_sent_tok][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['purchase$NN',\n",
       " 'mother$NN',\n",
       " 'problem$NN',\n",
       " 'give$VBP',\n",
       " 'something$NN',\n",
       " 'try$NN',\n",
       " 'come$VBP',\n",
       " 'leave$VBP',\n",
       " 'around$IN',\n",
       " 'fast$RB',\n",
       " 'like$IN',\n",
       " 'enjoy$NN',\n",
       " 'little$RB',\n",
       " 'big$JJ',\n",
       " 'thing$NN',\n",
       " 'play$NN',\n",
       " 'song$NN',\n",
       " 'time$NN',\n",
       " 'cook$NN']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elimino token con freq minore di 5\n",
    "tot_tokens = []\n",
    "\n",
    "for sent in [x for x in bigrams[new_sent_tok]]:\n",
    "    for tok in sent:\n",
    "        tot_tokens.append(tok)\n",
    "\n",
    "freqs = nltk.FreqDist(tot_tokens)\n",
    "cleaned_reviews = []\n",
    "\n",
    "for sent in [x for x in bigrams[new_sent_tok]]:\n",
    "    clean_sent = []\n",
    "    for tok in sent:\n",
    "        if freqs[tok] > 4:\n",
    "            clean_sent.append(tok)\n",
    "    cleaned_reviews.append(clean_sent)\n",
    "\n",
    "# qui invece creo una nuova lista che contiene tutti i token e la relativa pos nella forma \"good$JJ\"\n",
    "pos_reviews = [[\"$\".join(x) for x in pos_tag(rev)] for rev in cleaned_reviews]\n",
    "pos_reviews[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 1.0,\n",
       " 'not': 1.0,\n",
       " 'tech_savvy': 1.0,\n",
       " 'device': 0.8648437904399189,\n",
       " 'include': 0.8648437904399189,\n",
       " 'grandkids': 0.8648437904399189,\n",
       " 'cut': 0.8648437904399189,\n",
       " 'place': 0.7240030054062944,\n",
       " 'would': 0.7240030054062944,\n",
       " 'work': 0.6993366681294355,\n",
       " 'great': 0.6977542072262416,\n",
       " 'get': 0.6747608154592976,\n",
       " 'dad': 0.6747608154592976,\n",
       " 'father_day': 0.6747608154592976,\n",
       " 'classroom': 0.6747608154592976,\n",
       " 'comfortable': 0.6747608154592976,\n",
       " 'sooner': 0.6747608154592976,\n",
       " 'time': 0.612980640878305,\n",
       " 'sit': 0.612980640878305,\n",
       " 'course': 0.612980640878305,\n",
       " 'try': 0.5938337210336337,\n",
       " 'use': 0.5852081560151066,\n",
       " 'malfunction': 0.5852081560151066,\n",
       " 'buy': 0.5610881162499615,\n",
       " 'husband': 0.5610881162499615,\n",
       " 'saw': 0.5610881162499615,\n",
       " 'thing': 0.49041767976809375,\n",
       " 'base': 0.49041767976809375,\n",
       " 'one': 0.4847468460507719,\n",
       " 'mother': 0.4847468460507719,\n",
       " 'daughter': 0.4847468460507719,\n",
       " 'sale': 0.4847468460507719,\n",
       " 'product': 0.48097443546119756,\n",
       " 'versatile': 0.48097443546119756,\n",
       " 'highly_recommend': 0.48097443546119756,\n",
       " 'control_light': 0.455765316323714,\n",
       " 'audible': 0.455765316323714,\n",
       " 'living_room': 0.455765316323714,\n",
       " 'really_enjoy': 0.455765316323714,\n",
       " 'guest': 0.455765316323714,\n",
       " 'like': 0.4463874964082101,\n",
       " 'screen': 0.44046719783074056,\n",
       " 'want': 0.433619518751411,\n",
       " 'primarily': 0.433619518751411,\n",
       " 'radio_station': 0.433619518751411,\n",
       " 'tap': 0.40198104711037697,\n",
       " 'compact': 0.40198104711037697,\n",
       " 'brand_new': 0.40198104711037697,\n",
       " 'convenience': 0.40198104711037697,\n",
       " 'sing': 0.40198104711037697,\n",
       " 'hand_free': 0.40198104711037697,\n",
       " 'charm': 0.40198104711037697,\n",
       " 'return': 0.379313075329754,\n",
       " 'stop': 0.36424866996589805,\n",
       " \"n't\": 0.3593388040121897,\n",
       " 'say': 0.3497156427696918,\n",
       " 'good': 0.3330230426197945,\n",
       " 'music': 0.3314159537982547,\n",
       " 'really': 0.331169456916177,\n",
       " 'regret': 0.331169456916177,\n",
       " 'sound': 0.32380791657474023,\n",
       " 'need': 0.31933214337965543,\n",
       " 'ask': 0.31933214337965543,\n",
       " 'voice_command': 0.3117610331794259,\n",
       " 'condition': 0.3117610331794259,\n",
       " 'counter': 0.3117610331794259,\n",
       " 'back': 0.3111124721742413,\n",
       " 'set': 0.30991931715330473,\n",
       " 'alarm_wake': 0.30991931715330473,\n",
       " 'could': 0.3007924330550321,\n",
       " 'surrender': 0.3007924330550321,\n",
       " 'make': 0.29480316102448234,\n",
       " 'busy': 0.29480316102448234,\n",
       " 'terrible': 0.29164650175905366,\n",
       " 'month': 0.2911260965651384,\n",
       " 'still': 0.2910807717550687,\n",
       " 'turn': 0.2890738075632867,\n",
       " 'downstairs': 0.2890738075632867,\n",
       " 'also': 0.2878591007871443,\n",
       " 'day': 0.2865986356118335,\n",
       " 'show': 0.28130933143478376,\n",
       " 'worth_every': 0.28130933143478376,\n",
       " 'penny': 0.28130933143478376,\n",
       " 'still_learn': 0.2799737541409653,\n",
       " 'equipment': 0.2799737541409653,\n",
       " 'connect': 0.2629613240498628,\n",
       " 'ring': 0.2629613240498628,\n",
       " 'doorbell': 0.2629613240498628,\n",
       " 'problem': 0.2627753704262939,\n",
       " 'item': 0.2619701462714551,\n",
       " 'deliver': 0.2619701462714551,\n",
       " 'disappointed': 0.25922682165460503,\n",
       " 'idle': 0.2572477886394178,\n",
       " 'money': 0.2572173453667699,\n",
       " 'easy': 0.25446342753027124,\n",
       " 'speaker': 0.24130478347572634,\n",
       " 'understands': 0.2393476296359876,\n",
       " 'floor': 0.2393476296359876,\n",
       " 'new': 0.23534883772049003,\n",
       " 'flash_briefing': 0.2328901608533195,\n",
       " 'outstanding': 0.2328901608533195,\n",
       " 'give': 0.23287982041950267,\n",
       " 'traffic': 0.23287982041950267,\n",
       " 'phone': 0.22189483204848437,\n",
       " 'never': 0.22120873840935737,\n",
       " 'app': 0.219646661126473,\n",
       " 'know': 0.2148603768709837,\n",
       " 'laugh': 0.2148603768709837,\n",
       " 'unplug': 0.21423933392955996,\n",
       " 'start': 0.2133921357599827,\n",
       " 'walk': 0.2133921357599827,\n",
       " 'half': 0.21210978975244216,\n",
       " 'much': 0.21074357067866317,\n",
       " 'remember': 0.21074357067866317,\n",
       " 'purchase': 0.20877596028836817,\n",
       " 'home': 0.20288943682505323,\n",
       " 'tell': 0.20097050481825876,\n",
       " 'another': 0.197923367063301,\n",
       " 'fun': 0.1963643371046565,\n",
       " 'easy_set': 0.19555092008846717,\n",
       " 'plus': 0.1943873142575988,\n",
       " 'far': 0.19372507581466847,\n",
       " 'think': 0.19261812955141444,\n",
       " 'enjoy': 0.19261812955141444,\n",
       " 'cute': 0.19261812955141444,\n",
       " 'play_music': 0.19222317774131797,\n",
       " 'surprise': 0.19176141665209404,\n",
       " 'bulb': 0.19176141665209404,\n",
       " 'reason': 0.19153789029323973,\n",
       " 'tell_joke': 0.1893207485875256,\n",
       " 'even': 0.1893207485875256,\n",
       " 'four': 0.1893207485875256,\n",
       " 'pool': 0.1893207485875256,\n",
       " 'already': 0.18872295080284807,\n",
       " 'way': 0.18802335361320582,\n",
       " 'two': 0.18802335361320582,\n",
       " 'three': 0.18802335361320582,\n",
       " 'play': 0.17952827791815099,\n",
       " 'type': 0.17952827791815099,\n",
       " 'various': 0.17952827791815099,\n",
       " 'fix': 0.17829890249801922,\n",
       " 'light': 0.17615872046834505,\n",
       " 'toy': 0.17101579842789624,\n",
       " 'refurbish': 0.17021069433523905,\n",
       " 'see': 0.1668496128784932,\n",
       " 'wifi': 0.16476684639759584,\n",
       " 'smart': 0.1624147475497079,\n",
       " 'everything': 0.16177716435869804,\n",
       " 'talk': 0.1616579687378304,\n",
       " 'cell_phone': 0.1616579687378304,\n",
       " 'many': 0.15929877208503682,\n",
       " 'odd': 0.15918497296677292,\n",
       " 'enough': 0.15856372663116597,\n",
       " 'unsure': 0.15746940224355896,\n",
       " 'well': 0.15734946624741508,\n",
       " 'poor': 0.15636050160483128,\n",
       " 'phenomenal': 0.15624877032936535,\n",
       " 'gadget': 0.15624877032936535,\n",
       " 'entertainment': 0.15624877032936535,\n",
       " 'amaze': 0.15624877032936535,\n",
       " 'learning': 0.15594569354881463,\n",
       " 'plug': 0.15594569354881463,\n",
       " 'cloud': 0.15594569354881463,\n",
       " 'look': 0.15367249206566666,\n",
       " 'interface': 0.15367249206566666,\n",
       " 'anything': 0.1528240750782704,\n",
       " 'lack': 0.15231412070957437,\n",
       " 'keep': 0.15209946969856725,\n",
       " 'hue': 0.15165157100422014,\n",
       " 'something': 0.15070876399052863,\n",
       " 'record': 0.15070876399052863,\n",
       " 'schedule': 0.15070876399052863,\n",
       " 'hour': 0.15039993586698536,\n",
       " 'price': 0.15018575156614467,\n",
       " 'super_easy': 0.15018575156614467,\n",
       " 'repair': 0.15006154747611336,\n",
       " 'speak': 0.149212516057873,\n",
       " 'pay': 0.1480830427394525,\n",
       " 'reset': 0.14763787507499432,\n",
       " 'useless': 0.14763787507499432,\n",
       " 'sell': 0.14763787507499432,\n",
       " 'nothing': 0.1470061224763919,\n",
       " 'quite': 0.1470061224763919,\n",
       " 'understand': 0.1459770814670981,\n",
       " 'refurbished': 0.1459770814670981,\n",
       " 'answer': 0.1449918429513726,\n",
       " 'feature': 0.14388942409559313,\n",
       " 'able': 0.14320384655019383,\n",
       " 'realize': 0.14171811680579652,\n",
       " 'unit': 0.14142331468660496,\n",
       " 'recall': 0.14142331468660496,\n",
       " 'hire': 0.14124432095888545,\n",
       " 'room': 0.1412435469153071,\n",
       " 'little': 0.14091137509685364,\n",
       " 'support': 0.14007104343552657,\n",
       " 'help': 0.1398321288999443,\n",
       " 'week': 0.13982615655376657,\n",
       " 'first': 0.13939242947596936,\n",
       " 'send': 0.13712639556348005,\n",
       " 'respond': 0.1357983585365987,\n",
       " 'spot': 0.13572477499242824,\n",
       " 'learn': 0.1346540330718059,\n",
       " 'bad': 0.1345508595066583,\n",
       " 'best': 0.13401613983039573,\n",
       " 'order': 0.13375252590571243,\n",
       " 'weather': 0.133329995622513,\n",
       " 'throughout_house': 0.13226212156904876,\n",
       " 'favorite': 0.13226212156904876,\n",
       " 'actually': 0.13226212156904876,\n",
       " 'send_back': 0.1321030714416336,\n",
       " 'cycle': 0.1321030714416336,\n",
       " 'spend': 0.1321030714416336,\n",
       " 'dont': 0.1312696767612569,\n",
       " 'voice': 0.1299309939101441,\n",
       " 'totally': 0.12970020560735782,\n",
       " 'instal': 0.12970020560735782,\n",
       " 'nice': 0.12836459029651348,\n",
       " 'card': 0.12757809158881453,\n",
       " 'come': 0.12754231898573568,\n",
       " 'find': 0.12537722712965094,\n",
       " 'perfect': 0.1252918914054223,\n",
       " 'alarm': 0.12496748880592488,\n",
       " 'calendar': 0.12496748880592488,\n",
       " 'awesome': 0.12461707344853121,\n",
       " 'bedroom': 0.12461707344853121,\n",
       " 'connection': 0.12396496495605919,\n",
       " 'house': 0.12259593434759546,\n",
       " 'add': 0.12259593434759546,\n",
       " 'switch': 0.12239830310326645,\n",
       " 'setup': 0.12218847627616287,\n",
       " 'issue': 0.12218847627616287,\n",
       " 'everywhere': 0.12178235347344045,\n",
       " 'everyday': 0.12178235347344045,\n",
       " 'minor': 0.12156344330157604,\n",
       " 'question': 0.12090196788487101,\n",
       " 'account': 0.11838054701623953,\n",
       " 'work_fine': 0.11721851461771832,\n",
       " 'listen_music': 0.11677495764984343,\n",
       " 'disconnect': 0.11377588110537237,\n",
       " 'disappointing': 0.11377588110537237,\n",
       " 'around_house': 0.11289966783746457,\n",
       " 'improvement': 0.11232227928303103,\n",
       " 'full': 0.11232227928303103,\n",
       " 'replace': 0.11232227928303103,\n",
       " 'seem': 0.11148467463398384,\n",
       " 'unless': 0.11139686226219393,\n",
       " 'either': 0.11139686226219393,\n",
       " 'act': 0.10933606240347397,\n",
       " 'scroll': 0.10933606240347397,\n",
       " 'bridge': 0.10933606240347397,\n",
       " 'slow': 0.10933606240347397,\n",
       " 'family': 0.10894586501788668,\n",
       " 'grandchild': 0.10894586501788668,\n",
       " 'absolutely_love': 0.10894586501788668,\n",
       " 'wake': 0.1084768235822049,\n",
       " 'sound_quality': 0.10792528733664819,\n",
       " 'end': 0.10589227147173663,\n",
       " '....': 0.10530986763983702,\n",
       " 'volume': 0.10530986763983702,\n",
       " 'lyric': 0.10530986763983702,\n",
       " 'big': 0.10364666264444515,\n",
       " 'alexia': 0.10364666264444515,\n",
       " 'guy': 0.10364666264444515,\n",
       " 'apple': 0.10307848940073637,\n",
       " \"'ll\": 0.1018431843730339,\n",
       " 'review': 0.1018431843730339,\n",
       " 'worry': 0.1018431843730339,\n",
       " 'clock': 0.10072046820861608,\n",
       " 'additional': 0.09984198896095567,\n",
       " 'without': 0.09984198896095567,\n",
       " 'ease': 0.09980431755678627,\n",
       " 'worth': 0.09980431755678627,\n",
       " 'intuitive': 0.09980431755678627,\n",
       " 'cheap': 0.09963469846899901,\n",
       " 'number': 0.09963469846899901,\n",
       " 'seriously': 0.09963469846899901,\n",
       " 'ignore': 0.09963469846899901,\n",
       " 'amazing': 0.09962085822620687,\n",
       " 'listen': 0.09893878558114685,\n",
       " 'piece': 0.09863867069883797,\n",
       " 'audio': 0.09863867069883797,\n",
       " 'expect': 0.09828346788106918,\n",
       " 'leave': 0.09770304642638271,\n",
       " 'ask_question': 0.09682091639799871,\n",
       " 'song': 0.0956939900054158,\n",
       " 'lot': 0.0956535656913172,\n",
       " 'horrible': 0.09501798717790318,\n",
       " 'garbage': 0.09501798717790318,\n",
       " 'que': 0.09372395071277984,\n",
       " 'internet': 0.09372395071277984,\n",
       " 'bluetooth': 0.09303792337325067,\n",
       " 'stupid': 0.09267316878540295,\n",
       " 'customer_service': 0.09267316878540295,\n",
       " 'small': 0.09258544336292387,\n",
       " 'receive': 0.09238109769610034,\n",
       " 'notification': 0.09238109769610034,\n",
       " 'radio': 0.0917510888353633,\n",
       " 'wish': 0.09141535174820552,\n",
       " 'deal': 0.09114579266839787,\n",
       " 'hope': 0.09069065308275427,\n",
       " 'point': 0.09069065308275427,\n",
       " 'clarity': 0.08988886836848514,\n",
       " 'great_addition': 0.08988886836848514,\n",
       " 'middle': 0.0889733198671543,\n",
       " 'take': 0.08865227590688204,\n",
       " 'kitchen': 0.0884371170308083,\n",
       " 'figure': 0.08843125900351112,\n",
       " 'watch_movie': 0.08779558115069393,\n",
       " 'update': 0.08746637771004223,\n",
       " 'battery': 0.08745852461645492,\n",
       " 'hard': 0.08745852461645492,\n",
       " 'hop': 0.08745852461645492,\n",
       " 'install': 0.08745852461645492,\n",
       " 'clearly': 0.08745852461645492,\n",
       " 'obviate': 0.08745852461645492,\n",
       " 'old': 0.08700565472174669,\n",
       " 'school': 0.08700565472174669,\n",
       " 'second': 0.08700565472174669,\n",
       " 'version': 0.08700565472174669,\n",
       " 'work_well': 0.08682891470912837,\n",
       " 'hear': 0.08682891470912837,\n",
       " 'video': 0.08682891470912837,\n",
       " 'watch': 0.08626683591315999,\n",
       " 'pretty': 0.0861235246933627,\n",
       " 'within': 0.0861034940907065,\n",
       " 'often': 0.0861034940907065,\n",
       " 'wrong': 0.0861034940907065,\n",
       " 'lose': 0.0861034940907065,\n",
       " 'happy': 0.08530432682028789,\n",
       " \"'re\": 0.08528910126853952,\n",
       " 'quality': 0.08528910126853952,\n",
       " 'bother': 0.08528910126853952,\n",
       " 'sync': 0.08487771987877253,\n",
       " 'bass': 0.08487771987877253,\n",
       " 'cool': 0.08442418676606996,\n",
       " 'custom': 0.08411640514602448,\n",
       " 'entire': 0.08411640514602448,\n",
       " 'control': 0.08411640514602448,\n",
       " 'kasa_smart': 0.08411640514602448,\n",
       " 'functionality': 0.08375867569820628,\n",
       " 'setting': 0.08375867569820628,\n",
       " 'miss': 0.08375867569820628,\n",
       " 'constantly': 0.08272925484178754,\n",
       " 'package': 0.08272925484178754,\n",
       " 'instead': 0.08272925484178754,\n",
       " 'improve': 0.08177615999555758,\n",
       " 'experience': 0.08177615999555758,\n",
       " 'specific': 0.08168370599146434,\n",
       " 'outside': 0.08136548700700584,\n",
       " 'deck': 0.08136548700700584,\n",
       " 'news': 0.08104750839375108,\n",
       " 'etc': 0.0800672429322454,\n",
       " 'several': 0.08005882677995763,\n",
       " 'upgrade': 0.08005882677995763,\n",
       " 'next': 0.0792791398862449,\n",
       " 'people': 0.0792791398862449,\n",
       " 'gift': 0.07917778967322701,\n",
       " 'minute': 0.07784867867523891,\n",
       " 'information': 0.07729866841036606,\n",
       " 'fine': 0.07718900100350984,\n",
       " 'call': 0.07632170546254603,\n",
       " 'definitely': 0.07596322679157586,\n",
       " 'soon': 0.07539153734196823,\n",
       " 'useful': 0.0748441826110096,\n",
       " 'yet': 0.074751169155192,\n",
       " 'dislike': 0.07381476175459088,\n",
       " 'warranty': 0.07344631117943372,\n",
       " 'annoy': 0.07344631117943372,\n",
       " 'unbend': 0.07344631117943372,\n",
       " 'unable': 0.07344631117943372,\n",
       " 'apps': 0.07286166690836092,\n",
       " 'size': 0.07285348183698902,\n",
       " 'sure': 0.07197435683456181,\n",
       " 'part': 0.07197435683456181,\n",
       " 'kid': 0.07160220484358194,\n",
       " 'mode': 0.07157045646543353,\n",
       " 'potential': 0.07157045646543353,\n",
       " 'suck': 0.07157045646543353,\n",
       " 'activate': 0.07157045646543353,\n",
       " 'jack': 0.07157045646543353,\n",
       " 'waste': 0.07157045646543353,\n",
       " 'speaker_via': 0.07157045646543353,\n",
       " 'simple': 0.07155265036718525,\n",
       " 'right': 0.07126922309563885,\n",
       " 'night': 0.07074858262262784,\n",
       " 'command': 0.07036464679904822,\n",
       " 'wonderful': 0.07002547375825295,\n",
       " \"'ve\": 0.06999184113191312,\n",
       " 'sonos': 0.06998444390331457,\n",
       " 'basically': 0.06998444390331457,\n",
       " 'software': 0.06998444390331457,\n",
       " 'error': 0.06998444390331457,\n",
       " 'since': 0.06968270908173683,\n",
       " 'option': 0.06968270908173683,\n",
       " 'wall': 0.06861057733083462,\n",
       " 'unretentive': 0.06861057733083462,\n",
       " 'step': 0.06861057733083462,\n",
       " 'alarm_clock': 0.0677523436436069,\n",
       " 'camera': 0.0677523436436069,\n",
       " 'turn_light': 0.06742029036323191,\n",
       " 'original': 0.06742029036323191,\n",
       " 'skill': 0.06742029036323191,\n",
       " 'smart_home': 0.06709815061606661,\n",
       " 'thought': 0.06631471670967637,\n",
       " 'suppose': 0.06631471670967637,\n",
       " 'another_room': 0.06540468213986537,\n",
       " 'load': 0.0653340973401292,\n",
       " 'box': 0.0653340973401292,\n",
       " 'difficult': 0.0644388619956762,\n",
       " 'lock': 0.0644388619956762,\n",
       " 'pleasure': 0.0644388619956762,\n",
       " 'view': 0.0644388619956762,\n",
       " 'tech': 0.06361532531054122,\n",
       " 'bonus': 0.06361532531054122,\n",
       " 'real': 0.06361532531054122,\n",
       " 'open': 0.06361532531054122,\n",
       " 'kind': 0.06361532531054122,\n",
       " 'light_bulb': 0.06285284943355723,\n",
       " 'difference': 0.06214300137451796,\n",
       " 'differ': 0.06214300137451796,\n",
       " 'live': 0.061892409452797614,\n",
       " 'recommend': 0.06147898286107727,\n",
       " 'wife': 0.06124239520763586,\n",
       " 'must': 0.06085523334610708,\n",
       " 'bluetooth_speaker': 0.06085523334610708,\n",
       " 'lot_fun': 0.06068182720877792,\n",
       " 'excelente': 0.06068182720877792,\n",
       " 'exactly': 0.06068182720877792,\n",
       " 'user_friendly': 0.06068182720877792,\n",
       " 'begin': 0.06068182720877792,\n",
       " 'look_brand': 0.06068182720877792,\n",
       " 'almost': 0.06026714666051776,\n",
       " 'satisfy': 0.06026714666051776,\n",
       " 'super': 0.06026714666051776,\n",
       " 'excellent': 0.06025662072798714,\n",
       " 'access': 0.05971086437730231,\n",
       " 'away': 0.05971086437730231,\n",
       " 'different': 0.05926638902508177,\n",
       " 'always': 0.05918312223991905,\n",
       " 'long': 0.05895821359627668,\n",
       " 'program': 0.058681134098398806,\n",
       " 'instruction': 0.058681134098398806,\n",
       " 'whole': 0.058681134098398806,\n",
       " 'easy_setup': 0.05826591561676827,\n",
       " 'pleased': 0.05826591561676827,\n",
       " 'build': 0.05820250287037186,\n",
       " 'sleep': 0.05792434996360165,\n",
       " 'friend': 0.05792434996360165,\n",
       " 'movie': 0.05759520766942229,\n",
       " 'around': 0.05730726752591885,\n",
       " 'rent': 0.05730726752591885,\n",
       " 'fact': 0.05688726161876082,\n",
       " 'easily': 0.055920507711876385,\n",
       " 'read': 0.05559207919921617,\n",
       " 'thank': 0.05559207919921617,\n",
       " 'glad': 0.05390275865702334,\n",
       " 'cable': 0.05357509980698448,\n",
       " 'son': 0.05325980843483068,\n",
       " 'deny': 0.05187463518096425,\n",
       " 'yard': 0.05187463518096425,\n",
       " 'simultaneously': 0.05187463518096425,\n",
       " 'nest': 0.05187463518096425,\n",
       " 'buyer': 0.05187463518096425,\n",
       " 'none': 0.05187463518096425,\n",
       " 'party': 0.05187463518096425,\n",
       " 'past': 0.05187463518096425,\n",
       " 'maybe': 0.05187463518096425,\n",
       " 'complete': 0.05187463518096425,\n",
       " 'adapter': 0.05187463518096425,\n",
       " 'handy': 0.051549539628641464,\n",
       " 'wait': 0.051229691902092596,\n",
       " 'list': 0.051229691902092596,\n",
       " 'compare': 0.050467744145464115,\n",
       " 'later': 0.050467744145464115,\n",
       " 'due': 0.050467744145464115,\n",
       " 'clock_face': 0.050467744145464115,\n",
       " 'honestly': 0.050467744145464115,\n",
       " 'excite': 0.050467744145464115,\n",
       " 'capability': 0.05016359152294642,\n",
       " 'fast': 0.04982317797062778,\n",
       " 'timer': 0.04982317797062778,\n",
       " 'stuff': 0.04949725457205548,\n",
       " 'satisfied': 0.049278234723874895,\n",
       " 'move': 0.049278234723874895,\n",
       " 'close': 0.049278234723874895,\n",
       " 'interact': 0.049278234723874895,\n",
       " 'hue_bulb': 0.049278234723874895,\n",
       " 'continue': 0.04824783479451492,\n",
       " 'impress': 0.04824783479451492,\n",
       " 'photo': 0.04824783479451492,\n",
       " 'even_though': 0.04824783479451492,\n",
       " 'pair': 0.04824783479451492,\n",
       " 'expensive': 0.04824783479451492,\n",
       " 'unmake': 0.04824783479451492,\n",
       " 'work_perfectly': 0.04776003327597518,\n",
       " 'drop': 0.04743509306694373,\n",
       " 'drop-in': 0.047338957644095285,\n",
       " 'communicate': 0.047338957644095285,\n",
       " 'free': 0.047338957644095285,\n",
       " 'rather': 0.047338957644095285,\n",
       " 'completely': 0.047338957644095285,\n",
       " 'privacy': 0.047338957644095285,\n",
       " 'selection': 0.047338957644095285,\n",
       " 'cord': 0.047338957644095285,\n",
       " 'every': 0.04712398436830655,\n",
       " 'lol': 0.046899193065456105,\n",
       " 'digital': 0.046525939328646244,\n",
       " 'yes': 0.046525939328646244,\n",
       " 'top': 0.046525939328646244,\n",
       " 'face': 0.046525939328646244,\n",
       " 'choose': 0.046525939328646244,\n",
       " 'response': 0.04579047480148586,\n",
       " 'automation': 0.04579047480148586,\n",
       " 'ready': 0.04579047480148586,\n",
       " 'color': 0.04579047480148586,\n",
       " 'else': 0.04535647502900393,\n",
       " 'run': 0.04535647502900393,\n",
       " 'couple': 0.04511904829314611,\n",
       " 'forget': 0.04511904829314611,\n",
       " 'pick': 0.04511904829314611,\n",
       " 'high': 0.04511904829314611,\n",
       " 'may': 0.04511904829314611,\n",
       " 'loud': 0.04511904829314611,\n",
       " 'finally': 0.04511904829314611,\n",
       " 'stay': 0.04511904829314611,\n",
       " 'system': 0.045047008163259704,\n",
       " 'contact': 0.04450139577929488,\n",
       " 'however': 0.04450139577929488,\n",
       " 'save': 0.04450139577929488,\n",
       " 'check': 0.04450139577929488,\n",
       " 'trouble': 0.043929538871556886,\n",
       " 'touch': 0.043929538871556886,\n",
       " 'less': 0.043929538871556886,\n",
       " 'along': 0.043929538871556886,\n",
       " 'low': 0.043929538871556886,\n",
       " 'white': 0.043929538871556886,\n",
       " 'office': 0.04358327593690388,\n",
       " 'morning': 0.04358327593690388,\n",
       " 'convenient': 0.04358327593690388,\n",
       " 'technology': 0.0432605892447267,\n",
       " 'hook': 0.0432605892447267,\n",
       " 'especially': 0.04295291678203268,\n",
       " 'name': 0.04289913894219692,\n",
       " 'function': 0.04243132680596928,\n",
       " 'change': 0.04243132680596928,\n",
       " 'perform': 0.04243132680596928,\n",
       " 'probably': 0.04243132680596928,\n",
       " 'feel': 0.04243132680596928,\n",
       " 'complaint': 0.04243132680596928,\n",
       " 'multiple': 0.04199026179177729,\n",
       " 'download': 0.04180669536091141,\n",
       " 'recipe': 0.04180669536091141,\n",
       " 'decide': 0.041573050079365695,\n",
       " 'bit': 0.041467927868139555,\n",
       " 'book': 0.041467927868139555,\n",
       " 'reminder': 0.04117724347632824,\n",
       " 'advertised': 0.04117724347632824,\n",
       " 'though': 0.04117724347632824,\n",
       " 'ever': 0.04117724347632824,\n",
       " 'clear': 0.04114654089230783,\n",
       " 'plan': 0.04114654089230783,\n",
       " 'ability': 0.04114654089230783,\n",
       " 'year': 0.040840837710245236,\n",
       " 'moment': 0.039770352440828105,\n",
       " 'life': 0.039671524522135425,\n",
       " 'look_forward': 0.0393332850680596,\n",
       " 'put': 0.0393332850680596,\n",
       " 'definitely_worth': 0.03915269992697687,\n",
       " 'source': 0.038048456974959434,\n",
       " 'cook': 0.03751586580502291,\n",
       " 'helpful': 0.03717821779080857,\n",
       " 'game': 0.03717821779080857,\n",
       " 'daily': 0.03717821779080857,\n",
       " 'request': 0.0368598747752078,\n",
       " 'remote': 0.0368598747752078,\n",
       " 'set_timer': 0.035338437095062736,\n",
       " 'easy_install': 0.035338437095062736,\n",
       " 'smart_plug': 0.03500145607280767,\n",
       " 'mostly': 0.03500145607280767,\n",
       " 'door': 0.03500145607280767,\n",
       " 'display': 0.03500145607280767,\n",
       " 'spotify': 0.034684911059481724,\n",
       " 'thermostat': 0.034684911059481724,\n",
       " 'gen': 0.034684911059481724,\n",
       " 'link': 0.034684911059481724,\n",
       " 'available': 0.0331377849708478,\n",
       " 'mom': 0.0331377849708478,\n",
       " 'assistant': 0.03280156196136382,\n",
       " 'lamp': 0.03280156196136382,\n",
       " 'check_weather': 0.03280156196136382,\n",
       " 'everyone': 0.03280156196136382,\n",
       " 'pandora': 0.03248704634059242,\n",
       " 'discover': 0.03248704634059242,\n",
       " 'grocery_list': 0.031964296595481036,\n",
       " 'trivia': 0.031292870087141274,\n",
       " 'happy_purchase': 0.030912247881573027,\n",
       " 'thanks': 0.030912247881573027,\n",
       " 'let': 0.030576893907900034,\n",
       " 'many_thing': 0.030576893907900034,\n",
       " 'large': 0.030576893907900034,\n",
       " 'extra': 0.030576893907900034,\n",
       " 'future': 0.030576893907900034,\n",
       " 'hate': 0.03030295918249479,\n",
       " 'follow': 0.03030295918249479,\n",
       " 'company': 0.03030295918249479,\n",
       " 'limited': 0.03030295918249479,\n",
       " 'seamlessly': 0.03030295918249479,\n",
       " 'bug': 0.03030295918249479,\n",
       " 'boom': 0.03030295918249479,\n",
       " 'bottom': 0.03030295918249479,\n",
       " 'mean': 0.03030295918249479,\n",
       " 'message': 0.03030295918249479,\n",
       " 'fan': 0.03030295918249479,\n",
       " 'yell': 0.03030295918249479,\n",
       " 'enter': 0.03030295918249479,\n",
       " 'basic': 0.03030295918249479,\n",
       " 'guess': 0.03030295918249479,\n",
       " 'fill': 0.03030295918249479,\n",
       " 'together': 0.03030295918249479,\n",
       " 'tablet': 0.03030295918249479,\n",
       " 'silence': 0.03030295918249479,\n",
       " 'loud_enough': 0.03030295918249479,\n",
       " 'network': 0.03030295918249479,\n",
       " 'speed': 0.03030295918249479,\n",
       " 'year_old': 0.030264686827664908,\n",
       " 'huge': 0.030264686827664908,\n",
       " 'quick': 0.030264686827664908,\n",
       " 'word': 0.030264686827664908,\n",
       " 'video_chat': 0.030264686827664908,\n",
       " 'fantastic': 0.030264686827664908,\n",
       " 'hardly': 0.029365031825494693,\n",
       " 'surprised': 0.029365031825494693,\n",
       " 'responds': 0.029365031825494693,\n",
       " 'funny': 0.029365031825494693,\n",
       " 'five': 0.029365031825494693,\n",
       " 'please': 0.029365031825494693,\n",
       " 'least': 0.029365031825494693,\n",
       " 'allow': 0.029365031825494693,\n",
       " 'short': 0.029365031825494693,\n",
       " '.....': 0.029365031825494693,\n",
       " 'black': 0.029365031825494693,\n",
       " 'exchange': 0.029365031825494693,\n",
       " 'default': 0.029365031825494693,\n",
       " 'mainly': 0.028659907945396378,\n",
       " 'discount': 0.02857202554443522,\n",
       " 'repeat': 0.02857202554443522,\n",
       " 'rock': 0.02857202554443522,\n",
       " 'fault': 0.02857202554443522,\n",
       " 'line': 0.02857202554443522,\n",
       " '......': 0.02857202554443522,\n",
       " 'personal': 0.02832556035911195,\n",
       " 'computer': 0.02832556035911195,\n",
       " 'sometimes': 0.028016002844952256,\n",
       " 'think_would': 0.028016002844952256,\n",
       " 'user': 0.027885092258195243,\n",
       " 'sister': 0.027885092258195243,\n",
       " 'overall': 0.027885092258195243,\n",
       " 'today': 0.027885092258195243,\n",
       " 'excited': 0.027885092258195243,\n",
       " 'adjust': 0.027885092258195243,\n",
       " 'power': 0.027885092258195243,\n",
       " 'concern': 0.027885092258195243,\n",
       " 'replacement': 0.027885092258195243,\n",
       " 'external': 0.027885092258195243,\n",
       " 'cost': 0.027885092258195243,\n",
       " 'might': 0.027885092258195243,\n",
       " 'mini': 0.02727917415791548,\n",
       " 'disappoint': 0.02727917415791548,\n",
       " 'blue': 0.02727917415791548,\n",
       " 'tooth': 0.02727917415791548,\n",
       " 'become': 0.02727917415791548,\n",
       " 'range': 0.02727917415791548,\n",
       " 'station': 0.02727917415791548,\n",
       " 'every_room': 0.026737161947616116,\n",
       " 'immediately': 0.026737161947616116,\n",
       " 'process': 0.026737161947616116,\n",
       " 'job': 0.026737161947616116,\n",
       " 'alone': 0.026737161947616116,\n",
       " 'intercom': 0.026737161947616116,\n",
       " 'service': 0.026737161947616116,\n",
       " 'happen': 0.026737161947616116,\n",
       " 'play_game': 0.026378526599523732,\n",
       " 'every_morning': 0.026378526599523732,\n",
       " 'blast': 0.026378526599523732,\n",
       " 'create': 0.026378526599523732,\n",
       " 'household': 0.02624685226284253,\n",
       " 'across': 0.02624685226284253,\n",
       " 'value': 0.02624685226284253,\n",
       " 'impressed': 0.02624685226284253,\n",
       " 'third': 0.02624685226284253,\n",
       " 'ago': 0.02624685226284253,\n",
       " 'channel': 0.02624685226284253,\n",
       " 'watch_video': 0.02624685226284253,\n",
       " 'nightstand': 0.02624685226284253,\n",
       " 'birthday': 0.02604535812407826,\n",
       " 'group': 0.02604535812407826,\n",
       " 'parent': 0.02604535812407826,\n",
       " 'security': 0.02604535812407826,\n",
       " 'joke': 0.02579923459061603,\n",
       " 'someone': 0.02579923459061603,\n",
       " 'arrive': 0.02579923459061603,\n",
       " 'stand': 0.02579923459061603,\n",
       " 'button': 0.02579923459061603,\n",
       " 'fall': 0.02579923459061603,\n",
       " 'stream': 0.02579923459061603,\n",
       " 'offer': 0.02573887283665087,\n",
       " 'playlist': 0.02573887283665087,\n",
       " 'bose': 0.02573887283665087,\n",
       " 'tune': 0.024651304280036913,\n",
       " 'search': 0.024065456711231295,\n",
       " 'front': 0.024007420265831476,\n",
       " 'make_life': 0.023733688734983303,\n",
       " 'story': 0.023733688734983303,\n",
       " 'quickly': 0.023733688734983303,\n",
       " 'would_recommend': 0.023733688734983303,\n",
       " 'bedside': 0.023733688734983303,\n",
       " 'although': 0.023733688734983303,\n",
       " 'expectation': 0.023713376923036815,\n",
       " 'stereo': 0.02292037064197734,\n",
       " 'favorite_song': 0.021717519283367858,\n",
       " 'shopping_list': 0.021717519283367858,\n",
       " 'routine': 0.021717519283367858,\n",
       " 'kindle': 0.0216275192554576,\n",
       " 'work_advertised': 0.02138744204906607,\n",
       " 'provide': 0.02138744204906607,\n",
       " 'wireless': 0.02138744204906607,\n",
       " 'explore': 0.02138744204906607,\n",
       " 'extremely': 0.02138744204906607,\n",
       " 'upstairs': 0.02138744204906607,\n",
       " 'video_call': 0.02138744204906607,\n",
       " 'regular': 0.02138744204906607,\n",
       " 'picture': 0.02138744204906607,\n",
       " 'artist': 0.02059519736038465,\n",
       " 'appointment': 0.02059519736038465,\n",
       " 'trek': 0.020292500764098772,\n",
       " 'installation': 0.019330824887854432,\n",
       " 'addition': 0.019330824887854432,\n",
       " 'news_weather': 0.019002829372946874,\n",
       " 'voice_control': 0.019002829372946874,\n",
       " 'consider': 0.019002829372946874,\n",
       " 'hit': 0.019002829372946874,\n",
       " 'responsive': 0.019002829372946874,\n",
       " 'could_differ': 0.019002829372946874,\n",
       " 'absolutely': 0.019002829372946874,\n",
       " 'bed': 0.019002829372946874,\n",
       " 'world': 0.019002829372946874,\n",
       " 'tool': 0.019002829372946874,\n",
       " 'others': 0.016900504853197693,\n",
       " 'packaging': 0.016900504853197693,\n",
       " 'microphone': 0.016900504853197693,\n",
       " 'misuse': 0.016900504853197693,\n",
       " 'report': 0.0167267035292201,\n",
       " 'operate': 0.016575135538070003,\n",
       " 'simply': 0.016575135538070003,\n",
       " 'design': 0.016575135538070003,\n",
       " 'cover': 0.016575135538070003,\n",
       " 'info': 0.016575135538070003,\n",
       " 'inside': 0.016575135538070003,\n",
       " 'shop': 0.016575135538070003,\n",
       " 'bathroom': 0.016575135538070003,\n",
       " 'choice': 0.016575135538070003,\n",
       " 'remind': 0.016575135538070003,\n",
       " 'cam': 0.016575135538070003,\n",
       " 'dim': 0.016575135538070003,\n",
       " 'bring': 0.016575135538070003,\n",
       " 'wi-fi': 0.016575135538070003,\n",
       " 'anyone': 0.016575135538070003,\n",
       " 'direction': 0.016575135538070003,\n",
       " 'homework': 0.014420286722902796,\n",
       " 'set-up': 0.014420286722902796,\n",
       " 'shipping': 0.014420286722902796,\n",
       " 'location': 0.014420286722902796,\n",
       " 'surprisingly': 0.014420286722902796,\n",
       " 'trailer': 0.014401530247627409,\n",
       " 'member': 0.014098334172680738,\n",
       " 'podcasts': 0.014098334172680738,\n",
       " 'unlimited': 0.014098334172680738,\n",
       " 'phone_call': 0.014098334172680738,\n",
       " 'beginning': 0.014098334172680738,\n",
       " 'particular': 0.014098334172680738,\n",
       " 'throughout': 0.014098334172680738,\n",
       " 'last': 0.014098334172680738,\n",
       " 'answer_question': 0.014098334172680738,\n",
       " 'see_lyric': 0.014098334172680738,\n",
       " 'mine': 0.014098334172680738,\n",
       " 'require': 0.014098334172680738,\n",
       " 'anymore': 0.011881781488251072,\n",
       " 'forward': 0.011881781488251072,\n",
       " 'dead': 0.011881781488251072,\n",
       " 'awhile': 0.011881781488251072,\n",
       " 'important': 0.011881781488251072,\n",
       " 'general': 0.011881781488251072,\n",
       " 'clean': 0.011881781488251072,\n",
       " 'benefit': 0.0115644572840155,\n",
       " 'test': 0.0115644572840155,\n",
       " 'local': 0.0115644572840155,\n",
       " 'integrate': 0.0115644572840155,\n",
       " 'bought': 0.0115644572840155,\n",
       " 'side': 0.0115644572840155,\n",
       " 'personally': 0.0115644572840155,\n",
       " 'compatible': 0.0115644572840155,\n",
       " 'imagine': 0.0115644572840155,\n",
       " 'person': 0.0115644572840155,\n",
       " 'navigate': 0.0115644572840155,\n",
       " 'idea': 0.0115644572840155,\n",
       " 'directly': 0.0115644572840155,\n",
       " 'lag': 0.0115644572840155,\n",
       " 'knowledge': 0.008962487208516662,\n",
       " 'charge': 0.008962487208516662,\n",
       " 'delivery': 0.008962487208516662,\n",
       " 'fairly': 0.008962487208516662,\n",
       " 'flawlessly': 0.008962487208516662,\n",
       " 'appear': 0.008962487208516662,\n",
       " 'eye': 0.008962487208516662,\n",
       " 'intend': 0.008962487208516662,\n",
       " 'date': 0.008962487208516662,\n",
       " 'possible': 0.008962487208516662,\n",
       " 'state': 0.008962487208516662,\n",
       " 'rid': 0.008962487208516662,\n",
       " 'accent': 0.008962487208516662,\n",
       " 'complain': 0.008962487208516662,\n",
       " 'streaming': 0.008962487208516662,\n",
       " 'current': 0.008962487208516662,\n",
       " 'task': 0.008962487208516662,\n",
       " 'area': 0.008962487208516662,\n",
       " 'child': 0.008962487208516662,\n",
       " 'direct': 0.008962487208516662,\n",
       " 'shut': 0.008962487208516662,\n",
       " 'slightly': 0.008962487208516662}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questa parte estrare le parole piÃ¹ rilevanti per ogni categoria, ma non la uso alla fine.\n",
    "# Lo riprenderÃ² piÃ¹ avanti\n",
    "\n",
    "neg_tokenized = [rev for rev, feedback in zip(cleaned_reviews, dataset[\"feedback\"]) if feedback == 0]\n",
    "pos_tokenized = [rev for rev, feedback in zip(cleaned_reviews, dataset[\"feedback\"]) if feedback == 1]\n",
    "neg_tokenized = [w for rev in neg_tokenized for w in rev]\n",
    "pos_tokenized = [w for rev in pos_tokenized for w in rev]\n",
    "\n",
    "import math \n",
    "\n",
    "def get_pos_neg_score(pos, neg, threshold = 0.30):\n",
    "    total_tokens = pos + neg\n",
    "    total_tokens_freq = nltk.FreqDist(total_tokens)\n",
    "    pos_freq = nltk.FreqDist(pos)\n",
    "    neg_freq = nltk.FreqDist(neg)\n",
    "    data_dict = {\"pos\": {}, \"neg\": {}}\n",
    "\n",
    "    for w in pos:\n",
    "        p = total_tokens_freq[w] / len(total_tokens)\n",
    "        p_category = pos_freq[w] / total_tokens_freq[w]\n",
    "        h = -math.log2(p)\n",
    "        score = p_category * h * p\n",
    "        data_dict[\"pos\"][w] = score\n",
    "    \n",
    "    for w in neg:\n",
    "        p = total_tokens_freq[w] / len(total_tokens)\n",
    "        p_category = neg_freq[w] / total_tokens_freq[w]\n",
    "        h = -math.log2(p)\n",
    "        score = p_category * h * p\n",
    "        data_dict[\"neg\"][w] = score\n",
    "\n",
    "    risultato = {}\n",
    "\n",
    "    for label in [\"pos\", \"neg\"]:\n",
    "        values_list = list(data_dict[label].values())\n",
    "        min_values = min(values_list)\n",
    "        max_values = max(values_list)\n",
    "        for k in data_dict[label]:\n",
    "            val = data_dict[label][k]\n",
    "            data_dict[label][k] = (val- min_values)/(max_values-min_values)\n",
    "\n",
    "    for w in total_tokens:\n",
    "\n",
    "        try:\n",
    "            pos_score = data_dict[\"pos\"][w]\n",
    "        except KeyError:\n",
    "            # risultato[w] = 1\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            neg_score = data_dict[\"neg\"][w]\n",
    "        except KeyError:\n",
    "            # risultato[w] = 1\n",
    "            pass\n",
    "\n",
    "\n",
    "        risultato[w] = max([pos_score, neg_score])\n",
    "\n",
    "    # return data_dict\n",
    "    return {k: v for k, v in sorted(risultato.items(), key = lambda item: item[1], reverse=True)}\n",
    "    \n",
    "data_dict = get_pos_neg_score(pos_tokenized, neg_tokenized, threshold=0)\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(cleaned_reviews, vector_size=300, window = 5, min_count = 0, sg=1, hs = 1, alpha=0.03, min_alpha=0.0007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1663348, 2193800)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(cleaned_reviews, total_examples=len(cleaned_reviews), epochs=100, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('work', 0.2645948827266693),\n",
       " ('satisfied', 0.19260777533054352),\n",
       " ('love', 0.18071243166923523),\n",
       " ('charm', 0.18004941940307617),\n",
       " ('flawlessly', 0.1788301318883896),\n",
       " ('many_thing', 0.17521290481090546),\n",
       " ('course', 0.17247360944747925),\n",
       " ('shipping', 0.16908293962478638),\n",
       " ('excellent', 0.1676042377948761),\n",
       " ('kitchen', 0.16568666696548462)]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(\"great\", topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('package', -0.033238790929317474),\n",
       " ('suppose', -0.03372375667095184),\n",
       " ('people', -0.03378671035170555),\n",
       " ('never', -0.03396548703312874),\n",
       " ('sonos', -0.0390961617231369),\n",
       " ('annoy', -0.0394415408372879),\n",
       " ('close', -0.04699898511171341),\n",
       " ('default', -0.050131235271692276),\n",
       " ('expensive', -0.06306134909391403),\n",
       " ('app', -0.06488937884569168)]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(\"love\", topn = 2000)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benefit 0.32633520817571116\n",
      "come 0.23328841732724445\n",
      "couple 0.29703902023569817\n",
      "day 0.18880233480487343\n",
      "different 0.2607284750446854\n",
      "household 0.3008270617286897\n",
      "learn 0.222350996368215\n",
      "like 0.1463344158156626\n",
      "lot_fun 0.2902667364243624\n",
      "member 0.3200158010669249\n",
      "new 0.3761371904696644\n",
      "toy 0.3094554757625976\n",
      "try 0.21104537606605894\n",
      "use 0.13200924198830968\n"
     ]
    }
   ],
   "source": [
    "# tfidf weighting sui token, per ora senza pos. Mi sono reso conto che la pos per averla piÃ¹ accurata la devo fare prima del pre processing.\n",
    " \n",
    "tfidf = TfidfVectorizer(tokenizer=lambda i:i, lowercase=False, min_df = 0)\n",
    "tfidf_model = tfidf.fit_transform(cleaned_reviews)\n",
    "review = 15\n",
    "for score, feature in zip(tfidf_model.toarray()[review], tfidf.get_feature_names_out()):\n",
    "    if score > 0.0:\n",
    "        print(feature, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'ll</th>\n",
       "      <th>'re</th>\n",
       "      <th>'ve</th>\n",
       "      <th>....</th>\n",
       "      <th>.....</th>\n",
       "      <th>......</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absolutely_love</th>\n",
       "      <th>...</th>\n",
       "      <th>worth_every</th>\n",
       "      <th>would</th>\n",
       "      <th>would_recommend</th>\n",
       "      <th>wrong</th>\n",
       "      <th>yard</th>\n",
       "      <th>year</th>\n",
       "      <th>year_old</th>\n",
       "      <th>yell</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2543 rows Ã 829 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      'll       're  've      ....  .....  ......  ability  able  absolutely  \\\n",
       "0     0.0  0.000000  0.0  0.000000    0.0     0.0      0.0   0.0         0.0   \n",
       "1     0.0  0.000000  0.0  0.000000    0.0     0.0      0.0   0.0         0.0   \n",
       "2     0.0  0.000000  0.0  0.000000    0.0     0.0      0.0   0.0         0.0   \n",
       "3     0.0  0.000000  0.0  0.000000    0.0     0.0      0.0   0.0         0.0   \n",
       "4     0.0  0.000000  0.0  0.000000    0.0     0.0      0.0   0.0         0.0   \n",
       "...   ...       ...  ...       ...    ...     ...      ...   ...         ...   \n",
       "2538  0.0  0.000000  0.0  0.000000    0.0     0.0      0.0   0.0         0.0   \n",
       "2539  0.0  0.000000  0.0  0.000000    0.0     0.0      0.0   0.0         0.0   \n",
       "2540  0.0  0.000000  0.0  0.000000    0.0     0.0      0.0   0.0         0.0   \n",
       "2541  0.0  0.000000  0.0  0.154716    0.0     0.0      0.0   0.0         0.0   \n",
       "2542  0.0  0.205564  0.0  0.000000    0.0     0.0      0.0   0.0         0.0   \n",
       "\n",
       "      absolutely_love  ...  worth_every  would  would_recommend  wrong  yard  \\\n",
       "0                 0.0  ...          0.0    0.0              0.0    0.0   0.0   \n",
       "1                 0.0  ...          0.0    0.0              0.0    0.0   0.0   \n",
       "2                 0.0  ...          0.0    0.0              0.0    0.0   0.0   \n",
       "3                 0.0  ...          0.0    0.0              0.0    0.0   0.0   \n",
       "4                 0.0  ...          0.0    0.0              0.0    0.0   0.0   \n",
       "...               ...  ...          ...    ...              ...    ...   ...   \n",
       "2538              0.0  ...          0.0    0.0              0.0    0.0   0.0   \n",
       "2539              0.0  ...          0.0    0.0              0.0    0.0   0.0   \n",
       "2540              0.0  ...          0.0    0.0              0.0    0.0   0.0   \n",
       "2541              0.0  ...          0.0    0.0              0.0    0.0   0.0   \n",
       "2542              0.0  ...          0.0    0.0              0.0    0.0   0.0   \n",
       "\n",
       "      year  year_old  yell  yes  yet  \n",
       "0      0.0       0.0   0.0  0.0  0.0  \n",
       "1      0.0       0.0   0.0  0.0  0.0  \n",
       "2      0.0       0.0   0.0  0.0  0.0  \n",
       "3      0.0       0.0   0.0  0.0  0.0  \n",
       "4      0.0       0.0   0.0  0.0  0.0  \n",
       "...    ...       ...   ...  ...  ...  \n",
       "2538   0.0       0.0   0.0  0.0  0.0  \n",
       "2539   0.0       0.0   0.0  0.0  0.0  \n",
       "2540   0.0       0.0   0.0  0.0  0.0  \n",
       "2541   0.0       0.0   0.0  0.0  0.0  \n",
       "2542   0.0       0.0   0.0  0.0  0.0  \n",
       "\n",
       "[2543 rows x 829 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tfidf_model.toarray(), columns = tfidf.get_feature_names_out())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model = []\n",
    "# google_model = api.load('word2vec-google-news-300', True)\n",
    "# g_model = KeyedVectors.load_word2vec_format(google_model, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_vectors(tokens, size, weights, pretrained = False):\n",
    "\n",
    "    \"\"\"Genera un vettore per ogni recensione: questo vettore\n",
    "    Ã¨ calcolato come la media ponderata (t * w: token vettore * perso tfidf) dei vettori dei token nella recensione.\n",
    "    Il vettore risultante Ã¨ normalizzato alla fine.\"\"\"\n",
    "\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    if len(tokens) != len(weights):\n",
    "        print(\"nope\")\n",
    "    for word, weight in zip(tokens, weights):\n",
    "        word = word.split(\"$\")[0]\n",
    "        try:\n",
    "            if pretrained:\n",
    "                vec += g_model[word] * weight\n",
    "            else:\n",
    "                vec += w2v_model.wv[word] * weight\n",
    "            count +=1\n",
    "        except KeyError:\n",
    "            print(\"non trovo\", word)\n",
    "            continue\n",
    "\n",
    "    if count!= 0:\n",
    "        vec = vec / norm(vec)\n",
    "        \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018835</td>\n",
       "      <td>0.114063</td>\n",
       "      <td>-0.005872</td>\n",
       "      <td>-0.037132</td>\n",
       "      <td>-0.019159</td>\n",
       "      <td>-0.106562</td>\n",
       "      <td>-0.032998</td>\n",
       "      <td>0.036485</td>\n",
       "      <td>0.011260</td>\n",
       "      <td>-0.024760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052651</td>\n",
       "      <td>-0.010966</td>\n",
       "      <td>0.016686</td>\n",
       "      <td>-0.031776</td>\n",
       "      <td>0.020766</td>\n",
       "      <td>-0.008479</td>\n",
       "      <td>-0.043000</td>\n",
       "      <td>0.084970</td>\n",
       "      <td>-0.016822</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018835</td>\n",
       "      <td>0.114063</td>\n",
       "      <td>-0.005872</td>\n",
       "      <td>-0.037132</td>\n",
       "      <td>-0.019159</td>\n",
       "      <td>-0.106562</td>\n",
       "      <td>-0.032998</td>\n",
       "      <td>0.036485</td>\n",
       "      <td>0.011260</td>\n",
       "      <td>-0.024760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052651</td>\n",
       "      <td>-0.010966</td>\n",
       "      <td>0.016686</td>\n",
       "      <td>-0.031776</td>\n",
       "      <td>0.020766</td>\n",
       "      <td>-0.008479</td>\n",
       "      <td>-0.043000</td>\n",
       "      <td>0.084970</td>\n",
       "      <td>-0.016822</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.054088</td>\n",
       "      <td>0.054925</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.037074</td>\n",
       "      <td>-0.012668</td>\n",
       "      <td>-0.027078</td>\n",
       "      <td>0.103468</td>\n",
       "      <td>0.133006</td>\n",
       "      <td>0.012010</td>\n",
       "      <td>-0.037656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081107</td>\n",
       "      <td>0.027491</td>\n",
       "      <td>0.026664</td>\n",
       "      <td>-0.054770</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.044232</td>\n",
       "      <td>-0.086418</td>\n",
       "      <td>-0.032396</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.046461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.031830</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>-0.031511</td>\n",
       "      <td>0.035185</td>\n",
       "      <td>0.090978</td>\n",
       "      <td>-0.045289</td>\n",
       "      <td>0.094294</td>\n",
       "      <td>0.039568</td>\n",
       "      <td>-0.043606</td>\n",
       "      <td>0.078406</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046349</td>\n",
       "      <td>-0.012908</td>\n",
       "      <td>0.019170</td>\n",
       "      <td>0.062864</td>\n",
       "      <td>0.028851</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.039124</td>\n",
       "      <td>0.033055</td>\n",
       "      <td>0.046597</td>\n",
       "      <td>-0.088817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001675</td>\n",
       "      <td>-0.025436</td>\n",
       "      <td>-0.033233</td>\n",
       "      <td>-0.007951</td>\n",
       "      <td>-0.019409</td>\n",
       "      <td>-0.016291</td>\n",
       "      <td>0.054255</td>\n",
       "      <td>0.116747</td>\n",
       "      <td>-0.022510</td>\n",
       "      <td>-0.128829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009673</td>\n",
       "      <td>-0.021017</td>\n",
       "      <td>0.044019</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>0.103746</td>\n",
       "      <td>0.050996</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>-0.023255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>0.018835</td>\n",
       "      <td>0.114063</td>\n",
       "      <td>-0.005872</td>\n",
       "      <td>-0.037132</td>\n",
       "      <td>-0.019159</td>\n",
       "      <td>-0.106562</td>\n",
       "      <td>-0.032998</td>\n",
       "      <td>0.036485</td>\n",
       "      <td>0.011260</td>\n",
       "      <td>-0.024760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052651</td>\n",
       "      <td>-0.010966</td>\n",
       "      <td>0.016686</td>\n",
       "      <td>-0.031776</td>\n",
       "      <td>0.020766</td>\n",
       "      <td>-0.008479</td>\n",
       "      <td>-0.043000</td>\n",
       "      <td>0.084970</td>\n",
       "      <td>-0.016822</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>-0.029426</td>\n",
       "      <td>0.048604</td>\n",
       "      <td>-0.028471</td>\n",
       "      <td>0.100392</td>\n",
       "      <td>0.019874</td>\n",
       "      <td>-0.104132</td>\n",
       "      <td>0.148054</td>\n",
       "      <td>0.107587</td>\n",
       "      <td>-0.082930</td>\n",
       "      <td>-0.008598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008962</td>\n",
       "      <td>-0.023171</td>\n",
       "      <td>-0.007217</td>\n",
       "      <td>-0.060348</td>\n",
       "      <td>-0.042541</td>\n",
       "      <td>0.039134</td>\n",
       "      <td>0.023135</td>\n",
       "      <td>-0.069694</td>\n",
       "      <td>0.092551</td>\n",
       "      <td>0.028465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>0.044208</td>\n",
       "      <td>0.071327</td>\n",
       "      <td>0.082717</td>\n",
       "      <td>0.037706</td>\n",
       "      <td>-0.015875</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>0.068997</td>\n",
       "      <td>0.115959</td>\n",
       "      <td>0.009944</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029193</td>\n",
       "      <td>0.071147</td>\n",
       "      <td>0.057531</td>\n",
       "      <td>-0.092072</td>\n",
       "      <td>0.021728</td>\n",
       "      <td>0.055076</td>\n",
       "      <td>0.046241</td>\n",
       "      <td>-0.039149</td>\n",
       "      <td>-0.029371</td>\n",
       "      <td>0.028971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>-0.009945</td>\n",
       "      <td>0.131182</td>\n",
       "      <td>-0.037812</td>\n",
       "      <td>-0.013819</td>\n",
       "      <td>-0.007487</td>\n",
       "      <td>-0.093861</td>\n",
       "      <td>0.048825</td>\n",
       "      <td>0.173389</td>\n",
       "      <td>0.027627</td>\n",
       "      <td>-0.065191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030953</td>\n",
       "      <td>0.030750</td>\n",
       "      <td>0.051448</td>\n",
       "      <td>-0.004972</td>\n",
       "      <td>0.036655</td>\n",
       "      <td>0.138683</td>\n",
       "      <td>-0.024324</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.082460</td>\n",
       "      <td>-0.050042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>0.035481</td>\n",
       "      <td>0.081790</td>\n",
       "      <td>-0.060574</td>\n",
       "      <td>0.022071</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>-0.082071</td>\n",
       "      <td>0.030271</td>\n",
       "      <td>0.107210</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>-0.036939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.031306</td>\n",
       "      <td>0.100466</td>\n",
       "      <td>-0.040234</td>\n",
       "      <td>0.106779</td>\n",
       "      <td>-0.052770</td>\n",
       "      <td>-0.044618</td>\n",
       "      <td>-0.029136</td>\n",
       "      <td>0.064771</td>\n",
       "      <td>-0.059521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2543 rows Ã 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.018835  0.114063 -0.005872 -0.037132 -0.019159 -0.106562 -0.032998   \n",
       "1     0.018835  0.114063 -0.005872 -0.037132 -0.019159 -0.106562 -0.032998   \n",
       "2     0.054088  0.054925  0.004768  0.037074 -0.012668 -0.027078  0.103468   \n",
       "3    -0.031830  0.004683 -0.031511  0.035185  0.090978 -0.045289  0.094294   \n",
       "4     0.001675 -0.025436 -0.033233 -0.007951 -0.019409 -0.016291  0.054255   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2538  0.018835  0.114063 -0.005872 -0.037132 -0.019159 -0.106562 -0.032998   \n",
       "2539 -0.029426  0.048604 -0.028471  0.100392  0.019874 -0.104132  0.148054   \n",
       "2540  0.044208  0.071327  0.082717  0.037706 -0.015875  0.004365  0.068997   \n",
       "2541 -0.009945  0.131182 -0.037812 -0.013819 -0.007487 -0.093861  0.048825   \n",
       "2542  0.035481  0.081790 -0.060574  0.022071  0.026822 -0.082071  0.030271   \n",
       "\n",
       "           7         8         9    ...       290       291       292  \\\n",
       "0     0.036485  0.011260 -0.024760  ...  0.052651 -0.010966  0.016686   \n",
       "1     0.036485  0.011260 -0.024760  ...  0.052651 -0.010966  0.016686   \n",
       "2     0.133006  0.012010 -0.037656  ... -0.081107  0.027491  0.026664   \n",
       "3     0.039568 -0.043606  0.078406  ... -0.046349 -0.012908  0.019170   \n",
       "4     0.116747 -0.022510 -0.128829  ... -0.009673 -0.021017  0.044019   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2538  0.036485  0.011260 -0.024760  ...  0.052651 -0.010966  0.016686   \n",
       "2539  0.107587 -0.082930 -0.008598  ... -0.008962 -0.023171 -0.007217   \n",
       "2540  0.115959  0.009944  0.000178  ... -0.029193  0.071147  0.057531   \n",
       "2541  0.173389  0.027627 -0.065191  ... -0.030953  0.030750  0.051448   \n",
       "2542  0.107210  0.034507 -0.036939  ...  0.004695  0.031306  0.100466   \n",
       "\n",
       "           293       294       295       296       297       298       299  \n",
       "0    -0.031776  0.020766 -0.008479 -0.043000  0.084970 -0.016822  0.053334  \n",
       "1    -0.031776  0.020766 -0.008479 -0.043000  0.084970 -0.016822  0.053334  \n",
       "2    -0.054770  0.000420  0.044232 -0.086418 -0.032396 -0.003430 -0.046461  \n",
       "3     0.062864  0.028851  0.003115  0.039124  0.033055  0.046597 -0.088817  \n",
       "4     0.003073  0.103746  0.050996  0.001409  0.017452  0.003311 -0.023255  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2538 -0.031776  0.020766 -0.008479 -0.043000  0.084970 -0.016822  0.053334  \n",
       "2539 -0.060348 -0.042541  0.039134  0.023135 -0.069694  0.092551  0.028465  \n",
       "2540 -0.092072  0.021728  0.055076  0.046241 -0.039149 -0.029371  0.028971  \n",
       "2541 -0.004972  0.036655  0.138683 -0.024324  0.002024  0.082460 -0.050042  \n",
       "2542 -0.040234  0.106779 -0.052770 -0.044618 -0.029136  0.064771 -0.059521  \n",
       "\n",
       "[2543 rows x 300 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qui viene creato per ogni recensione il vettore\n",
    "\n",
    "w2v_reviews = np.zeros((len(cleaned_reviews), 300))\n",
    "for i in range(len(cleaned_reviews)):\n",
    "    w2v_reviews[i,:] = review_vectors(tfidf.inverse_transform(tfidf_model[i, :])[0], 300, tfidf_model[i,:].data, False)\n",
    "w2v_df = pd.DataFrame(w2v_reviews)\n",
    "w2v_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(w2v_reviews, dataset[\"feedback\"].values, test_size=0.20, random_state=10)\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.57      0.62        44\n",
      "           1       0.96      0.97      0.97       465\n",
      "\n",
      "    accuracy                           0.94       509\n",
      "   macro avg       0.82      0.77      0.79       509\n",
      "weighted avg       0.94      0.94      0.94       509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(max_iter=3000)\n",
    "svm_model = svm.fit(X_train, Y_train)\n",
    "predictions = svm_model.predict(X_test)\n",
    "print(metrics.classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# risultati migliori:\n",
    "\n",
    "# w2v + tf-idf weights considering pos (good$JJ) disambiguation also! + svm and word count > 4\n",
    "\n",
    "# w2v configuration:\n",
    "# w2v_model = Word2Vec(cleaned_reviews, vector_size=300, window = 5, min_count = 0, sg=1, hs = 1, alpha=0.03, min_alpha=0.0007) and 100 epochs for training\n",
    "\n",
    "# otherwise the balanced dataset performs better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001],\n",
    "              'kernel': ['rbf','linear', 'poly'],\n",
    "              'class_weight':['balanced', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.862 total time=   0.5s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.882 total time=   0.3s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.857 total time=   0.5s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.907 total time=   0.3s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.879 total time=   0.4s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=1, kernel=linear;, score=0.855 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=1, kernel=linear;, score=0.860 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=1, kernel=linear;, score=0.826 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=1, kernel=linear;, score=0.865 total time=   0.3s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=1, kernel=linear;, score=0.889 total time=   0.2s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=1, kernel=poly;, score=0.919 total time=   0.5s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=1, kernel=poly;, score=0.934 total time=   0.5s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=1, kernel=poly;, score=0.916 total time=   0.7s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=1, kernel=poly;, score=0.929 total time=   0.6s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=1, kernel=poly;, score=0.933 total time=   0.5s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.686 total time=   0.9s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.678 total time=   0.9s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.644 total time=   0.9s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.693 total time=   0.9s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.727 total time=   0.9s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.855 total time=   0.3s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.860 total time=   0.4s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.826 total time=   0.3s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.865 total time=   0.4s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.889 total time=   0.3s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.897 total time=   0.6s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.106 total time=   0.6s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.106 total time=   0.6s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.106 total time=   0.6s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.897 total time=   0.6s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.897 total time=   0.9s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.106 total time=   0.8s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.106 total time=   0.8s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.106 total time=   0.9s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.897 total time=   0.9s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.855 total time=   0.4s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.860 total time=   0.3s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.826 total time=   0.4s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.865 total time=   0.4s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.889 total time=   0.3s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.897 total time=   0.6s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.106 total time=   0.6s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.106 total time=   0.5s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.106 total time=   0.6s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.897 total time=   0.6s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.897 total time=   0.9s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.106 total time=   0.9s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.106 total time=   0.9s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.106 total time=   0.9s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.897 total time=   0.9s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.855 total time=   0.3s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.860 total time=   0.3s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.826 total time=   0.4s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.865 total time=   0.3s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.889 total time=   0.4s\n",
      "[CV 1/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.897 total time=   0.6s\n",
      "[CV 2/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.106 total time=   0.6s\n",
      "[CV 3/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.106 total time=   0.6s\n",
      "[CV 4/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.106 total time=   0.6s\n",
      "[CV 5/5] END C=0.1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.897 total time=   0.6s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=1, kernel=rbf;, score=0.897 total time=   0.2s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=1, kernel=rbf;, score=0.894 total time=   0.3s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=1, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=1, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=1, kernel=rbf;, score=0.897 total time=   0.3s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=1, kernel=linear;, score=0.897 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=1, kernel=linear;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=1, kernel=linear;, score=0.894 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=1, kernel=linear;, score=0.894 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=1, kernel=linear;, score=0.897 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=1, kernel=poly;, score=0.897 total time=   0.2s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=1, kernel=poly;, score=0.894 total time=   0.2s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=1, kernel=poly;, score=0.894 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=1, kernel=poly;, score=0.894 total time=   0.4s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=1, kernel=poly;, score=0.897 total time=   0.2s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.897 total time=   0.2s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.894 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.897 total time=   0.2s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.1, kernel=linear;, score=0.897 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.1, kernel=linear;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.1, kernel=linear;, score=0.894 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.1, kernel=linear;, score=0.894 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.1, kernel=linear;, score=0.897 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.1, kernel=poly;, score=0.897 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.1, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.1, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.1, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.1, kernel=poly;, score=0.897 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.897 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.894 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.894 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.897 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.01, kernel=linear;, score=0.897 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.01, kernel=linear;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.01, kernel=linear;, score=0.894 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.01, kernel=linear;, score=0.894 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.01, kernel=linear;, score=0.897 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.01, kernel=poly;, score=0.897 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.01, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.01, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.01, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.01, kernel=poly;, score=0.897 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.897 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.894 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.894 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.897 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.001, kernel=linear;, score=0.897 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.001, kernel=linear;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.001, kernel=linear;, score=0.894 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.001, kernel=linear;, score=0.894 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.001, kernel=linear;, score=0.897 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, class_weight=None, gamma=0.001, kernel=poly;, score=0.897 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, class_weight=None, gamma=0.001, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, class_weight=None, gamma=0.001, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, class_weight=None, gamma=0.001, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, class_weight=None, gamma=0.001, kernel=poly;, score=0.897 total time=   0.0s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.919 total time=   0.3s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.929 total time=   0.3s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.897 total time=   0.3s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.948 total time=   0.3s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=1, kernel=rbf;, score=0.933 total time=   0.3s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=1, kernel=linear;, score=0.870 total time=   0.2s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=1, kernel=linear;, score=0.862 total time=   0.2s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=1, kernel=linear;, score=0.838 total time=   0.2s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=1, kernel=linear;, score=0.889 total time=   0.2s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=1, kernel=linear;, score=0.874 total time=   0.2s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=1, kernel=poly;, score=0.926 total time=   0.3s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=1, kernel=poly;, score=0.948 total time=   0.3s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=1, kernel=poly;, score=0.946 total time=   0.3s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=1, kernel=poly;, score=0.958 total time=   0.3s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=1, kernel=poly;, score=0.958 total time=   0.2s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.860 total time=   0.5s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.857 total time=   0.5s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.889 total time=   0.5s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.867 total time=   0.5s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.870 total time=   0.2s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.862 total time=   0.2s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.838 total time=   0.2s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.889 total time=   0.2s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.874 total time=   0.2s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.103 total time=   0.6s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.106 total time=   0.6s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.106 total time=   0.6s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.106 total time=   0.6s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.103 total time=   0.6s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.725 total time=   0.9s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.717 total time=   0.9s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.688 total time=   0.8s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.737 total time=   0.8s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.766 total time=   0.8s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.870 total time=   0.2s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.862 total time=   0.2s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.838 total time=   0.2s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.889 total time=   0.2s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.874 total time=   0.2s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.103 total time=   0.5s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.106 total time=   0.6s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.106 total time=   0.6s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.106 total time=   0.5s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.103 total time=   0.6s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.103 total time=   0.9s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.106 total time=   0.9s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.106 total time=   0.9s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.106 total time=   0.9s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.103 total time=   0.9s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.870 total time=   0.2s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.862 total time=   0.2s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.838 total time=   0.2s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.889 total time=   0.2s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.874 total time=   0.2s\n",
      "[CV 1/5] END C=1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.103 total time=   0.6s\n",
      "[CV 2/5] END C=1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.106 total time=   0.6s\n",
      "[CV 3/5] END C=1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.106 total time=   0.6s\n",
      "[CV 4/5] END C=1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.106 total time=   0.6s\n",
      "[CV 5/5] END C=1, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.103 total time=   0.6s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=1, kernel=rbf;, score=0.921 total time=   0.2s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=1, kernel=rbf;, score=0.939 total time=   0.2s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=1, kernel=rbf;, score=0.936 total time=   0.2s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=1, kernel=rbf;, score=0.943 total time=   0.2s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=1, kernel=rbf;, score=0.931 total time=   0.2s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=1, kernel=linear;, score=0.919 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=1, kernel=linear;, score=0.929 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=1, kernel=linear;, score=0.936 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=1, kernel=linear;, score=0.936 total time=   0.1s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=1, kernel=linear;, score=0.924 total time=   0.1s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=1, kernel=poly;, score=0.926 total time=   0.2s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=1, kernel=poly;, score=0.936 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=1, kernel=poly;, score=0.941 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=1, kernel=poly;, score=0.941 total time=   0.1s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=1, kernel=poly;, score=0.941 total time=   0.2s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.897 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.894 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.1, kernel=rbf;, score=0.897 total time=   0.1s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.1, kernel=linear;, score=0.919 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.1, kernel=linear;, score=0.929 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.1, kernel=linear;, score=0.936 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.1, kernel=linear;, score=0.936 total time=   0.1s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.1, kernel=linear;, score=0.924 total time=   0.1s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.1, kernel=poly;, score=0.897 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.1, kernel=poly;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.1, kernel=poly;, score=0.894 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.1, kernel=poly;, score=0.894 total time=   0.1s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.1, kernel=poly;, score=0.897 total time=   0.1s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.897 total time=   0.2s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.01, kernel=rbf;, score=0.897 total time=   0.2s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.01, kernel=linear;, score=0.919 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.01, kernel=linear;, score=0.929 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.01, kernel=linear;, score=0.936 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.01, kernel=linear;, score=0.936 total time=   0.1s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.01, kernel=linear;, score=0.924 total time=   0.1s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.01, kernel=poly;, score=0.897 total time=   0.0s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.01, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.01, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.01, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.01, kernel=poly;, score=0.897 total time=   0.0s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.897 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.894 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.001, kernel=rbf;, score=0.897 total time=   0.1s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.001, kernel=linear;, score=0.919 total time=   0.1s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.001, kernel=linear;, score=0.929 total time=   0.1s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.001, kernel=linear;, score=0.936 total time=   0.1s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.001, kernel=linear;, score=0.936 total time=   0.1s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.001, kernel=linear;, score=0.924 total time=   0.1s\n",
      "[CV 1/5] END C=1, class_weight=None, gamma=0.001, kernel=poly;, score=0.897 total time=   0.0s\n",
      "[CV 2/5] END C=1, class_weight=None, gamma=0.001, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 3/5] END C=1, class_weight=None, gamma=0.001, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END C=1, class_weight=None, gamma=0.001, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 5/5] END C=1, class_weight=None, gamma=0.001, kernel=poly;, score=0.897 total time=   0.0s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=1, kernel=rbf;, score=0.926 total time=   0.2s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=1, kernel=rbf;, score=0.929 total time=   0.3s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=1, kernel=rbf;, score=0.907 total time=   0.2s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=1, kernel=rbf;, score=0.951 total time=   0.2s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=1, kernel=rbf;, score=0.933 total time=   0.3s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=1, kernel=linear;, score=0.907 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=1, kernel=linear;, score=0.892 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=1, kernel=linear;, score=0.877 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=1, kernel=linear;, score=0.924 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=1, kernel=linear;, score=0.899 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=1, kernel=poly;, score=0.889 total time=   0.4s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=1, kernel=poly;, score=0.904 total time=   0.3s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=1, kernel=poly;, score=0.877 total time=   0.4s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=1, kernel=poly;, score=0.941 total time=   0.4s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=1, kernel=poly;, score=0.926 total time=   0.3s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.865 total time=   0.2s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.916 total time=   0.2s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.892 total time=   0.2s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.907 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.892 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.877 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.924 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.899 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.897 total time=   0.6s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.894 total time=   0.6s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.894 total time=   0.6s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.894 total time=   0.6s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.103 total time=   0.5s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.862 total time=   0.5s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.838 total time=   0.5s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.885 total time=   0.5s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.865 total time=   0.4s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.907 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.892 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.877 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.924 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.899 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.897 total time=   0.6s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.894 total time=   0.5s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.894 total time=   0.6s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.894 total time=   0.6s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.103 total time=   0.5s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.727 total time=   0.8s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.732 total time=   0.8s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.693 total time=   0.8s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.744 total time=   0.8s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.771 total time=   0.8s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.907 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.892 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.877 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.924 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.899 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.897 total time=   0.6s\n",
      "[CV 2/5] END C=10, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.894 total time=   0.6s\n",
      "[CV 3/5] END C=10, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.894 total time=   0.6s\n",
      "[CV 4/5] END C=10, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.894 total time=   0.5s\n",
      "[CV 5/5] END C=10, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.103 total time=   0.5s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=1, kernel=rbf;, score=0.931 total time=   0.2s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=1, kernel=rbf;, score=0.941 total time=   0.2s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=1, kernel=rbf;, score=0.939 total time=   0.2s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=1, kernel=rbf;, score=0.958 total time=   0.2s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=1, kernel=rbf;, score=0.951 total time=   0.2s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=1, kernel=linear;, score=0.909 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=1, kernel=linear;, score=0.916 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=1, kernel=linear;, score=0.929 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=1, kernel=linear;, score=0.931 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=1, kernel=linear;, score=0.924 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=1, kernel=poly;, score=0.931 total time=   0.2s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=1, kernel=poly;, score=0.941 total time=   0.2s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=1, kernel=poly;, score=0.946 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=1, kernel=poly;, score=0.951 total time=   0.2s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=1, kernel=poly;, score=0.953 total time=   0.2s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.1, kernel=rbf;, score=0.916 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.1, kernel=rbf;, score=0.934 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.1, kernel=rbf;, score=0.934 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.1, kernel=rbf;, score=0.953 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.1, kernel=rbf;, score=0.926 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.1, kernel=linear;, score=0.909 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.1, kernel=linear;, score=0.916 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.1, kernel=linear;, score=0.929 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.1, kernel=linear;, score=0.931 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.1, kernel=linear;, score=0.924 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.1, kernel=poly;, score=0.897 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.1, kernel=poly;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.1, kernel=poly;, score=0.894 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.1, kernel=poly;, score=0.894 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.1, kernel=poly;, score=0.897 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.01, kernel=rbf;, score=0.897 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.01, kernel=rbf;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.01, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.01, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.01, kernel=rbf;, score=0.897 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.01, kernel=linear;, score=0.909 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.01, kernel=linear;, score=0.916 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.01, kernel=linear;, score=0.929 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.01, kernel=linear;, score=0.931 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.01, kernel=linear;, score=0.924 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.01, kernel=poly;, score=0.897 total time=   0.0s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.01, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.01, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.01, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.01, kernel=poly;, score=0.897 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.001, kernel=rbf;, score=0.897 total time=   0.2s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.001, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.001, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.001, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.001, kernel=rbf;, score=0.897 total time=   0.2s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.001, kernel=linear;, score=0.909 total time=   0.1s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.001, kernel=linear;, score=0.916 total time=   0.1s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.001, kernel=linear;, score=0.929 total time=   0.1s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.001, kernel=linear;, score=0.931 total time=   0.1s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.001, kernel=linear;, score=0.924 total time=   0.1s\n",
      "[CV 1/5] END C=10, class_weight=None, gamma=0.001, kernel=poly;, score=0.897 total time=   0.0s\n",
      "[CV 2/5] END C=10, class_weight=None, gamma=0.001, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 3/5] END C=10, class_weight=None, gamma=0.001, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END C=10, class_weight=None, gamma=0.001, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 5/5] END C=10, class_weight=None, gamma=0.001, kernel=poly;, score=0.897 total time=   0.0s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=1, kernel=rbf;, score=0.926 total time=   0.2s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=1, kernel=rbf;, score=0.929 total time=   0.2s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=1, kernel=rbf;, score=0.907 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=1, kernel=rbf;, score=0.951 total time=   0.3s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=1, kernel=rbf;, score=0.933 total time=   0.2s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=1, kernel=linear;, score=0.909 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=1, kernel=linear;, score=0.907 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=1, kernel=linear;, score=0.877 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=1, kernel=linear;, score=0.909 total time=   0.2s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=1, kernel=linear;, score=0.901 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=1, kernel=poly;, score=0.889 total time=   0.4s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=1, kernel=poly;, score=0.904 total time=   0.3s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=1, kernel=poly;, score=0.877 total time=   0.4s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=1, kernel=poly;, score=0.941 total time=   0.4s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=1, kernel=poly;, score=0.926 total time=   0.2s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.916 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.921 total time=   0.2s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.934 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.1, kernel=rbf;, score=0.924 total time=   0.2s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.909 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.907 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.877 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.909 total time=   0.3s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.1, kernel=linear;, score=0.901 total time=   0.2s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.919 total time=   0.5s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.934 total time=   0.5s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.916 total time=   0.5s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.929 total time=   0.5s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.1, kernel=poly;, score=0.933 total time=   0.5s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.882 total time=   0.2s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.877 total time=   0.2s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.848 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.904 total time=   0.3s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.01, kernel=rbf;, score=0.884 total time=   0.2s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.909 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.907 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.877 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.909 total time=   0.2s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.01, kernel=linear;, score=0.901 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.103 total time=   0.6s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.894 total time=   0.5s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.894 total time=   0.6s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.894 total time=   0.6s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.01, kernel=poly;, score=0.897 total time=   0.5s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.860 total time=   0.5s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.838 total time=   0.4s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.885 total time=   0.5s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.001, kernel=rbf;, score=0.865 total time=   0.5s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.909 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.907 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.877 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.909 total time=   0.2s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.001, kernel=linear;, score=0.901 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.103 total time=   0.6s\n",
      "[CV 2/5] END C=100, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.894 total time=   0.5s\n",
      "[CV 3/5] END C=100, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.894 total time=   0.6s\n",
      "[CV 4/5] END C=100, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.894 total time=   0.6s\n",
      "[CV 5/5] END C=100, class_weight=balanced, gamma=0.001, kernel=poly;, score=0.897 total time=   0.5s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=1, kernel=rbf;, score=0.931 total time=   0.2s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=1, kernel=rbf;, score=0.941 total time=   0.2s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=1, kernel=rbf;, score=0.939 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=1, kernel=rbf;, score=0.958 total time=   0.3s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=1, kernel=rbf;, score=0.951 total time=   0.3s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=1, kernel=linear;, score=0.912 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=1, kernel=linear;, score=0.916 total time=   0.2s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=1, kernel=linear;, score=0.919 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=1, kernel=linear;, score=0.919 total time=   0.2s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=1, kernel=linear;, score=0.906 total time=   0.3s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=1, kernel=poly;, score=0.931 total time=   0.2s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=1, kernel=poly;, score=0.941 total time=   0.2s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=1, kernel=poly;, score=0.946 total time=   0.3s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=1, kernel=poly;, score=0.951 total time=   0.2s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=1, kernel=poly;, score=0.953 total time=   0.3s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.1, kernel=rbf;, score=0.921 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.1, kernel=rbf;, score=0.936 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.1, kernel=rbf;, score=0.934 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.1, kernel=rbf;, score=0.946 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.1, kernel=rbf;, score=0.936 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.1, kernel=linear;, score=0.912 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.1, kernel=linear;, score=0.916 total time=   0.2s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.1, kernel=linear;, score=0.919 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.1, kernel=linear;, score=0.919 total time=   0.2s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.1, kernel=linear;, score=0.906 total time=   0.3s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.1, kernel=poly;, score=0.897 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.1, kernel=poly;, score=0.894 total time=   0.2s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.1, kernel=poly;, score=0.894 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.1, kernel=poly;, score=0.894 total time=   0.2s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.1, kernel=poly;, score=0.897 total time=   0.2s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.01, kernel=rbf;, score=0.912 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.01, kernel=rbf;, score=0.929 total time=   0.2s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.01, kernel=rbf;, score=0.931 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.01, kernel=rbf;, score=0.951 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.01, kernel=rbf;, score=0.929 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.01, kernel=linear;, score=0.912 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.01, kernel=linear;, score=0.916 total time=   0.2s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.01, kernel=linear;, score=0.919 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.01, kernel=linear;, score=0.919 total time=   0.2s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.01, kernel=linear;, score=0.906 total time=   0.3s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.01, kernel=poly;, score=0.897 total time=   0.2s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.01, kernel=poly;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.01, kernel=poly;, score=0.894 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.01, kernel=poly;, score=0.894 total time=   0.0s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.01, kernel=poly;, score=0.897 total time=   0.1s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.001, kernel=rbf;, score=0.897 total time=   0.2s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.001, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.001, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.001, kernel=rbf;, score=0.894 total time=   0.3s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.001, kernel=rbf;, score=0.897 total time=   0.2s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.001, kernel=linear;, score=0.912 total time=   0.3s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.001, kernel=linear;, score=0.916 total time=   0.3s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.001, kernel=linear;, score=0.919 total time=   0.2s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.001, kernel=linear;, score=0.919 total time=   0.2s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.001, kernel=linear;, score=0.906 total time=   0.3s\n",
      "[CV 1/5] END C=100, class_weight=None, gamma=0.001, kernel=poly;, score=0.897 total time=   0.1s\n",
      "[CV 2/5] END C=100, class_weight=None, gamma=0.001, kernel=poly;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END C=100, class_weight=None, gamma=0.001, kernel=poly;, score=0.894 total time=   0.1s\n",
      "[CV 4/5] END C=100, class_weight=None, gamma=0.001, kernel=poly;, score=0.894 total time=   0.1s\n",
      "[CV 5/5] END C=100, class_weight=None, gamma=0.001, kernel=poly;, score=0.897 total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100],\n",
       "                         &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;linear&#x27;, &#x27;poly&#x27;]},\n",
       "             refit=&#x27;f1_macro&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100],\n",
       "                         &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;linear&#x27;, &#x27;poly&#x27;]},\n",
       "             refit=&#x27;f1_macro&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100],\n",
       "                         'class_weight': ['balanced', None],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001],\n",
       "                         'kernel': ['rbf', 'linear', 'poly']},\n",
       "             refit='f1_macro', verbose=3)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(), param_grid, refit ='f1_macro', cv=kfold, verbose=3)\n",
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.68        44\n",
      "           1       0.97      0.97      0.97       465\n",
      "\n",
      "    accuracy                           0.95       509\n",
      "   macro avg       0.84      0.82      0.83       509\n",
      "weighted avg       0.95      0.95      0.95       509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = grid.predict(X_test)\n",
    "\n",
    "    # print classification report\n",
    "print(classification_report(Y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43973268aa23c7cf4b4cafe0e819fac9b2412fcc991a21988492c3271a4e3f9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
